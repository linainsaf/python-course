{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction to Python Programming Python is a powerful, high-level programming language that is widely used for web development, data analysis, machine learning, and scientific computing. Its simple, easy-to-read syntax and versatile libraries make it a popular choice for beginners and experienced programmers alike. In this course, you will learn the basics of Python programming, including data types, variables, operators, control flow, and functions. You will also explore advanced topics such as data structures, working with data, data visualization, and machine learning. Along the way, you will gain hands-on experience through a variety of exercises and a final project. By the end of this course, you will have a solid foundation in Python programming, and the skills to apply it to a wide range of data science and other applications. Various Recources for you to practice Codecademy's Learn Python Track : This interactive course covers all the basics of Python and includes exercises to practice what you've learned. HackerRank's Python Domain : This website offers a wide range of Python coding challenges, from beginners to advanced levels. Python.org's Beginner's Guide : This guide provides a gentle introduction to Python, including tutorials and exercises for beginners. Google's Python Class : This free class, taught by Google engineer Nick Parlante, includes video lectures, slides, and exercises. Full Stack Python : Is a website that provides resources and tutorials on various aspects of the Python programming language, with a focus on web development and data science. Additionally, the website provides a curated list of resources for further learning and a podcast discussing all things Python. Code Signal : Is a website and platform that provides a variety of tools and resources for developers, including a code editor, a test runner, and a code execution environment. It also provides a variety of challenges and assessments to help developers improve their coding skills.","title":"Home"},{"location":"#introduction-to-python-programming","text":"Python is a powerful, high-level programming language that is widely used for web development, data analysis, machine learning, and scientific computing. Its simple, easy-to-read syntax and versatile libraries make it a popular choice for beginners and experienced programmers alike. In this course, you will learn the basics of Python programming, including data types, variables, operators, control flow, and functions. You will also explore advanced topics such as data structures, working with data, data visualization, and machine learning. Along the way, you will gain hands-on experience through a variety of exercises and a final project. By the end of this course, you will have a solid foundation in Python programming, and the skills to apply it to a wide range of data science and other applications.","title":"Introduction to Python Programming"},{"location":"#various-recources-for-you-to-practice","text":"Codecademy's Learn Python Track : This interactive course covers all the basics of Python and includes exercises to practice what you've learned. HackerRank's Python Domain : This website offers a wide range of Python coding challenges, from beginners to advanced levels. Python.org's Beginner's Guide : This guide provides a gentle introduction to Python, including tutorials and exercises for beginners. Google's Python Class : This free class, taught by Google engineer Nick Parlante, includes video lectures, slides, and exercises. Full Stack Python : Is a website that provides resources and tutorials on various aspects of the Python programming language, with a focus on web development and data science. Additionally, the website provides a curated list of resources for further learning and a podcast discussing all things Python. Code Signal : Is a website and platform that provides a variety of tools and resources for developers, including a code editor, a test runner, and a code execution environment. It also provides a variety of challenges and assessments to help developers improve their coding skills.","title":"Various Recources for you to practice"},{"location":"basic/","text":"Basic Python Concepts Variables Variables are used to store values in Python. They are like containers that hold data, and you can use them to perform operations on that data. Variables are declared using the assignment operator (=) and can be of different types, such as integers, floating-point numbers, strings, and more. # Example of variable assignment x = 5 y = \"Hello World\" z = [ 1 , 2 , 3 ] Data types and structures Python supports several built-in data types, such as integers, floating-point numbers, strings, lists, tuples, and dictionaries. Each data type has its own set of characteristics and methods. # Example of different data types x = 5 # integer y = 3.14 # floating-point number z = \"Hello World\" # string a = [ 1 , 2 , 3 ] # list b = ( 4 , 5 , 6 ) # tuple c = { \"name\" : \"John\" , \"age\" : 30 } # dictionary Operators Python supports various types of operators, such as arithmetic operators (+, -, x , /, %), comparison operators (>, <, >=, <=, ==, !=), and logical operators (and, or, not). These operators are used to perform different types of operations on variables and data. # Example of operators x = 5 y = 2 # arithmetic operators print ( x + y ) # 7 print ( x - y ) # 3 print ( x * y ) # 10 print ( x / y ) # 2.5 print ( x % y ) # 1 # comparison operators print ( x == y ) # False print ( x > 2 ) # True # logical operators print ( x == y and x > 2 ) # False print ( x == y or x > 2 ) # True Control flow Control flow or Conditional Statements allows us to control the flow of execution of our program based on certain conditions. For example : if-elif-else statements x = 5 if x > 0 : print ( \"x is positive\" ) elif x < 0 : print ( \"x is negative\" ) else : print ( \"x is zero\" ) for loop for i in range ( 5 ): print ( i ) while loop x = 5 while x > 0 : print ( x ) x -= 1 Functions Functions are a way to group together a set of instructions to perform a specific task. Functions are defined using the def keyword and can take input arguments and return output values. def add ( x , y ): return x + y result = add ( 5 , 2 ) print ( result ) # 7 Modules and Libraries Python has a large number of built-in modules and libraries that provide a wide range of functionality. You can use these modules to perform various tasks, such as working with the file system, performing mathematical calculations, and more. # Example of importing a module import math result = math . sqrt ( 16 ) print ( result ) # 4.0 # Example of importing a specific function from a module from math import sqrt result = sqrt ( 16 ) print ( result ) # 4.0 Exception Handling Python supports exception handling, which allows you to handle errors and exceptions that may occur while running your program. This helps you to write robust code that can handle unexpected situations while True : try : x = int ( input ( \"Please enter a number: \" )) y = int ( input ( \"Please enter another number: \" )) print ( \"The result of x/y is:\" , x / y ) break except ValueError : print ( \"Oops! One of the inputs was not a valid number. Try again...\" ) except ZeroDivisionError : print ( \"Oops! You cannot divide by zero. Try again...\" ) In this example, program will handle two types of exception: ValueError and ZeroDivisionError, as the user input may not be valid number and also user may try to divide by zero. Now, let's code ! Things to Remember Case Sensitivity: Python is a case-sensitive language, so be mindful of the case when naming variables, functions, and classes. This means, Variable and variable are not the same. Each variable, function and class should have a unique name within your code The only variables you need to consider inside your function are the arguments of that function Always give the identifiers a name that makes sense. While c = 10 is a valid name, writing count = 10 would make more sense, and it would be easier to figure out what it represents when you look at your code after a long gap. Multiple words can be separated using an underscore, like this_is_a_long_variable . Comments: Use the pound symbol (#) to denote comments in your code, which will be ignored by the interpreter. In computer programming, comments are hints that we use to make our code more understandable. Quotation Marks: In Python, you can use either single quotes or double quotes to denote strings, but be consistent within your code. Colon (:): Colons are used to denote the start of a new block of code, such as in a for loop, if statement, or function definition. White Space: Be mindful of white space, as it can affect the way your code is interpreted. For example, leading white space is used to denote blocks of code. Parentheses: Parentheses are used to group expressions, to call functions, and to define tuples. Import Statement: Use the import statement to import libraries and modules into your code. print() function: Use the print() function to output text to the console.","title":"Basic Python Concepts"},{"location":"basic/#basic-python-concepts","text":"","title":"Basic Python Concepts"},{"location":"basic/#variables","text":"Variables are used to store values in Python. They are like containers that hold data, and you can use them to perform operations on that data. Variables are declared using the assignment operator (=) and can be of different types, such as integers, floating-point numbers, strings, and more. # Example of variable assignment x = 5 y = \"Hello World\" z = [ 1 , 2 , 3 ]","title":"Variables"},{"location":"basic/#data-types-and-structures","text":"Python supports several built-in data types, such as integers, floating-point numbers, strings, lists, tuples, and dictionaries. Each data type has its own set of characteristics and methods. # Example of different data types x = 5 # integer y = 3.14 # floating-point number z = \"Hello World\" # string a = [ 1 , 2 , 3 ] # list b = ( 4 , 5 , 6 ) # tuple c = { \"name\" : \"John\" , \"age\" : 30 } # dictionary","title":"Data types and structures"},{"location":"basic/#operators","text":"Python supports various types of operators, such as arithmetic operators (+, -, x , /, %), comparison operators (>, <, >=, <=, ==, !=), and logical operators (and, or, not). These operators are used to perform different types of operations on variables and data. # Example of operators x = 5 y = 2 # arithmetic operators print ( x + y ) # 7 print ( x - y ) # 3 print ( x * y ) # 10 print ( x / y ) # 2.5 print ( x % y ) # 1 # comparison operators print ( x == y ) # False print ( x > 2 ) # True # logical operators print ( x == y and x > 2 ) # False print ( x == y or x > 2 ) # True","title":"Operators"},{"location":"basic/#control-flow","text":"Control flow or Conditional Statements allows us to control the flow of execution of our program based on certain conditions. For example : if-elif-else statements x = 5 if x > 0 : print ( \"x is positive\" ) elif x < 0 : print ( \"x is negative\" ) else : print ( \"x is zero\" ) for loop for i in range ( 5 ): print ( i ) while loop x = 5 while x > 0 : print ( x ) x -= 1","title":"Control flow"},{"location":"basic/#functions","text":"Functions are a way to group together a set of instructions to perform a specific task. Functions are defined using the def keyword and can take input arguments and return output values. def add ( x , y ): return x + y result = add ( 5 , 2 ) print ( result ) # 7","title":"Functions"},{"location":"basic/#modules-and-libraries","text":"Python has a large number of built-in modules and libraries that provide a wide range of functionality. You can use these modules to perform various tasks, such as working with the file system, performing mathematical calculations, and more. # Example of importing a module import math result = math . sqrt ( 16 ) print ( result ) # 4.0 # Example of importing a specific function from a module from math import sqrt result = sqrt ( 16 ) print ( result ) # 4.0","title":"Modules and Libraries"},{"location":"basic/#exception-handling","text":"Python supports exception handling, which allows you to handle errors and exceptions that may occur while running your program. This helps you to write robust code that can handle unexpected situations while True : try : x = int ( input ( \"Please enter a number: \" )) y = int ( input ( \"Please enter another number: \" )) print ( \"The result of x/y is:\" , x / y ) break except ValueError : print ( \"Oops! One of the inputs was not a valid number. Try again...\" ) except ZeroDivisionError : print ( \"Oops! You cannot divide by zero. Try again...\" ) In this example, program will handle two types of exception: ValueError and ZeroDivisionError, as the user input may not be valid number and also user may try to divide by zero. Now, let's code !","title":"Exception Handling"},{"location":"basic/#things-to-remember","text":"Case Sensitivity: Python is a case-sensitive language, so be mindful of the case when naming variables, functions, and classes. This means, Variable and variable are not the same. Each variable, function and class should have a unique name within your code The only variables you need to consider inside your function are the arguments of that function Always give the identifiers a name that makes sense. While c = 10 is a valid name, writing count = 10 would make more sense, and it would be easier to figure out what it represents when you look at your code after a long gap. Multiple words can be separated using an underscore, like this_is_a_long_variable . Comments: Use the pound symbol (#) to denote comments in your code, which will be ignored by the interpreter. In computer programming, comments are hints that we use to make our code more understandable. Quotation Marks: In Python, you can use either single quotes or double quotes to denote strings, but be consistent within your code. Colon (:): Colons are used to denote the start of a new block of code, such as in a for loop, if statement, or function definition. White Space: Be mindful of white space, as it can affect the way your code is interpreted. For example, leading white space is used to denote blocks of code. Parentheses: Parentheses are used to group expressions, to call functions, and to define tuples. Import Statement: Use the import statement to import libraries and modules into your code. print() function: Use the print() function to output text to the console.","title":"Things to Remember"},{"location":"env/","text":"Setting up a Development Environment Introduction In this chapter, you will learn how to set up a Python development environment on your computer. A development environment is a software application that provides the necessary tools and resources for writing, testing, and debugging code. By the end of this chapter, you will have a working Python environment that you can use to start writing your own programs. Installing Python There are several ways to install Python 3, here are some of the most common methods: Using Anaconda Anaconda is a popular distribution of Python and R for data science and machine learning. It comes with a lot of packages and libraries pre-installed, and it also includes the conda package manager, which makes it easy to install additional packages and manage environments. To install Python using Anaconda, you can follow these steps: Go to the Anaconda Website and download the latest version of Anaconda for your operating system. Once the download is complete, run the installer and follow the prompts to install Anaconda. Once installation is complete, open Anaconda Navigator, which is a graphical user interface that allows you to manage your environments and packages. Create a new environment with Python 3 by clicking the \"Create\" button and selecting \"Python 3\" as the version. Using pip pip is the package installer for Python. It allows you to install and manage packages for your Python installation. To install Python 3 and Jupyter Notebook using pip, you can follow these two steps: Make sure that Python 3 is installed on your system by running the command python3 --version in a terminal or command prompt. If Python 3 is not installed, download the latest version from The Official Python Website . Using Homebrew (macOS and Linux) Homebrew is a package manager for macOS and Linux. It allows you to install and manage packages for your operating system. To install Python 3 using Homebrew, you can follow these steps: Make sure that Homebrew is installed on your system by running the command brew --version in a terminal. If Homebrew is not installed, you can install it by following the instructions on The Homebrew Website . Once you have Homebrew installed, you can use it to install Python 3 by running the command brew install python3 in a terminal. Using Chocolatey (Windows) Chocolatey is a package manager for Windows. It allows you to install and manage packages for your operating system. To install Python 3 using Chocolatey, you can follow these steps: Make sure that Chocolatey is installed on your system by running the command choco --version in a command prompt. If Chocolatey is not installed, you can install it by following the instructions on The Chocolatey Website . Once you have Chocolatey installed, you can use it to install Python 3 by running the command choco install python in a command prompt. PS : It's also worth noting that many operating systems and Linux distributions come with Python 2 pre-installed, and you may want to install Python 3 alongside it without replacing the pre-installed Python 2. In this case, you should be careful when running pip and python commands, since you may need to use pip3 and python3, respectively, to ensure that you're using the correct version of the software. Choosing an IDE or Text Editor Once you have Python installed, the next step is to choose a text editor or integrated development environment (IDE) to write your code in. An IDE is a software application that provides a comprehensive environment for coding, including features such as syntax highlighting, code completion, and debugging tools. In this class we're using Jupyter. Jupyter is an open-source web-based IDE that allows users to create and share documents that contain live code, equations, visualizations, and narrative text. It is particularly well-suited for data science because it: Provides an easy way to interact with data: Jupyter allows you to load, visualize, and manipulate data in a variety of formats, such as CSV, JSON, and SQL. This makes it a great tool for data exploration and analysis. Supports multiple programming languages: Jupyter supports many programming languages, including Python, R, and Julia, which makes it easy to use the language that is best suited for your project. Enables reproducible research: Jupyter allows you to organize your code, data, and visualizations in a single document, which makes it easy to reproduce your results and share your work with others. Provides a collaborative environment: Jupyter allows multiple users to work on the same notebook at the same time, which makes it a great tool for collaborative data science projects. Has a large and active community: Jupyter has a large and active community of developers, users, and contributors who provide support, resources, and add-ons that extend its functionality. To install Jupyter: Using Anaconda: In your conda enviroment you can install Jupyter Notebook by running the command conda install jupyter . Using pip3: You can install Jupyter using the pip package manager by running the command pip3 install jupyter in your command line. This method requires that you have Python3 and pip3 already installed on your system. You can then launch Jupyter Notebook by running the command jupyter notebook in a terminal or command prompt. Some popular IDEs for Python include PyCharm, Spyder, and IDLE. Text editors, such as Sublime Text, Atom, or Notepad++, are also popular among Python developers and are preferred by some. I suggest you Install Sublime Text as a second IDE. Installing Additional Libraries and Packages Python has a vast collection of libraries and packages that can be used to perform a wide range of tasks. Some popular packages include NumPy and Pandas for data manipulation, Matplotlib and Seaborn for data visualization, and scikit-learn for machine learning. You can install these packages using the pip package manager, which is included with Python. Examples : pip3 install numpy pip3 install pandas Conclusion By the end of this chapter, you should have a working Python development environment that you can use to start writing your own programs. You will have a Python interpreter, a text editor or IDE, and any additional libraries and packages that you need. In the next chapter, you will learn the basics of Python programming, including data types, variables, and operators.","title":"Setting up a Development Environment"},{"location":"env/#setting-up-a-development-environment","text":"","title":"Setting up a Development Environment"},{"location":"env/#introduction","text":"In this chapter, you will learn how to set up a Python development environment on your computer. A development environment is a software application that provides the necessary tools and resources for writing, testing, and debugging code. By the end of this chapter, you will have a working Python environment that you can use to start writing your own programs.","title":"Introduction"},{"location":"env/#installing-python","text":"There are several ways to install Python 3, here are some of the most common methods:","title":"Installing Python"},{"location":"env/#using-anaconda","text":"Anaconda is a popular distribution of Python and R for data science and machine learning. It comes with a lot of packages and libraries pre-installed, and it also includes the conda package manager, which makes it easy to install additional packages and manage environments. To install Python using Anaconda, you can follow these steps: Go to the Anaconda Website and download the latest version of Anaconda for your operating system. Once the download is complete, run the installer and follow the prompts to install Anaconda. Once installation is complete, open Anaconda Navigator, which is a graphical user interface that allows you to manage your environments and packages. Create a new environment with Python 3 by clicking the \"Create\" button and selecting \"Python 3\" as the version.","title":"Using Anaconda"},{"location":"env/#using-pip","text":"pip is the package installer for Python. It allows you to install and manage packages for your Python installation. To install Python 3 and Jupyter Notebook using pip, you can follow these two steps: Make sure that Python 3 is installed on your system by running the command python3 --version in a terminal or command prompt. If Python 3 is not installed, download the latest version from The Official Python Website .","title":"Using pip"},{"location":"env/#using-homebrew-macos-and-linux","text":"Homebrew is a package manager for macOS and Linux. It allows you to install and manage packages for your operating system. To install Python 3 using Homebrew, you can follow these steps: Make sure that Homebrew is installed on your system by running the command brew --version in a terminal. If Homebrew is not installed, you can install it by following the instructions on The Homebrew Website . Once you have Homebrew installed, you can use it to install Python 3 by running the command brew install python3 in a terminal.","title":"Using Homebrew (macOS and Linux)"},{"location":"env/#using-chocolatey-windows","text":"Chocolatey is a package manager for Windows. It allows you to install and manage packages for your operating system. To install Python 3 using Chocolatey, you can follow these steps: Make sure that Chocolatey is installed on your system by running the command choco --version in a command prompt. If Chocolatey is not installed, you can install it by following the instructions on The Chocolatey Website . Once you have Chocolatey installed, you can use it to install Python 3 by running the command choco install python in a command prompt. PS : It's also worth noting that many operating systems and Linux distributions come with Python 2 pre-installed, and you may want to install Python 3 alongside it without replacing the pre-installed Python 2. In this case, you should be careful when running pip and python commands, since you may need to use pip3 and python3, respectively, to ensure that you're using the correct version of the software.","title":"Using Chocolatey (Windows)"},{"location":"env/#choosing-an-ide-or-text-editor","text":"Once you have Python installed, the next step is to choose a text editor or integrated development environment (IDE) to write your code in. An IDE is a software application that provides a comprehensive environment for coding, including features such as syntax highlighting, code completion, and debugging tools. In this class we're using Jupyter. Jupyter is an open-source web-based IDE that allows users to create and share documents that contain live code, equations, visualizations, and narrative text. It is particularly well-suited for data science because it: Provides an easy way to interact with data: Jupyter allows you to load, visualize, and manipulate data in a variety of formats, such as CSV, JSON, and SQL. This makes it a great tool for data exploration and analysis. Supports multiple programming languages: Jupyter supports many programming languages, including Python, R, and Julia, which makes it easy to use the language that is best suited for your project. Enables reproducible research: Jupyter allows you to organize your code, data, and visualizations in a single document, which makes it easy to reproduce your results and share your work with others. Provides a collaborative environment: Jupyter allows multiple users to work on the same notebook at the same time, which makes it a great tool for collaborative data science projects. Has a large and active community: Jupyter has a large and active community of developers, users, and contributors who provide support, resources, and add-ons that extend its functionality. To install Jupyter: Using Anaconda: In your conda enviroment you can install Jupyter Notebook by running the command conda install jupyter . Using pip3: You can install Jupyter using the pip package manager by running the command pip3 install jupyter in your command line. This method requires that you have Python3 and pip3 already installed on your system. You can then launch Jupyter Notebook by running the command jupyter notebook in a terminal or command prompt. Some popular IDEs for Python include PyCharm, Spyder, and IDLE. Text editors, such as Sublime Text, Atom, or Notepad++, are also popular among Python developers and are preferred by some. I suggest you Install Sublime Text as a second IDE.","title":"Choosing an IDE or Text Editor"},{"location":"env/#installing-additional-libraries-and-packages","text":"Python has a vast collection of libraries and packages that can be used to perform a wide range of tasks. Some popular packages include NumPy and Pandas for data manipulation, Matplotlib and Seaborn for data visualization, and scikit-learn for machine learning. You can install these packages using the pip package manager, which is included with Python. Examples : pip3 install numpy pip3 install pandas","title":"Installing Additional Libraries and Packages"},{"location":"env/#conclusion","text":"By the end of this chapter, you should have a working Python development environment that you can use to start writing your own programs. You will have a Python interpreter, a text editor or IDE, and any additional libraries and packages that you need. In the next chapter, you will learn the basics of Python programming, including data types, variables, and operators.","title":"Conclusion"},{"location":"io/","text":"Introduction File Input/Output (I/O) operations in Python allow you to read from and write to files on your local file system. The open function is the main function used for working with files in Python, and it returns a file object that can be used to perform various operations on the file. Opening a File The basic syntax for opening a file in Python is as follows: file = open ( \"filename.extension\" , \"mode\" ) The first argument is the name of the file, and the second argument is the mode in which you want to open the file. The most common modes are \"r\" for reading, \"w\" for writing, and \"a\" for appending. For example, to open a text file called example.txt in read mode, you would write the following code: file = open ( \"example.txt\" , \"r\" ) Reading from a File Once you have opened a file, you can read from it using various methods, such as read, readline, and readlines. The read method reads the entire contents of a file as a single string. For example: file = open ( \"example.txt\" , \"r\" ) contents = file . read () print ( contents ) file . close () The readline method reads a single line of a file. For example: file = open ( \"example.txt\" , \"r\" ) first_line = file . readline () print ( first_line ) file . close () The readlines method reads all lines of a file as a list of strings, where each string is a single line. For example: file = open ( \"example.txt\" , \"r\" ) lines = file . readlines () print ( lines ) file . close () Writing to a File To write to a file, you can use the write method. The basic syntax for writing to a file is as follows: file = open ( \"filename.extension\" , \"mode\" ) file . write ( \"data to be written\" ) file . close () For example, to write the string \"Hello, World!\" to a file called example.txt, you would write the following code: file = open ( \"example.txt\" , \"w\" ) file . write ( \"Hello, World!\" ) file . close () If the file specified in the open function does not exist, it will be created. If the file does exist, its contents will be overwritten by the new data. Appending to a File To append data to an existing file, you can open the file in append mode (\"a\") instead of write mode (\"w\"). The basic syntax for appending to a file is as follows: file = open ( \"filename.extension\" , \"mode\" ) file . write ( \"data to be written\" ) file . close () For example, to append the string \"Hello, World!\" to a file called example.txt, you would write the following code: file = open ( \"example.txt\" , \"a\" ) file . write ( \"Hello, World!\" ) file . close () Context Manager One important thing to note when working with files in Python is that you should always close the file when you are done with it. This can be done using the close method, as demonstrated in the previous examples. However, there is a better way to ensure that the file is always closed, even if an error occurs, and that is by using a context manager. A context manager is an object that provides a convenient way to manage resources, such as files, that need to be cleaned up after they are used. In Python, the with statement is used to create a context manager. The basic syntax for using a context manager to open a file is as follows: with open ( \"filename.extension\" , \"mode\" ) as file : # Perform file I/O operations For example, to read the contents of a file called example.txt using a context manager, you would write the following code: with open ( \"example.txt\" , \"r\" ) as file : contents = file . read () print ( contents ) With this approach, the file is automatically closed when the with block is exited, even if an error occurs. CSV Library Reading data from a CSV file To read data from a CSV file, you can use the csv.reader function. This function returns an iterator that you can loop over to access the rows of the CSV file. Here is an example: import csv with open ( 'my_file.csv' , 'r' ) as csv_file : csv_reader = csv . reader ( csv_file ) # Loop over each row in the CSV file for row in csv_reader : # Access the values of each row print ( row ) This code opens the my_file.csv file in read mode and creates a csv.reader object using the csv.reader function. Then, it loops over each row in the CSV file and prints out the values of each row. Writing data to a CSV file To write data to a CSV file, you can use the csv.writer function. This function takes a file object and returns a writer object that you can use to write rows to the CSV file. Here is an example: import csv with open ( 'my_file.csv' , 'w' , newline = '' ) as csv_file : csv_writer = csv . writer ( csv_file ) # Write rows to the CSV file csv_writer . writerow ([ 'Title' , 'Author' , 'Publisher' ]) csv_writer . writerow ([ 'To Kill a Mockingbird' , 'Harper Lee' , 'Grand Central Publishing' ]) This code opens the my_file.csv file in write mode and creates a csv.writer object using the csv.writer function. Then, it writes two rows to the CSV file. Appending data to a CSV file To append data to a CSV file, you can use the csv.writer function with the a mode. This mode will open the file in append mode, which allows you to add new rows to the end of the file. Here is an example: import csv with open ( 'my_file.csv' , 'a' , newline = '' ) as csv_file : csv_writer = csv . writer ( csv_file ) # Append rows to the CSV file csv_writer . writerow ([ '1984' , 'George Orwell' , 'Signet Classic' ]) This code opens the my_file.csv file in append mode and creates a csv.writer object using the csv.writer function. Then, it appends a new row to the end of the CSV file. Removing data from a CSV file To remove data from a CSV file, you will need to read in the entire file, filter out the rows that you don't want, and then write the filtered rows back to the CSV file. Here is an example: import csv # Read in the CSV file and filter out the rows that match a specific criteria with open ( 'my_file.csv' , 'r' ) as csv_file : csv_reader = csv . reader ( csv_file ) filtered_rows = [] for row in csv_reader : if row [ 1 ] != 'Harper Lee' : filtered_rows . append ( row ) # Write the filtered rows back to the CSV file with open ( 'my_file.csv' , 'w' , newline = '' ) as csv_file : csv_writer = csv . writer ( csv_file ) for row in filtered_rows : csv_writer . writerow ( row ) This code reads in the my_file.csv file and filters out the rows where the author is \"Harper Lee\". Then, it opens the same file in write mode and writes the filtered rows back to the CSV file.","title":"File Input/Output (I/O) Operations"},{"location":"io/#introduction","text":"File Input/Output (I/O) operations in Python allow you to read from and write to files on your local file system. The open function is the main function used for working with files in Python, and it returns a file object that can be used to perform various operations on the file.","title":"Introduction"},{"location":"io/#opening-a-file","text":"The basic syntax for opening a file in Python is as follows: file = open ( \"filename.extension\" , \"mode\" ) The first argument is the name of the file, and the second argument is the mode in which you want to open the file. The most common modes are \"r\" for reading, \"w\" for writing, and \"a\" for appending. For example, to open a text file called example.txt in read mode, you would write the following code: file = open ( \"example.txt\" , \"r\" )","title":"Opening a File"},{"location":"io/#reading-from-a-file","text":"Once you have opened a file, you can read from it using various methods, such as read, readline, and readlines. The read method reads the entire contents of a file as a single string. For example: file = open ( \"example.txt\" , \"r\" ) contents = file . read () print ( contents ) file . close () The readline method reads a single line of a file. For example: file = open ( \"example.txt\" , \"r\" ) first_line = file . readline () print ( first_line ) file . close () The readlines method reads all lines of a file as a list of strings, where each string is a single line. For example: file = open ( \"example.txt\" , \"r\" ) lines = file . readlines () print ( lines ) file . close ()","title":"Reading from a File"},{"location":"io/#writing-to-a-file","text":"To write to a file, you can use the write method. The basic syntax for writing to a file is as follows: file = open ( \"filename.extension\" , \"mode\" ) file . write ( \"data to be written\" ) file . close () For example, to write the string \"Hello, World!\" to a file called example.txt, you would write the following code: file = open ( \"example.txt\" , \"w\" ) file . write ( \"Hello, World!\" ) file . close () If the file specified in the open function does not exist, it will be created. If the file does exist, its contents will be overwritten by the new data.","title":"Writing to a File"},{"location":"io/#appending-to-a-file","text":"To append data to an existing file, you can open the file in append mode (\"a\") instead of write mode (\"w\"). The basic syntax for appending to a file is as follows: file = open ( \"filename.extension\" , \"mode\" ) file . write ( \"data to be written\" ) file . close () For example, to append the string \"Hello, World!\" to a file called example.txt, you would write the following code: file = open ( \"example.txt\" , \"a\" ) file . write ( \"Hello, World!\" ) file . close ()","title":"Appending to a File"},{"location":"io/#context-manager","text":"One important thing to note when working with files in Python is that you should always close the file when you are done with it. This can be done using the close method, as demonstrated in the previous examples. However, there is a better way to ensure that the file is always closed, even if an error occurs, and that is by using a context manager. A context manager is an object that provides a convenient way to manage resources, such as files, that need to be cleaned up after they are used. In Python, the with statement is used to create a context manager. The basic syntax for using a context manager to open a file is as follows: with open ( \"filename.extension\" , \"mode\" ) as file : # Perform file I/O operations For example, to read the contents of a file called example.txt using a context manager, you would write the following code: with open ( \"example.txt\" , \"r\" ) as file : contents = file . read () print ( contents ) With this approach, the file is automatically closed when the with block is exited, even if an error occurs.","title":"Context Manager"},{"location":"io/#csv-library","text":"","title":"CSV Library"},{"location":"io/#reading-data-from-a-csv-file","text":"To read data from a CSV file, you can use the csv.reader function. This function returns an iterator that you can loop over to access the rows of the CSV file. Here is an example: import csv with open ( 'my_file.csv' , 'r' ) as csv_file : csv_reader = csv . reader ( csv_file ) # Loop over each row in the CSV file for row in csv_reader : # Access the values of each row print ( row ) This code opens the my_file.csv file in read mode and creates a csv.reader object using the csv.reader function. Then, it loops over each row in the CSV file and prints out the values of each row.","title":"Reading data from a CSV file"},{"location":"io/#writing-data-to-a-csv-file","text":"To write data to a CSV file, you can use the csv.writer function. This function takes a file object and returns a writer object that you can use to write rows to the CSV file. Here is an example: import csv with open ( 'my_file.csv' , 'w' , newline = '' ) as csv_file : csv_writer = csv . writer ( csv_file ) # Write rows to the CSV file csv_writer . writerow ([ 'Title' , 'Author' , 'Publisher' ]) csv_writer . writerow ([ 'To Kill a Mockingbird' , 'Harper Lee' , 'Grand Central Publishing' ]) This code opens the my_file.csv file in write mode and creates a csv.writer object using the csv.writer function. Then, it writes two rows to the CSV file.","title":"Writing data to a CSV file"},{"location":"io/#appending-data-to-a-csv-file","text":"To append data to a CSV file, you can use the csv.writer function with the a mode. This mode will open the file in append mode, which allows you to add new rows to the end of the file. Here is an example: import csv with open ( 'my_file.csv' , 'a' , newline = '' ) as csv_file : csv_writer = csv . writer ( csv_file ) # Append rows to the CSV file csv_writer . writerow ([ '1984' , 'George Orwell' , 'Signet Classic' ]) This code opens the my_file.csv file in append mode and creates a csv.writer object using the csv.writer function. Then, it appends a new row to the end of the CSV file.","title":"Appending data to a CSV file"},{"location":"io/#removing-data-from-a-csv-file","text":"To remove data from a CSV file, you will need to read in the entire file, filter out the rows that you don't want, and then write the filtered rows back to the CSV file. Here is an example: import csv # Read in the CSV file and filter out the rows that match a specific criteria with open ( 'my_file.csv' , 'r' ) as csv_file : csv_reader = csv . reader ( csv_file ) filtered_rows = [] for row in csv_reader : if row [ 1 ] != 'Harper Lee' : filtered_rows . append ( row ) # Write the filtered rows back to the CSV file with open ( 'my_file.csv' , 'w' , newline = '' ) as csv_file : csv_writer = csv . writer ( csv_file ) for row in filtered_rows : csv_writer . writerow ( row ) This code reads in the my_file.csv file and filters out the rows where the author is \"Harper Lee\". Then, it opens the same file in write mode and writes the filtered rows back to the CSV file.","title":"Removing data from a CSV file"},{"location":"numpy/","text":"NumPy NumPy is short for Numerical Python. It is a Python library/package used for working with arrays which contains classes, functions, variables , a large library of mathematical functions etc for working with scientific calculation. It can be used to create an \u201cn\u201d dimensional array where \u201cn\u201d is any integer. Why NumPy In Python we have lists that serve the purpose of arrays, but they are slow. NumPy aims to provide an array object that is up to 50x faster than a traditional Python list. The array object in NumPy is called ndarray, it provides a lot of supporting functions that make working with ndarray very easy. Arrays are very frequently used in data science, where speed and resources are very important. What makes NumPy arrays faster than lists: NumPy arrays are stored at one continuous place in memory unlike lists, so processes can access and manipulate them very efficiently. This behavior is called locality of reference. This is the main reason why NumPy is faster than lists. It is also optimized to work with the latest CPU architectures. Installing NumPy To install NumPy, you can use pip, the Python package installer. Open your terminal or command prompt and enter the following command: pip3 install numpy Importing NumPy There are two ways to import NumPy. Code Example : # this will import the entire NumPy module. import numpy as np # this will import all class, objects, variables etc from the NumPy package from numpy import * NumPy is usually imported under the np alias. alias: In Python aliases are an alternate name for referring to the same thing. Creating NumPy Arrays The array object in NumPy is called ndarray. We can create a NumPy ndarray object by using the array() function. NumPy arrays can be created in a number of ways. Here are some of the most common methods: Using the numpy.array() function to create an array from a list/tuple: a = np . array ([ 1 , 2 , 3 ]) - Using the numpy.zeros() function to create an array filled with zeros: b = np . zeros (( 2 , 3 )) - Using the numpy.ones() function to create an array filled with ones: c = np . ones (( 2 , 3 )) Using the numpy.random.randint(): Returns an array of random integers between the two given numbers d = np . random . randint ( 0 , 10 ) - Using the numpy.random.rand() function to create an array of random values: e = np . random . rand ( 2 , 3 ) NumPy Array Dimensions A dimension in arrays is one level of array depth (nested arrays). nested array: are arrays that have arrays as their elements. 0-D Arrays 1-D Arrays 2-D Arrays 3-D Arrays. 0-D arrays, or Scalars, are the elements in an array. Each value in an array is a 0-D array. Code Example: arr = np . array ( 30 ) print ( arr ) An array that has 0-D arrays as its elements is called a uni-dimensional or 1-D array. These are the most common types of arrays. Code Example : arr = np . array ([ 30 , 35 , 38 , 40 , 46 , 52 ]) print ( arr ) An array that has 1-D arrays as its elements is called a 2-D array. These are often used to represent matrix or 2nd order tensors. Code Example : arr = np . array ([[ 30 , 35 , 38 , 40 , 46 , 52 ],[ 22 , 28 , 39 , 42 , 49 , 52 ]]) print ( arr ) An array that has 2-D arrays (matrices) as its elements is called 3-D array. These are often used to represent a 3rd order tensor. Code Example : arr = np . array ([[[ 30 , 35 , 38 , 40 , 46 , 52 ],[ 22 , 28 , 39 , 42 , 49 , 52 ], [ 71 , 24 , 88 , 64 , 31 , 94 ]]]) print ( arr ) NumPy Arrays provides the ndim attribute that returns an integer that tells us how many dimensions the array has. Code Example : arr = np . array ([[[ 30 , 35 , 38 , 40 , 46 , 52 ],[ 22 , 28 , 39 , 42 , 49 , 52 ], [ 71 , 24 , 88 , 64 , 31 , 94 ]]]) print ( arr . ndim ) An array can have any number of dimensions. When the array is created, you can define the number of dimensions by using the ndim argument. Code Example : arr = np . array ([ 1 , 2 , 3 , 4 ], ndmin = 6 ) print ( arr . ndim ) print ( \u201c Number of dimensions : \u201d , arr . ndim ) Arrays type and shape NumPy Array Data Type :The NumPy array object has a property called dtype that returns the data type of the array. Code Example : arr = np . array ([ 1 , 2 , 3 , 4 , 5 ]) print ( arr . dtype ) NumPy Array Shape : The shape of an array is the number of elements in each dimension. NumPy arrays have an attribute called shape that returns a tuple with each index having the number of corresponding elements Code example : arr = np . array ([ 1 , 2 , 3 , 4 , 5 , 6 ]) print ( arr . shape ) NumPy Array Indexing Array indexing is the same as accessing an array element. You can access an array element by referring to its index number. The indexes in NumPy arrays start with 0, meaning that the first element has index 0, and the second has index 1 etc. Code Example : arr = np . array ([ 1 , 2 , 3 , 4 ]) print ( arr [ 0 ]) To access elements from 2-D arrays we can use comma separated integers representing the dimension and the index of the element. Code Example : arr = np . array ([[ 1 , 2 , 3 , 4 ],[ 4 , 3 , 2 , 1 ]]) print ( arr [ 0 ][ 1 ]) To access elements from 3-D arrays we can use comma separated integers representing the dimensions and the index of the element. Code Example : arr = np . array ([ 1 , 2 , 3 , 4 ],[ 4 , 3 , 2 , 1 ],[ 8 , 6 , 7 , 9 ]) print ( arr [ 0 ][ 1 ][ 0 ]) Use negative indexing to access an array from the end Code Example arr = np . array ([ 1 , 2 , 3 , 4 ],[ 4 , 3 , 2 , 1 ],[ 8 , 6 , 7 , 9 ]) print ( arr [ 0 ][ - 1 ][ - 2 ]) NumPy Array Slicing Slicing in python means taking elements from one given index to another given index. We pass slice instead of index like this [start: end]. We can also define the step, like this [start:end:step]. If we don't pass start its considered 0 If we don't pass end its considered length of array in that dimension If we don't pass step its considered 1 Note: The result includes the start index, but excludes the end index. Use the minus operator to refer to an index from the end. Code Example : arr = np . array ([ 1 , 2 , 3 , 4 , 5 ]) print ( arr [ 0 : 5 ]) #slice arrays from index 0 to 5 excluding 5 print (arr[:4]) #slice from beginning to 4 excluding 4 print ( arr [ 2 :]) #slice from index 2 onwards print ( arr [: - 3 ]) #slice from index -3 Code Example : arr = np . array ([ 1 , 2 , 3 , 4 , 5 ]) print ( arr [: 4 : 1 ]) #slice from beginning to 4 step of 1 print (arr[0::3]) #slice from index 0 onwards step of 3 print (arr[:-1:2]) #slice from index -1 step of 2 Array Operations in NumPy Element-wise Operations : NumPy allows you to perform element-wise operations on arrays. Here are some examples: a = np . array ([ 1 , 2 , 3 ]) b = np . array ([ 4 , 5 , 6 ]) # Element-wise addition c = a + b print ( c ) # Output: [5 7 9] # Element-wise multiplication d = a * b print ( d ) # Output: [ 4 10 18] Matrix Multiplication : NumPy allows you to perform matrix multiplication using the numpy.dot() function. Here is an example: a = np . array ([[ 1 , 2 ], [ 3 , 4 ]]) b = np . array ([[ 5 , 6 ], [ 7 , 8 ]]) # Matrix multiplication c = np . dot ( a , b ) print ( c ) NumPy Array Reshaping : Reshaping means changing the shape of an array. The shape of an array is the number of elements in each dimension. By reshaping we can add or remove dimensions or change number of elements in each dimension. Code Example : # we can do it this way arr = np . array ([ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ]) arr2 = arr . reshape ( 5 , 2 ) print ( arr ) print ( arr2 ) # or this way a = np . array ([ 1 , 2 , 3 , 4 , 5 , 6 ]) b = np . reshape ( a , ( 2 , 3 )) print ( a ) print ( b ) Transposing Arrays : NumPy provides a way to transpose arrays using the numpy.transpose() function. Here is an example: a = np . array ([[ 1 , 2 ], [ 3 , 4 ], [ 5 , 6 ]]) b = np . transpose ( a ) print ( b ) Aggregation Functions : NumPy provides several aggregation functions that can be used to compute statistics on arrays. Here are some examples: a = np . array ([ 1 , 2 , 3 , 4 , 5 ]) # Computing the sum of the elements in the array print ( np . sum ( a )) # Output: 15 # Computing the mean of the elements in the array print ( np . mean ( a )) # Output: 3.0 # Computing the standard deviation of the elements in the array print ( np . std ( a )) # Output: 1.41421356 NumPy Array Copy and View The main difference between a copy and a view of an array is that the copy is a new array, and the view is just a view, or link to, the original array. The copy owns the data and any changes made to the copy will not affect original array, and any changes made to the original array will not affect the copy. The view does not own the data and any changes made to the view will affect the original array, and any changes made to the original array will affect the view. As mentioned, copies owns the data, and views does not own the data, so how can we check if it owns the data or not? Every NumPy array has the attribute base that returns None if the array owns the data. Otherwise, the base attribute refers to the original object Code example : import numpy as np arr = np . array ([ 1 , 2 , 3 , 4 , 5 , 6 ]) arrview = arr . view () #creates a view of the array arrcopy=arr.copy() #creates a copy of the array print ( arrview . base ) #check if the array owns its data print (arrcopy.base) #check if the array owns its data (should output none) Documentations NumPy","title":"Understanding & working with Numpy"},{"location":"numpy/#numpy","text":"NumPy is short for Numerical Python. It is a Python library/package used for working with arrays which contains classes, functions, variables , a large library of mathematical functions etc for working with scientific calculation. It can be used to create an \u201cn\u201d dimensional array where \u201cn\u201d is any integer.","title":"NumPy"},{"location":"numpy/#why-numpy","text":"In Python we have lists that serve the purpose of arrays, but they are slow. NumPy aims to provide an array object that is up to 50x faster than a traditional Python list. The array object in NumPy is called ndarray, it provides a lot of supporting functions that make working with ndarray very easy. Arrays are very frequently used in data science, where speed and resources are very important. What makes NumPy arrays faster than lists: NumPy arrays are stored at one continuous place in memory unlike lists, so processes can access and manipulate them very efficiently. This behavior is called locality of reference. This is the main reason why NumPy is faster than lists. It is also optimized to work with the latest CPU architectures.","title":"Why NumPy"},{"location":"numpy/#installing-numpy","text":"To install NumPy, you can use pip, the Python package installer. Open your terminal or command prompt and enter the following command: pip3 install numpy","title":"Installing NumPy"},{"location":"numpy/#importing-numpy","text":"There are two ways to import NumPy. Code Example : # this will import the entire NumPy module. import numpy as np # this will import all class, objects, variables etc from the NumPy package from numpy import * NumPy is usually imported under the np alias. alias: In Python aliases are an alternate name for referring to the same thing.","title":"Importing NumPy"},{"location":"numpy/#creating-numpy-arrays","text":"The array object in NumPy is called ndarray. We can create a NumPy ndarray object by using the array() function. NumPy arrays can be created in a number of ways. Here are some of the most common methods: Using the numpy.array() function to create an array from a list/tuple: a = np . array ([ 1 , 2 , 3 ]) - Using the numpy.zeros() function to create an array filled with zeros: b = np . zeros (( 2 , 3 )) - Using the numpy.ones() function to create an array filled with ones: c = np . ones (( 2 , 3 )) Using the numpy.random.randint(): Returns an array of random integers between the two given numbers d = np . random . randint ( 0 , 10 ) - Using the numpy.random.rand() function to create an array of random values: e = np . random . rand ( 2 , 3 )","title":"Creating NumPy Arrays"},{"location":"numpy/#numpy-array-dimensions","text":"A dimension in arrays is one level of array depth (nested arrays). nested array: are arrays that have arrays as their elements. 0-D Arrays 1-D Arrays 2-D Arrays 3-D Arrays. 0-D arrays, or Scalars, are the elements in an array. Each value in an array is a 0-D array. Code Example: arr = np . array ( 30 ) print ( arr ) An array that has 0-D arrays as its elements is called a uni-dimensional or 1-D array. These are the most common types of arrays. Code Example : arr = np . array ([ 30 , 35 , 38 , 40 , 46 , 52 ]) print ( arr ) An array that has 1-D arrays as its elements is called a 2-D array. These are often used to represent matrix or 2nd order tensors. Code Example : arr = np . array ([[ 30 , 35 , 38 , 40 , 46 , 52 ],[ 22 , 28 , 39 , 42 , 49 , 52 ]]) print ( arr ) An array that has 2-D arrays (matrices) as its elements is called 3-D array. These are often used to represent a 3rd order tensor. Code Example : arr = np . array ([[[ 30 , 35 , 38 , 40 , 46 , 52 ],[ 22 , 28 , 39 , 42 , 49 , 52 ], [ 71 , 24 , 88 , 64 , 31 , 94 ]]]) print ( arr ) NumPy Arrays provides the ndim attribute that returns an integer that tells us how many dimensions the array has. Code Example : arr = np . array ([[[ 30 , 35 , 38 , 40 , 46 , 52 ],[ 22 , 28 , 39 , 42 , 49 , 52 ], [ 71 , 24 , 88 , 64 , 31 , 94 ]]]) print ( arr . ndim ) An array can have any number of dimensions. When the array is created, you can define the number of dimensions by using the ndim argument. Code Example : arr = np . array ([ 1 , 2 , 3 , 4 ], ndmin = 6 ) print ( arr . ndim ) print ( \u201c Number of dimensions : \u201d , arr . ndim )","title":"NumPy Array Dimensions"},{"location":"numpy/#arrays-type-and-shape","text":"NumPy Array Data Type :The NumPy array object has a property called dtype that returns the data type of the array. Code Example : arr = np . array ([ 1 , 2 , 3 , 4 , 5 ]) print ( arr . dtype ) NumPy Array Shape : The shape of an array is the number of elements in each dimension. NumPy arrays have an attribute called shape that returns a tuple with each index having the number of corresponding elements Code example : arr = np . array ([ 1 , 2 , 3 , 4 , 5 , 6 ]) print ( arr . shape )","title":"Arrays type and shape"},{"location":"numpy/#numpy-array-indexing","text":"Array indexing is the same as accessing an array element. You can access an array element by referring to its index number. The indexes in NumPy arrays start with 0, meaning that the first element has index 0, and the second has index 1 etc. Code Example : arr = np . array ([ 1 , 2 , 3 , 4 ]) print ( arr [ 0 ]) To access elements from 2-D arrays we can use comma separated integers representing the dimension and the index of the element. Code Example : arr = np . array ([[ 1 , 2 , 3 , 4 ],[ 4 , 3 , 2 , 1 ]]) print ( arr [ 0 ][ 1 ]) To access elements from 3-D arrays we can use comma separated integers representing the dimensions and the index of the element. Code Example : arr = np . array ([ 1 , 2 , 3 , 4 ],[ 4 , 3 , 2 , 1 ],[ 8 , 6 , 7 , 9 ]) print ( arr [ 0 ][ 1 ][ 0 ]) Use negative indexing to access an array from the end Code Example arr = np . array ([ 1 , 2 , 3 , 4 ],[ 4 , 3 , 2 , 1 ],[ 8 , 6 , 7 , 9 ]) print ( arr [ 0 ][ - 1 ][ - 2 ])","title":"NumPy Array Indexing"},{"location":"numpy/#numpy-array-slicing","text":"Slicing in python means taking elements from one given index to another given index. We pass slice instead of index like this [start: end]. We can also define the step, like this [start:end:step]. If we don't pass start its considered 0 If we don't pass end its considered length of array in that dimension If we don't pass step its considered 1 Note: The result includes the start index, but excludes the end index. Use the minus operator to refer to an index from the end. Code Example : arr = np . array ([ 1 , 2 , 3 , 4 , 5 ]) print ( arr [ 0 : 5 ]) #slice arrays from index 0 to 5 excluding 5 print (arr[:4]) #slice from beginning to 4 excluding 4 print ( arr [ 2 :]) #slice from index 2 onwards print ( arr [: - 3 ]) #slice from index -3 Code Example : arr = np . array ([ 1 , 2 , 3 , 4 , 5 ]) print ( arr [: 4 : 1 ]) #slice from beginning to 4 step of 1 print (arr[0::3]) #slice from index 0 onwards step of 3 print (arr[:-1:2]) #slice from index -1 step of 2","title":"NumPy Array Slicing"},{"location":"numpy/#array-operations-in-numpy","text":"Element-wise Operations : NumPy allows you to perform element-wise operations on arrays. Here are some examples: a = np . array ([ 1 , 2 , 3 ]) b = np . array ([ 4 , 5 , 6 ]) # Element-wise addition c = a + b print ( c ) # Output: [5 7 9] # Element-wise multiplication d = a * b print ( d ) # Output: [ 4 10 18] Matrix Multiplication : NumPy allows you to perform matrix multiplication using the numpy.dot() function. Here is an example: a = np . array ([[ 1 , 2 ], [ 3 , 4 ]]) b = np . array ([[ 5 , 6 ], [ 7 , 8 ]]) # Matrix multiplication c = np . dot ( a , b ) print ( c ) NumPy Array Reshaping : Reshaping means changing the shape of an array. The shape of an array is the number of elements in each dimension. By reshaping we can add or remove dimensions or change number of elements in each dimension. Code Example : # we can do it this way arr = np . array ([ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ]) arr2 = arr . reshape ( 5 , 2 ) print ( arr ) print ( arr2 ) # or this way a = np . array ([ 1 , 2 , 3 , 4 , 5 , 6 ]) b = np . reshape ( a , ( 2 , 3 )) print ( a ) print ( b ) Transposing Arrays : NumPy provides a way to transpose arrays using the numpy.transpose() function. Here is an example: a = np . array ([[ 1 , 2 ], [ 3 , 4 ], [ 5 , 6 ]]) b = np . transpose ( a ) print ( b ) Aggregation Functions : NumPy provides several aggregation functions that can be used to compute statistics on arrays. Here are some examples: a = np . array ([ 1 , 2 , 3 , 4 , 5 ]) # Computing the sum of the elements in the array print ( np . sum ( a )) # Output: 15 # Computing the mean of the elements in the array print ( np . mean ( a )) # Output: 3.0 # Computing the standard deviation of the elements in the array print ( np . std ( a )) # Output: 1.41421356","title":"Array Operations in NumPy"},{"location":"numpy/#numpy-array-copy-and-view","text":"The main difference between a copy and a view of an array is that the copy is a new array, and the view is just a view, or link to, the original array. The copy owns the data and any changes made to the copy will not affect original array, and any changes made to the original array will not affect the copy. The view does not own the data and any changes made to the view will affect the original array, and any changes made to the original array will affect the view. As mentioned, copies owns the data, and views does not own the data, so how can we check if it owns the data or not? Every NumPy array has the attribute base that returns None if the array owns the data. Otherwise, the base attribute refers to the original object Code example : import numpy as np arr = np . array ([ 1 , 2 , 3 , 4 , 5 , 6 ]) arrview = arr . view () #creates a view of the array arrcopy=arr.copy() #creates a copy of the array print ( arrview . base ) #check if the array owns its data print (arrcopy.base) #check if the array owns its data (should output none) Documentations NumPy","title":"NumPy Array Copy and View"},{"location":"oop/","text":"Introduction In the last chapter we learnt the basics of programming, you were shown how to store data in data structures such as lists, strings, integers, dictionaries, and others. And you were shown how to create behavior for your program using keywords, and later using functions to group these keywords. This coding approache is called Logic Programming. However, there are different approaches or perspectives in computer programming which we call programming paradigms. They provide various ways of organizing and structuring code to solve a particular problem. Each paradigm has its own strengths, weaknesses, and suitability for different types of problems and use cases. Some programming languages may support multiple paradigms, while others may have limited support for one specific paradigm. In this course we will get to know the object-oriented programming (OOP), a programming paradigm widely used in Python. PS: At this stage of the course, we assume that you know the basics of Python. Object-oriented programming (OOP) What is it ? Object-oriented programming (OOP) is an approach that organizes software design based on objects, which are data fields with unique attributes and behaviors, instead of functions and logic. Why we use it ? One of the main benefits of OOP is its organization, which makes it easier for developers to collaborate on a project by dividing it into smaller groups. Additionally, OOP offers several other advantages, such as code reusability, scalability, and efficiency. OOP Basic Concepts Class : A class is a blueprint for creating objects. It defines a set of attributes (properties) and methods (functions) that the objects created from the class will have. For example, you could create a \"Person\" class with attributes like name, age, and address, and methods like \"introduce\" and \"greet\". Object : An object is an instance of a class. When you create an object from a class, you get a specific \"realization\" of the class, with its own set of attributes and methods. For example, you could create two \"Person\" objects, \"John\" and \"Jane\", each with their own name, age, and address. Attributes : Attributes are the properties or characteristics of an object. They define the state of the object. In the example of the \"Person\" class, the attributes would be name, age, and address. Methods : Methods are the actions or behaviors of an object. They define what the object can do. In the example of the \"Person\" class, the methods would be \"introduce\" and \"greet\". Here is a simple example of a Python class that defines a \"Person\" object: class Person : def __init__ ( self , name , age , address ): self . name = name self . age = age self . address = address def introduce ( self ): return f \"Hi, my name is { self . name } and I am { self . age } years old.\" def greet ( self , other_person ): return f \"Hello { other_person . name } , it's nice to meet you!\" And here is how you can create objects from the \"Person\" class and use their attributes and methods: john = Person ( \"John\" , 30 , \"123 Main St.\" ) jane = Person ( \"Jane\" , 25 , \"456 Elm St.\" ) print ( john . introduce ()) # Output: Hi, my name is John and I am 30 years old. print ( jane . greet ( john )) # Output: Hello John, it's nice to meet you! When to use it ? Modeling real-world objects : You can create classes to model real-world objects in Python, such as dogs, cars, or books. For example, you can create a \"Dog\" class with properties like breed, name, and age, and methods like \"bark\", \"eat\", and \"sleep\". This makes it easier to manipulate and work with instances of the class, and to keep track of the state of each object. Building games : OOP is often used in game development to model game objects and their behaviors. For example, you can create a \"Player\" class to represent a player in a game, with properties like position, health, and score, and methods like \"move\", \"attack\", and \"jump\". Database applications : You can use OOP to interact with databases in Python. For example, you can create a \"Record\" class to represent a record in a database table, with properties like id, name, and date, and methods like \"insert\", \"update\", and \"delete\". Web development : OOP is commonly used in web development to build applications and services. For example, you can create a \"User\" class to represent a user of your application, with properties like name, email, and password, and methods like \"register\", \"login\", and \"logout\". Scientific simulations : OOP can be used to create scientific simulations, such as physical simulations or financial models. For example, you can create a \"Particle\" class to represent a particle in a physical simulation, with properties like position, velocity, and mass, and methods like \"move\", \"collide\", and \"absorb\". These are just a few examples of how OOP can be used in Python. With its powerful and flexible object-oriented features, OOP is a widely used paradigm in Python and can be applied to many different types of projects. Some examples Car : Create a class Car that represents a car. The class should have properties brand, model, and year, and a method drive that makes the car drive (print \"Driving the car !\"). ## Class implementation class Car : def __init__ ( self , brand , model , year ): self . brand = brand self . model = model self . year = year def drive ( self ): print ( \"Driving the car !\" ) ## Object declaration car = Car ( \"Toyota\" , \"Camry\" , 2020 ) print ( car . drive ()) # Output: Driving the car ! Dog : Create a class Dog that represents a dog. The class should have properties name, breed, and age, and a method bark that makes the dog bark (print \"Woof!\"). ## Class implementation class Dog : def __init__ ( self , name , breed , age ): self . name = name self . breed = breed self . age = age def bark ( self ): print ( \"Woof!\" ) ## Object declaration dog = Dog ( \"Max\" , \"Labrador\" , 5 ) print ( dog . bark ()) # Output: Woof! Let's code ! Operator overloading Operator overloading allows objects of user-defined classes to behave like built-in data types. This means that you can use familiar syntax for objects of your classes, making your code more intuitive and easier to read. For example, consider a class for a 2D point: class Point2D : def __init__ ( self , x , y ): self . x = x self . y = y def __str__ ( self ): return f \"( { self . x } , { self . y } )\" This class defines a 2D point, with x and y coordinates. You can create instances of the class and display them: p1 = Point2D ( 1 , 2 ) print ( p1 ) # Output: (1, 2) Now, if you want to add two points, you can overload the addition operator + by defining the __add__ method: class Point2D : def __init__ ( self , x , y ): self . x = x self . y = y def __str__ ( self ): return f \"( { self . x } , { self . y } )\" def __add__ ( self , other ): return Point2D ( self . x + other . x , self . y + other . y ) With this change, you can now add two points: p1 = Point2D ( 1 , 2 ) p2 = Point2D ( 3 , 4 ) p3 = p1 + p2 print ( p3 ) # Output: (4, 6) In this example, the __add__ method takes another Point2D object as its argument and returns a new Point2D object that represents the sum of the two points. This allows you to use the + operator with instances of your class, just like you would with built-in data types. You can also overload other operators, such as -, *, /, <, >, and so on, by defining the corresponding special methods, such as __sub__, __mul__, __truediv__, __lt__, __gt__, and so on. Here's an example that overloads the subtraction operator: class Point2D : def __init__ ( self , x , y ): self . x = x self . y = y def __str__ ( self ): return f \"( { self . x } , { self . y } )\" def __add__ ( self , other ): return Point2D ( self . x + other . x , self . y + other . y ) def __sub__ ( self , other ): return Point2D ( self . x - other . x , self . y - other . y ) With this change, you can now subtract two points: p1 = Point2D ( 1 , 2 ) p2 = Point2D ( 3 , 4 ) p3 = p1 - p2 print ( p3 ) # Output: (-2, -2) Cheat sheet for Class Special Methods: Operator Method String representation __str__ Addition (+) __add__ Subtraction (-) __sub__ Multiplication (*) __mul__ Power (**) __pow__ Division (/) __truediv__ Floor Division (//) __floordiv__ Remainder (modulo)(%) __mod__ Lesser than (<) __lt__ Greater than (>) __gt__ Lesser than or equal (<=) __le__ Greater than or equal (>=) __ge__ Equal (==) __eq__ Not equal (!=) __ne__ Absolute value (abs()) __abs__ Bitwise AND(&) __and__ Bitwise OR (|) __or__ Bitwise NOT(~) __invert__ Inheritance in Object-Oriented Programming What is it ? Inheritance is a mechanism in Object-Oriented Programming (OOP) that allows a new class to be defined based on an existing class. The new class, known as the subclass, inherits attributes and behavior from the existing class, known as the superclass. This enables code reuse, allowing new classes to be defined with little or no modifications to the existing classes. For example, consider a superclass called Animal which has attributes such as name, species, and age, and a method called make_sound() that returns the sound the animal makes. We can create a subclass of Animal called Dog which inherits all of the attributes and behavior of the Animal class. We can also add additional attributes specific to dogs such as breed and override the make_sound() method to return the specific sound a dog makes, like \"bark\". class Animal : def __init__ ( self , name , species , age ): self . name = name self . species = species self . age = age def make_sound ( self ): return \"Sound made by the animal\" class Dog ( Animal ): def __init__ ( self , name , breed , age ): Animal . __init__ ( self , name , \"Dog\" , age ) self . breed = breed def make_sound ( self ): return \"Bark\" dog = Dog ( \"Rufus\" , \"Labrador\" , 5 ) print ( dog . name ) # Rufus print ( dog . species ) # Dog print ( dog . age ) # 5 print ( dog . breed ) # Labrador print ( dog . make_sound ()) # Bark In this example, the Dog class inherits the attributes name, species, and age from the Animal class and also adds an additional attribute breed. The method make_sound() is also overridden in the Dog class to return a specific sound for dogs. Inheritance provides a way to model relationships between classes, and is an important concept in OOP for code reuse and organization. In Python, inheritance is an is-a relationship. That is, we use inheritance only if there exists an is-a relationship between two classes. For example, Car is a Vehicle Student is a Person Cat is an Animal Here, Car can inherit from Vehicle, Apple can Student from Person, and so on. Polymorphism and Abstraction Polymorphism : Is the ability of an object to take on multiple forms. It allows objects of different classes to be treated as objects of the same class. This means that you can write a single function or method that can work with objects of different classes, as long as they implement the same interface. Abstraction : Is a technique that allows you to simplify complex systems by ignoring irrelevant details and focusing on the essential features of an object. It is achieved by defining an interface that exposes the essential features of an object, while hiding the implementation details. Here's an example in Python to demonstrate the difference between polymorphism and abstraction: from abc import ABC , abstractmethod class Shape ( ABC ): @abstractmethod def area ( self ): pass class Rectangle ( Shape ): def __init__ ( self , width , height ): self . width = width self . height = height def area ( self ): return self . width * self . height class Circle ( Shape ): def __init__ ( self , radius ): self . radius = radius def area ( self ): return 3.14 * self . radius * self . radius def print_area ( shape ): print ( shape . area ()) rect = Rectangle ( 10 , 20 ) circ = Circle ( 5 ) print_area ( rect ) # 200 print_area ( circ ) # 78.5 In this example, the Shape class serves as an abstract class and defines an abstract method area. The Rectangle and Circle classes inherit from Shape and provide their own implementation of the area method. This demonstrates polymorphism, as objects of different classes (Rectangle and Circle) can be treated as objects of the same class (Shape). The print_area function demonstrates polymorphism, as it can accept objects of different classes (Rectangle and Circle) as long as they implement the same interface (area method). At the same time, the Shape class demonstrates abstraction by defining an interface that exposes the essential features of a shape, while hiding the implementation details. The Rectangle and Circle classes implement the area method, but the details of the implementation are hidden from the user. The user only sees the essential features of the object (the area method). Multiple and Multilevel Inheritance Multiple Inheritance : is a feature of Object Oriented Programming (OOP) languages where a class can inherit properties and attributes from more than one parent class. This means that a single class can have multiple base classes and it can inherit properties and attributes from all of them. For example, consider a scenario where you have two classes: Shape and Color. The class Shape defines the properties of a 2-D shape such as its area, perimeter, etc. The class Color defines the color of an object. Now, you want to create a new class Rectangle which is a shape and has a color. You can achieve this by using multiple inheritance. Here's an example implementation in Python: class Shape : def __init__ ( self , width , height ): self . width = width self . height = height def area ( self ): return self . width * self . height def perimeter ( self ): return 2 * ( self . width + self . height ) class Color : def __init__ ( self , color ): self . color = color class Rectangle ( Shape , Color ): pass rect = Rectangle ( 10 , 20 , 'red' ) print ( rect . area ()) print ( rect . perimeter ()) print ( rect . color ) In this example, the class Rectangle inherits from both Shape and Color classes. This means that it has all the attributes and methods defined in both the classes. Multilevel Inheritance : is a type of inheritance where a class inherits properties and attributes from its parent class, and the parent class inherits from its parent class, and so on. For example, consider a scenario where you have a class Animal which defines basic properties of an animal such as its name, age, and breed. Another class Mammal inherits from Animal class and adds new properties such as type of fur, etc. Finally, a new class Cat is created which inherits from Mammal class and adds new properties specific to cats such as the type of meow, etc. Here's an example implementation in Python: class Animal : def __init__ ( self , name , age , breed ): self . name = name self . age = age self . breed = breed class Mammal ( Animal ): def __init__ ( self , name , age , breed , fur_type ): Animal . __init__ ( self , name , age , breed ) self . fur_type = fur_type class Cat ( Mammal ): def __init__ ( self , name , age , breed , fur_type , meow_type ): Mammal . __init__ ( self , name , age , breed , fur_type ) self . meow_type = meow_type cat = Cat ( 'Tom' , 3 , 'Siamese' , 'short hair' , 'loud' ) print ( cat . name ) print ( cat . age ) print ( cat . breed ) print ( cat . fur_type ) print ( cat . meow_type ) In this example, the class Cat inherits from the class Mammal which in turn inherits from the class Animal. This creates a hierarchy of classes where each class inherits properties and attributes from its parent class.","title":"Object Oriented Programming in Python"},{"location":"oop/#introduction","text":"In the last chapter we learnt the basics of programming, you were shown how to store data in data structures such as lists, strings, integers, dictionaries, and others. And you were shown how to create behavior for your program using keywords, and later using functions to group these keywords. This coding approache is called Logic Programming. However, there are different approaches or perspectives in computer programming which we call programming paradigms. They provide various ways of organizing and structuring code to solve a particular problem. Each paradigm has its own strengths, weaknesses, and suitability for different types of problems and use cases. Some programming languages may support multiple paradigms, while others may have limited support for one specific paradigm. In this course we will get to know the object-oriented programming (OOP), a programming paradigm widely used in Python. PS: At this stage of the course, we assume that you know the basics of Python.","title":"Introduction"},{"location":"oop/#object-oriented-programming-oop","text":"","title":"Object-oriented programming (OOP)"},{"location":"oop/#what-is-it","text":"Object-oriented programming (OOP) is an approach that organizes software design based on objects, which are data fields with unique attributes and behaviors, instead of functions and logic.","title":"What is it ?"},{"location":"oop/#why-we-use-it","text":"One of the main benefits of OOP is its organization, which makes it easier for developers to collaborate on a project by dividing it into smaller groups. Additionally, OOP offers several other advantages, such as code reusability, scalability, and efficiency.","title":"Why we use it ?"},{"location":"oop/#oop-basic-concepts","text":"Class : A class is a blueprint for creating objects. It defines a set of attributes (properties) and methods (functions) that the objects created from the class will have. For example, you could create a \"Person\" class with attributes like name, age, and address, and methods like \"introduce\" and \"greet\". Object : An object is an instance of a class. When you create an object from a class, you get a specific \"realization\" of the class, with its own set of attributes and methods. For example, you could create two \"Person\" objects, \"John\" and \"Jane\", each with their own name, age, and address. Attributes : Attributes are the properties or characteristics of an object. They define the state of the object. In the example of the \"Person\" class, the attributes would be name, age, and address. Methods : Methods are the actions or behaviors of an object. They define what the object can do. In the example of the \"Person\" class, the methods would be \"introduce\" and \"greet\". Here is a simple example of a Python class that defines a \"Person\" object: class Person : def __init__ ( self , name , age , address ): self . name = name self . age = age self . address = address def introduce ( self ): return f \"Hi, my name is { self . name } and I am { self . age } years old.\" def greet ( self , other_person ): return f \"Hello { other_person . name } , it's nice to meet you!\" And here is how you can create objects from the \"Person\" class and use their attributes and methods: john = Person ( \"John\" , 30 , \"123 Main St.\" ) jane = Person ( \"Jane\" , 25 , \"456 Elm St.\" ) print ( john . introduce ()) # Output: Hi, my name is John and I am 30 years old. print ( jane . greet ( john )) # Output: Hello John, it's nice to meet you!","title":"OOP Basic Concepts"},{"location":"oop/#when-to-use-it","text":"Modeling real-world objects : You can create classes to model real-world objects in Python, such as dogs, cars, or books. For example, you can create a \"Dog\" class with properties like breed, name, and age, and methods like \"bark\", \"eat\", and \"sleep\". This makes it easier to manipulate and work with instances of the class, and to keep track of the state of each object. Building games : OOP is often used in game development to model game objects and their behaviors. For example, you can create a \"Player\" class to represent a player in a game, with properties like position, health, and score, and methods like \"move\", \"attack\", and \"jump\". Database applications : You can use OOP to interact with databases in Python. For example, you can create a \"Record\" class to represent a record in a database table, with properties like id, name, and date, and methods like \"insert\", \"update\", and \"delete\". Web development : OOP is commonly used in web development to build applications and services. For example, you can create a \"User\" class to represent a user of your application, with properties like name, email, and password, and methods like \"register\", \"login\", and \"logout\". Scientific simulations : OOP can be used to create scientific simulations, such as physical simulations or financial models. For example, you can create a \"Particle\" class to represent a particle in a physical simulation, with properties like position, velocity, and mass, and methods like \"move\", \"collide\", and \"absorb\". These are just a few examples of how OOP can be used in Python. With its powerful and flexible object-oriented features, OOP is a widely used paradigm in Python and can be applied to many different types of projects.","title":"When to use it ?"},{"location":"oop/#some-examples","text":"Car : Create a class Car that represents a car. The class should have properties brand, model, and year, and a method drive that makes the car drive (print \"Driving the car !\"). ## Class implementation class Car : def __init__ ( self , brand , model , year ): self . brand = brand self . model = model self . year = year def drive ( self ): print ( \"Driving the car !\" ) ## Object declaration car = Car ( \"Toyota\" , \"Camry\" , 2020 ) print ( car . drive ()) # Output: Driving the car ! Dog : Create a class Dog that represents a dog. The class should have properties name, breed, and age, and a method bark that makes the dog bark (print \"Woof!\"). ## Class implementation class Dog : def __init__ ( self , name , breed , age ): self . name = name self . breed = breed self . age = age def bark ( self ): print ( \"Woof!\" ) ## Object declaration dog = Dog ( \"Max\" , \"Labrador\" , 5 ) print ( dog . bark ()) # Output: Woof! Let's code !","title":"Some examples"},{"location":"oop/#operator-overloading","text":"Operator overloading allows objects of user-defined classes to behave like built-in data types. This means that you can use familiar syntax for objects of your classes, making your code more intuitive and easier to read. For example, consider a class for a 2D point: class Point2D : def __init__ ( self , x , y ): self . x = x self . y = y def __str__ ( self ): return f \"( { self . x } , { self . y } )\" This class defines a 2D point, with x and y coordinates. You can create instances of the class and display them: p1 = Point2D ( 1 , 2 ) print ( p1 ) # Output: (1, 2) Now, if you want to add two points, you can overload the addition operator + by defining the __add__ method: class Point2D : def __init__ ( self , x , y ): self . x = x self . y = y def __str__ ( self ): return f \"( { self . x } , { self . y } )\" def __add__ ( self , other ): return Point2D ( self . x + other . x , self . y + other . y ) With this change, you can now add two points: p1 = Point2D ( 1 , 2 ) p2 = Point2D ( 3 , 4 ) p3 = p1 + p2 print ( p3 ) # Output: (4, 6) In this example, the __add__ method takes another Point2D object as its argument and returns a new Point2D object that represents the sum of the two points. This allows you to use the + operator with instances of your class, just like you would with built-in data types. You can also overload other operators, such as -, *, /, <, >, and so on, by defining the corresponding special methods, such as __sub__, __mul__, __truediv__, __lt__, __gt__, and so on. Here's an example that overloads the subtraction operator: class Point2D : def __init__ ( self , x , y ): self . x = x self . y = y def __str__ ( self ): return f \"( { self . x } , { self . y } )\" def __add__ ( self , other ): return Point2D ( self . x + other . x , self . y + other . y ) def __sub__ ( self , other ): return Point2D ( self . x - other . x , self . y - other . y ) With this change, you can now subtract two points: p1 = Point2D ( 1 , 2 ) p2 = Point2D ( 3 , 4 ) p3 = p1 - p2 print ( p3 ) # Output: (-2, -2)","title":"Operator overloading"},{"location":"oop/#cheat-sheet-for-class-special-methods","text":"Operator Method String representation __str__ Addition (+) __add__ Subtraction (-) __sub__ Multiplication (*) __mul__ Power (**) __pow__ Division (/) __truediv__ Floor Division (//) __floordiv__ Remainder (modulo)(%) __mod__ Lesser than (<) __lt__ Greater than (>) __gt__ Lesser than or equal (<=) __le__ Greater than or equal (>=) __ge__ Equal (==) __eq__ Not equal (!=) __ne__ Absolute value (abs()) __abs__ Bitwise AND(&) __and__ Bitwise OR (|) __or__ Bitwise NOT(~) __invert__","title":"Cheat sheet for Class Special Methods:"},{"location":"oop/#inheritance-in-object-oriented-programming","text":"","title":"Inheritance in Object-Oriented Programming"},{"location":"oop/#what-is-it_1","text":"Inheritance is a mechanism in Object-Oriented Programming (OOP) that allows a new class to be defined based on an existing class. The new class, known as the subclass, inherits attributes and behavior from the existing class, known as the superclass. This enables code reuse, allowing new classes to be defined with little or no modifications to the existing classes. For example, consider a superclass called Animal which has attributes such as name, species, and age, and a method called make_sound() that returns the sound the animal makes. We can create a subclass of Animal called Dog which inherits all of the attributes and behavior of the Animal class. We can also add additional attributes specific to dogs such as breed and override the make_sound() method to return the specific sound a dog makes, like \"bark\". class Animal : def __init__ ( self , name , species , age ): self . name = name self . species = species self . age = age def make_sound ( self ): return \"Sound made by the animal\" class Dog ( Animal ): def __init__ ( self , name , breed , age ): Animal . __init__ ( self , name , \"Dog\" , age ) self . breed = breed def make_sound ( self ): return \"Bark\" dog = Dog ( \"Rufus\" , \"Labrador\" , 5 ) print ( dog . name ) # Rufus print ( dog . species ) # Dog print ( dog . age ) # 5 print ( dog . breed ) # Labrador print ( dog . make_sound ()) # Bark In this example, the Dog class inherits the attributes name, species, and age from the Animal class and also adds an additional attribute breed. The method make_sound() is also overridden in the Dog class to return a specific sound for dogs. Inheritance provides a way to model relationships between classes, and is an important concept in OOP for code reuse and organization. In Python, inheritance is an is-a relationship. That is, we use inheritance only if there exists an is-a relationship between two classes. For example, Car is a Vehicle Student is a Person Cat is an Animal Here, Car can inherit from Vehicle, Apple can Student from Person, and so on.","title":"What is it ?"},{"location":"oop/#polymorphism-and-abstraction","text":"Polymorphism : Is the ability of an object to take on multiple forms. It allows objects of different classes to be treated as objects of the same class. This means that you can write a single function or method that can work with objects of different classes, as long as they implement the same interface. Abstraction : Is a technique that allows you to simplify complex systems by ignoring irrelevant details and focusing on the essential features of an object. It is achieved by defining an interface that exposes the essential features of an object, while hiding the implementation details. Here's an example in Python to demonstrate the difference between polymorphism and abstraction: from abc import ABC , abstractmethod class Shape ( ABC ): @abstractmethod def area ( self ): pass class Rectangle ( Shape ): def __init__ ( self , width , height ): self . width = width self . height = height def area ( self ): return self . width * self . height class Circle ( Shape ): def __init__ ( self , radius ): self . radius = radius def area ( self ): return 3.14 * self . radius * self . radius def print_area ( shape ): print ( shape . area ()) rect = Rectangle ( 10 , 20 ) circ = Circle ( 5 ) print_area ( rect ) # 200 print_area ( circ ) # 78.5 In this example, the Shape class serves as an abstract class and defines an abstract method area. The Rectangle and Circle classes inherit from Shape and provide their own implementation of the area method. This demonstrates polymorphism, as objects of different classes (Rectangle and Circle) can be treated as objects of the same class (Shape). The print_area function demonstrates polymorphism, as it can accept objects of different classes (Rectangle and Circle) as long as they implement the same interface (area method). At the same time, the Shape class demonstrates abstraction by defining an interface that exposes the essential features of a shape, while hiding the implementation details. The Rectangle and Circle classes implement the area method, but the details of the implementation are hidden from the user. The user only sees the essential features of the object (the area method).","title":"Polymorphism and Abstraction"},{"location":"oop/#multiple-and-multilevel-inheritance","text":"Multiple Inheritance : is a feature of Object Oriented Programming (OOP) languages where a class can inherit properties and attributes from more than one parent class. This means that a single class can have multiple base classes and it can inherit properties and attributes from all of them. For example, consider a scenario where you have two classes: Shape and Color. The class Shape defines the properties of a 2-D shape such as its area, perimeter, etc. The class Color defines the color of an object. Now, you want to create a new class Rectangle which is a shape and has a color. You can achieve this by using multiple inheritance. Here's an example implementation in Python: class Shape : def __init__ ( self , width , height ): self . width = width self . height = height def area ( self ): return self . width * self . height def perimeter ( self ): return 2 * ( self . width + self . height ) class Color : def __init__ ( self , color ): self . color = color class Rectangle ( Shape , Color ): pass rect = Rectangle ( 10 , 20 , 'red' ) print ( rect . area ()) print ( rect . perimeter ()) print ( rect . color ) In this example, the class Rectangle inherits from both Shape and Color classes. This means that it has all the attributes and methods defined in both the classes. Multilevel Inheritance : is a type of inheritance where a class inherits properties and attributes from its parent class, and the parent class inherits from its parent class, and so on. For example, consider a scenario where you have a class Animal which defines basic properties of an animal such as its name, age, and breed. Another class Mammal inherits from Animal class and adds new properties such as type of fur, etc. Finally, a new class Cat is created which inherits from Mammal class and adds new properties specific to cats such as the type of meow, etc. Here's an example implementation in Python: class Animal : def __init__ ( self , name , age , breed ): self . name = name self . age = age self . breed = breed class Mammal ( Animal ): def __init__ ( self , name , age , breed , fur_type ): Animal . __init__ ( self , name , age , breed ) self . fur_type = fur_type class Cat ( Mammal ): def __init__ ( self , name , age , breed , fur_type , meow_type ): Mammal . __init__ ( self , name , age , breed , fur_type ) self . meow_type = meow_type cat = Cat ( 'Tom' , 3 , 'Siamese' , 'short hair' , 'loud' ) print ( cat . name ) print ( cat . age ) print ( cat . breed ) print ( cat . fur_type ) print ( cat . meow_type ) In this example, the class Cat inherits from the class Mammal which in turn inherits from the class Animal. This creates a hierarchy of classes where each class inherits properties and attributes from its parent class.","title":"Multiple and Multilevel Inheritance"},{"location":"pd/","text":"Pandas Introduction to Pandas Pandas is a Python library used for working with data sets. It has functions for analyzing, cleaning, exploring, and manipulating data. Pandas allows us to : Analyze big data and make conclusions based on statistical theories. Clean messy data sets, and make them readable and relevant. Relevant data is very important in data science. Pandas gives you answers about the data Such as : Is there a correlation between two or more columns? What is the average value? Max value? Min value? Manage diffrent data sets merging them filtering them etc... Pandas is also able to delete rows that are not relevant, or contain wrong values, like empty or NULL values. This is called cleaning the data. To start using Pandas, you first need to install it. You can install it using the following command: ! pip install pandas After installing pandas, you can import it as follows: import pandas as pd Pandas Data Structures Pandas provides two main data structures: Series and DataFrame. A Series is a one-dimensional array-like object that can hold any data type. A DataFrame is a two-dimensional table that can hold data of different types in columns. Series A Pandas Series is like a column in a table. It is a one-dimensional array holding data of any type import pandas as pd dataset1 = [ 1 , 3 , 5 , np . nan , 6 , 8 ] df1 = pd . Series ( dataset1 ) print ( df1 ) If nothing else is specified, the values are labeled with their index number. The first value has index 0, etc. This label can be used to access a specified value. With the index argument, you can name your own labels. When using labels, you can access an item by using the label. Code example : import pandas as pd dataset1 = [ 1 , 3 , 5 , np . nan , 6 , 8 ] df1 = pd . Series ( dataset1 , index = [ \"a\" , \"b\" , \"c\" , \"e\" , \"f\" , \"g\" ]) print ( df1 ) print ( df1 [ \"a\" ]) We can also use key/value pair objects like dictionaries when creating a Series Note: The keys of the dictionary become the labels Code example : import pandas as pd dataset1 = { \"Vehicle number\" : 1 , \"Wheels\" : 4 , \"Doors\" : 4 } df1 = pd . Series ( dataset1 ) print ( df1 ) DataFrame Data sets in Pandas are usually multi-dimensional tables, called DataFrames. Series can be considered to be like a column in a table, whereas a DataFrame can be considered to be the table. A DataFrame can be created in several ways. One way is to pass a dictionary of lists to the pd.DataFrame() function. Each key in the dictionary represents a column name, and each list represents the data in that column. data = { 'name' : [ 'Alice' , 'Bob' , 'Charlie' , 'David' ], 'age' : [ 25 , 32 , 18 , 47 ], 'gender' : [ 'F' , 'M' , 'M' , 'M' ]} df = pd . DataFrame ( data ) print ( df ) We can use the loc attribute to locate one or more rows. Just as with series, we can name indexes of data frames and locate them using the loc attribute Code example : import pandas as pd dataset1 = { \"Vehicle number\" :[ 1 , 2 , 3 ], \"Wheels\" :[ 4 , 2 , 4 ], \"Doors\" :[ 4 , 0 , 5 ]} df1 = pd . DataFrame ( dataset1 , index = [ \"Car\" , \"Motorcycle\" , \"Van\" ]) print ( df1 ) print ( df1 . loc [ \"Car\" ]) Data Import and Export Pandas supports reading and writing data from and to various file formats, such as CSV, Excel, SQL databases, and more. CSV : A simple way to store big data sets is to use CSV (Comma Separated Value) files. CSV files contain plain text and are a well know format that can be read by almost all software including Pandas. To read a CSV file, you can use the pd.read_csv() function. The function takes the path to the CSV file as an argument and returns a DataFrame. To write a DataFrame to a CSV file, you can use the to_csv() method. Code example : import pandas as pd ## Importing a CSV file df = pd . read_csv ( 'data.csv' ) print ( df ) ## Export a CSV file df . to_csv ( 'data.csv' , index = False ) #The index=False argument tells Pandas not to write the row index to the CSV file. Excel : To read an Excel file, you can use the pd.read_excel() function. The function takes the path to the Excel file as an argument and returns a DataFrame. To write a DataFrame to an Excel file, you can use the to_excel() method. ## Importing a Excel file df = pd . read_excel ( 'data.xlsx' , sheet_name = 'Sheet1' ) print ( df ) ## Export a Excel file df . to_excel ( 'data.xlsx' , sheet_name = 'Sheet1' , index = False ) - SQL Databases : To read data from a SQL database, you can use the pd.read_sql() function. The function takes a SQL query and a connection object as arguments and returns a DataFrame. To write a DataFrame to a SQL database, you can use the to_sql() method. import sqlite3 ## Importing a SQL file conn = sqlite3 . connect ( 'mydatabase.db' ) query = 'SELECT * FROM mytable' df = pd . read_sql ( query , conn ) print ( df ) ## Export a SQL file df . to_sql ( 'mytable' , conn , if_exists = 'replace' , index = False ) #The if_exists='replace' argument tells Pandas to replace the table if it already exists in the database. Getting a quick overview of the Dataframes content One of the most used method for getting a quick overview of the DataFrame, is the head() method. The head() method returns the headers and a specified number of rows, starting from the top. The tail() method returns the last rows of the DataFrame The DataFrame object has a method called info(), that gives you more information about the data set. Code Example : import pandas as pd df = pd . read_csv ( \"data.csv\" ) print ( df . head ()) print ( df . tail ()) df . info () Data Cleaning with pandas Data cleaning means fixing bad data in your data set it is an essential step in data analysis. Pandas provides several functions and methods for cleaning and preparing data. Examples of bad data include : Empty cells Empty cells can potentially give you a wrong result when you analyze data. One way to deal with empty cells is to remove rows that contain empty cells. This usually works since data sets can be very large, and removing a few rows will not have a significant impact on the results. To detect empty cells we can use : df . isnull () . value_counts () To remove empty cells, we can use the dropna() method. By default, the dropna() method returns a new DataFrame, and will not change the original. If you want to change the original DataFrame, use the inplace = True argument. Code Example : import pandas as pd df = pd . read_csv ( \"data.csv\" ) print ( df ) df . dropna ( inplace = True ) print ( df ) Another way of dealing with empty cells is to insert a new value to replace the empty cell. This way you do not have to delete entire rows just because of some empty cells. The fillna() method allows us to replace empty cells with a value. To only replace empty values for one column, specify the column name for the DataFrame. Code Example : import pandas as pd df = pd . read_csv ( \"data.csv\" ) df . fillna ( 130 , inplace = True ) df [ \"Calories\" ] . fillna ( 130 , inplace = True ) print ( df . to_string ()) You can also fill in empty cells with the mean, median or mode of the column. Pandas uses the mean() median() and mode() methods to calculate the respective values for a specified column Mean : the mean is the average value (the sum of all values divided by number of values) Median : the median is the value in the middle, after you have sorted all values ascending Mode : the mode is the value that appears most frequently Code Example : import pandas as pd df = pd . read_csv ( \"data.csv\" ) meancal = df [ \"Calories\" ] . mean () mediancal = df [ \"Calories\" ] . median () modecal = df [ \"Calories\" ] . mode () print ( \"The mean of calories is\" + str ( meancal ) + \" The median of calories is \" + str ( mediancal ) + \" The mode of calories is \" + str ( modecal )) meandf = df [ \"Calories\" ] . fillna ( meancal ) mediandf = df [ \"Calories\" ] . fillna ( mediancal ) modedf = df [ \"Calories\" ] . fillna ( modecal ) print ( meandf . to_string ()) print ( mediandf . to_string ()) print ( modedf . to_string ()) Data in wrong format Cells with data of incorrect format can make it difficult, or even impossible, to analyze data. To remedy this, you can either remove the rows, or convert all cells in the columns into the same format Incorrect Data Incorrect data does not have to be empty cells or incorrect format, it can just be incorrect, like if someone entered 199 instead of 1.99. Sometimes you can spot incorrect data by looking at the data set because you have an expectation of what it should be. If you take a look at our data set you can see that in row 7 the duration is 450, but for all the other rows the duration is between 30 and 60. It doesn't have to be incorrect, but taking in consideration that this is the data set of someone's workout sessions, we conclude this person did not work out for 450 minutes One way to fix wrong values is to replace them with something else. For small data sets you might be able to replace the wrong data one by one, but not for large data sets. To replace wrong data for larger data sets you can create some rules and set some boundaries for legal values, and replace any values that are outside of the boundaries Another way of handling incorrect data is to remove the rows that contains incorrect data. This way you do not have to find out what to replace them with, and there is a good chance you do not need them for analysis. Code Example import pandas as pd df1 = pd . read_csv ( \"data.csv\" ) df2 = pd . read_csv ( \"data.csv\" ) for x in df1 . index : #replace all values in duration above 120 with 120 if df1 . loc [ x , \"Duration\" ] > 120 : df1 . loc [ x , \"Duration\" ] = 120 for y in df2 . index : #drop all values above 120 if df2 . loc [ y , \"Duration\" ] > 120 : df2 . drop ( y , inplace = True ) print ( dataframe1 . to_string ()) print ( dataframe2 . to_string ()) Wrong data Duplicates Duplicate rows are rows that have been entered more than once. By taking a look at our test data set, we can assume that row 11 and 12 are duplicates To discover duplicates, we can use the duplicated() method The duplicated() method returns a Boolean values for each row To remove duplicates, use the drop_duplicates() method. Code Example : import pandas as pd df1 = pd . read_csv ( \"data.csv\" ) df1 . duplicated () . value_counts () #search for duplicates and output true when found df1 . drop_duplicates ( inplace = True ) #drop all duplicates df1 Merging and Joining Data Pandas provides several functions and methods for merging and joining DataFrames. To merge two DataFrames based on a common column, you can use the merge() method. df1 = pd . DataFrame ({ 'id' : [ 1 , 2 , 3 , 4 ], 'name' : [ 'Alice' , 'Bob' , 'Charlie' , 'David' ]}) df2 = pd . DataFrame ({ 'id' : [ 1 , 2 , 3 , 4 ], 'age' : [ 25 , 32 , 18 , 47 ]}) merged_df = pd . merge ( df1 , df2 , on = 'id' ) # Merge DataFrames on 'id' column print ( merged_df ) The merge() method merges the two DataFrames based on the 'id' column. The result is a new DataFrame with columns from both DataFrames. To join two DataFrames based on a common column, you can use the join() method. df1 = pd . DataFrame ({ 'id' : [ 1 , 2 , 3 , 4 ], 'name' : [ 'Alice' , 'Bob' , 'Charlie' , 'David' ]}) df2 = pd . DataFrame ({ 'id' : [ 1 , 2 , 3 , 4 ], 'age' : [ 25 , 32 , 18 , 47 ]}) joined_df = df1 . set_index ( 'id' ) . join ( df2 . set_index ( 'id' )) # Join DataFrames on 'id' column print ( joined_df ) The join() method joins the two DataFrames based on the 'id' column. The result is a new DataFrame with columns from both DataFrames. Data Analysis in Pandas Describe in Pandas The describe() method in Pandas provides summary statistics of a DataFrame. It calculates several common statistics for each numerical column in the DataFrame, such as count, mean, standard deviation, minimum, maximum, and quartiles. Code Example : import pandas as pd df1 = pd . read_csv ( \"data.csv\" ) df1 . describe () Correlation in Pandas The corr() method calculates the relationship between each column in your data set. The corr() method ignores \"not numeric\" columns. Code Example : import pandas as pd df1 = pd . read_csv ( \"data.csv\" ) df1 . corr () The Result of the corr() method is a table with a lot of numbers that represents how well the relationship is between two columns. The number varies from -1 to 1 such as : 1 means that there is a 1 to 1 relationship (a perfect correlation), and for this data set, each time a value went up in the first column, the other one went up as well. 0.9 is also a good relationship, and if you increase one value, the other will probably increase as well. -0.9 would be just as good relationship as 0.9, but if you increase one value, the other will probably go down 0.2 means NOT a good relationship, meaning that if one value goes up does not mean that the other will What is a good correlation? It depends on the use, but I think it is safe to say you have to have at least 0.6 (or -0.6) to call it a good correlation Perfect Correlation : We can see that \"Duration\" and \"Duration\" got the number 1.000000, which makes sense, each column always has a perfect relationship with itself. Good Correlation : \"Duration\" and \"Calories\" got a 0.922721 correlation, which is a very good correlation, and we can predict that the longer you work out, the more calories you burn, and the other way around: if you burned a lot of calories, you probably had a long work out Bad Correlation : \"Duration\" and \"Maxpulse\" got a 0.009403 correlation, which is a very bad correlation, meaning that we can not predict the max pulse by just looking at the duration of the work out, and vice versa","title":"Understanding & working with Pandas"},{"location":"pd/#pandas","text":"","title":"Pandas"},{"location":"pd/#introduction-to-pandas","text":"Pandas is a Python library used for working with data sets. It has functions for analyzing, cleaning, exploring, and manipulating data. Pandas allows us to : Analyze big data and make conclusions based on statistical theories. Clean messy data sets, and make them readable and relevant. Relevant data is very important in data science. Pandas gives you answers about the data Such as : Is there a correlation between two or more columns? What is the average value? Max value? Min value? Manage diffrent data sets merging them filtering them etc... Pandas is also able to delete rows that are not relevant, or contain wrong values, like empty or NULL values. This is called cleaning the data. To start using Pandas, you first need to install it. You can install it using the following command: ! pip install pandas After installing pandas, you can import it as follows: import pandas as pd","title":"Introduction to Pandas"},{"location":"pd/#pandas-data-structures","text":"Pandas provides two main data structures: Series and DataFrame. A Series is a one-dimensional array-like object that can hold any data type. A DataFrame is a two-dimensional table that can hold data of different types in columns.","title":"Pandas Data Structures"},{"location":"pd/#series","text":"A Pandas Series is like a column in a table. It is a one-dimensional array holding data of any type import pandas as pd dataset1 = [ 1 , 3 , 5 , np . nan , 6 , 8 ] df1 = pd . Series ( dataset1 ) print ( df1 ) If nothing else is specified, the values are labeled with their index number. The first value has index 0, etc. This label can be used to access a specified value. With the index argument, you can name your own labels. When using labels, you can access an item by using the label. Code example : import pandas as pd dataset1 = [ 1 , 3 , 5 , np . nan , 6 , 8 ] df1 = pd . Series ( dataset1 , index = [ \"a\" , \"b\" , \"c\" , \"e\" , \"f\" , \"g\" ]) print ( df1 ) print ( df1 [ \"a\" ]) We can also use key/value pair objects like dictionaries when creating a Series Note: The keys of the dictionary become the labels Code example : import pandas as pd dataset1 = { \"Vehicle number\" : 1 , \"Wheels\" : 4 , \"Doors\" : 4 } df1 = pd . Series ( dataset1 ) print ( df1 )","title":"Series"},{"location":"pd/#dataframe","text":"Data sets in Pandas are usually multi-dimensional tables, called DataFrames. Series can be considered to be like a column in a table, whereas a DataFrame can be considered to be the table. A DataFrame can be created in several ways. One way is to pass a dictionary of lists to the pd.DataFrame() function. Each key in the dictionary represents a column name, and each list represents the data in that column. data = { 'name' : [ 'Alice' , 'Bob' , 'Charlie' , 'David' ], 'age' : [ 25 , 32 , 18 , 47 ], 'gender' : [ 'F' , 'M' , 'M' , 'M' ]} df = pd . DataFrame ( data ) print ( df ) We can use the loc attribute to locate one or more rows. Just as with series, we can name indexes of data frames and locate them using the loc attribute Code example : import pandas as pd dataset1 = { \"Vehicle number\" :[ 1 , 2 , 3 ], \"Wheels\" :[ 4 , 2 , 4 ], \"Doors\" :[ 4 , 0 , 5 ]} df1 = pd . DataFrame ( dataset1 , index = [ \"Car\" , \"Motorcycle\" , \"Van\" ]) print ( df1 ) print ( df1 . loc [ \"Car\" ])","title":"DataFrame"},{"location":"pd/#data-import-and-export","text":"Pandas supports reading and writing data from and to various file formats, such as CSV, Excel, SQL databases, and more. CSV : A simple way to store big data sets is to use CSV (Comma Separated Value) files. CSV files contain plain text and are a well know format that can be read by almost all software including Pandas. To read a CSV file, you can use the pd.read_csv() function. The function takes the path to the CSV file as an argument and returns a DataFrame. To write a DataFrame to a CSV file, you can use the to_csv() method. Code example : import pandas as pd ## Importing a CSV file df = pd . read_csv ( 'data.csv' ) print ( df ) ## Export a CSV file df . to_csv ( 'data.csv' , index = False ) #The index=False argument tells Pandas not to write the row index to the CSV file. Excel : To read an Excel file, you can use the pd.read_excel() function. The function takes the path to the Excel file as an argument and returns a DataFrame. To write a DataFrame to an Excel file, you can use the to_excel() method. ## Importing a Excel file df = pd . read_excel ( 'data.xlsx' , sheet_name = 'Sheet1' ) print ( df ) ## Export a Excel file df . to_excel ( 'data.xlsx' , sheet_name = 'Sheet1' , index = False ) - SQL Databases : To read data from a SQL database, you can use the pd.read_sql() function. The function takes a SQL query and a connection object as arguments and returns a DataFrame. To write a DataFrame to a SQL database, you can use the to_sql() method. import sqlite3 ## Importing a SQL file conn = sqlite3 . connect ( 'mydatabase.db' ) query = 'SELECT * FROM mytable' df = pd . read_sql ( query , conn ) print ( df ) ## Export a SQL file df . to_sql ( 'mytable' , conn , if_exists = 'replace' , index = False ) #The if_exists='replace' argument tells Pandas to replace the table if it already exists in the database.","title":"Data Import and Export"},{"location":"pd/#getting-a-quick-overview-of-the-dataframes-content","text":"One of the most used method for getting a quick overview of the DataFrame, is the head() method. The head() method returns the headers and a specified number of rows, starting from the top. The tail() method returns the last rows of the DataFrame The DataFrame object has a method called info(), that gives you more information about the data set. Code Example : import pandas as pd df = pd . read_csv ( \"data.csv\" ) print ( df . head ()) print ( df . tail ()) df . info ()","title":"Getting a quick overview of the Dataframes content"},{"location":"pd/#data-cleaning-with-pandas","text":"Data cleaning means fixing bad data in your data set it is an essential step in data analysis. Pandas provides several functions and methods for cleaning and preparing data. Examples of bad data include :","title":"Data Cleaning with pandas"},{"location":"pd/#empty-cells","text":"Empty cells can potentially give you a wrong result when you analyze data. One way to deal with empty cells is to remove rows that contain empty cells. This usually works since data sets can be very large, and removing a few rows will not have a significant impact on the results. To detect empty cells we can use : df . isnull () . value_counts () To remove empty cells, we can use the dropna() method. By default, the dropna() method returns a new DataFrame, and will not change the original. If you want to change the original DataFrame, use the inplace = True argument. Code Example : import pandas as pd df = pd . read_csv ( \"data.csv\" ) print ( df ) df . dropna ( inplace = True ) print ( df ) Another way of dealing with empty cells is to insert a new value to replace the empty cell. This way you do not have to delete entire rows just because of some empty cells. The fillna() method allows us to replace empty cells with a value. To only replace empty values for one column, specify the column name for the DataFrame. Code Example : import pandas as pd df = pd . read_csv ( \"data.csv\" ) df . fillna ( 130 , inplace = True ) df [ \"Calories\" ] . fillna ( 130 , inplace = True ) print ( df . to_string ()) You can also fill in empty cells with the mean, median or mode of the column. Pandas uses the mean() median() and mode() methods to calculate the respective values for a specified column Mean : the mean is the average value (the sum of all values divided by number of values) Median : the median is the value in the middle, after you have sorted all values ascending Mode : the mode is the value that appears most frequently Code Example : import pandas as pd df = pd . read_csv ( \"data.csv\" ) meancal = df [ \"Calories\" ] . mean () mediancal = df [ \"Calories\" ] . median () modecal = df [ \"Calories\" ] . mode () print ( \"The mean of calories is\" + str ( meancal ) + \" The median of calories is \" + str ( mediancal ) + \" The mode of calories is \" + str ( modecal )) meandf = df [ \"Calories\" ] . fillna ( meancal ) mediandf = df [ \"Calories\" ] . fillna ( mediancal ) modedf = df [ \"Calories\" ] . fillna ( modecal ) print ( meandf . to_string ()) print ( mediandf . to_string ()) print ( modedf . to_string ())","title":"Empty cells"},{"location":"pd/#data-in-wrong-format","text":"Cells with data of incorrect format can make it difficult, or even impossible, to analyze data. To remedy this, you can either remove the rows, or convert all cells in the columns into the same format","title":"Data in wrong format"},{"location":"pd/#incorrect-data","text":"Incorrect data does not have to be empty cells or incorrect format, it can just be incorrect, like if someone entered 199 instead of 1.99. Sometimes you can spot incorrect data by looking at the data set because you have an expectation of what it should be. If you take a look at our data set you can see that in row 7 the duration is 450, but for all the other rows the duration is between 30 and 60. It doesn't have to be incorrect, but taking in consideration that this is the data set of someone's workout sessions, we conclude this person did not work out for 450 minutes One way to fix wrong values is to replace them with something else. For small data sets you might be able to replace the wrong data one by one, but not for large data sets. To replace wrong data for larger data sets you can create some rules and set some boundaries for legal values, and replace any values that are outside of the boundaries Another way of handling incorrect data is to remove the rows that contains incorrect data. This way you do not have to find out what to replace them with, and there is a good chance you do not need them for analysis. Code Example import pandas as pd df1 = pd . read_csv ( \"data.csv\" ) df2 = pd . read_csv ( \"data.csv\" ) for x in df1 . index : #replace all values in duration above 120 with 120 if df1 . loc [ x , \"Duration\" ] > 120 : df1 . loc [ x , \"Duration\" ] = 120 for y in df2 . index : #drop all values above 120 if df2 . loc [ y , \"Duration\" ] > 120 : df2 . drop ( y , inplace = True ) print ( dataframe1 . to_string ()) print ( dataframe2 . to_string ())","title":"Incorrect Data"},{"location":"pd/#wrong-data-duplicates","text":"Duplicate rows are rows that have been entered more than once. By taking a look at our test data set, we can assume that row 11 and 12 are duplicates To discover duplicates, we can use the duplicated() method The duplicated() method returns a Boolean values for each row To remove duplicates, use the drop_duplicates() method. Code Example : import pandas as pd df1 = pd . read_csv ( \"data.csv\" ) df1 . duplicated () . value_counts () #search for duplicates and output true when found df1 . drop_duplicates ( inplace = True ) #drop all duplicates df1","title":"Wrong data Duplicates"},{"location":"pd/#merging-and-joining-data","text":"Pandas provides several functions and methods for merging and joining DataFrames. To merge two DataFrames based on a common column, you can use the merge() method. df1 = pd . DataFrame ({ 'id' : [ 1 , 2 , 3 , 4 ], 'name' : [ 'Alice' , 'Bob' , 'Charlie' , 'David' ]}) df2 = pd . DataFrame ({ 'id' : [ 1 , 2 , 3 , 4 ], 'age' : [ 25 , 32 , 18 , 47 ]}) merged_df = pd . merge ( df1 , df2 , on = 'id' ) # Merge DataFrames on 'id' column print ( merged_df ) The merge() method merges the two DataFrames based on the 'id' column. The result is a new DataFrame with columns from both DataFrames. To join two DataFrames based on a common column, you can use the join() method. df1 = pd . DataFrame ({ 'id' : [ 1 , 2 , 3 , 4 ], 'name' : [ 'Alice' , 'Bob' , 'Charlie' , 'David' ]}) df2 = pd . DataFrame ({ 'id' : [ 1 , 2 , 3 , 4 ], 'age' : [ 25 , 32 , 18 , 47 ]}) joined_df = df1 . set_index ( 'id' ) . join ( df2 . set_index ( 'id' )) # Join DataFrames on 'id' column print ( joined_df ) The join() method joins the two DataFrames based on the 'id' column. The result is a new DataFrame with columns from both DataFrames.","title":"Merging and Joining Data"},{"location":"pd/#data-analysis-in-pandas","text":"","title":"Data Analysis in Pandas"},{"location":"pd/#describe-in-pandas","text":"The describe() method in Pandas provides summary statistics of a DataFrame. It calculates several common statistics for each numerical column in the DataFrame, such as count, mean, standard deviation, minimum, maximum, and quartiles. Code Example : import pandas as pd df1 = pd . read_csv ( \"data.csv\" ) df1 . describe ()","title":"Describe in Pandas"},{"location":"pd/#correlation-in-pandas","text":"The corr() method calculates the relationship between each column in your data set. The corr() method ignores \"not numeric\" columns. Code Example : import pandas as pd df1 = pd . read_csv ( \"data.csv\" ) df1 . corr () The Result of the corr() method is a table with a lot of numbers that represents how well the relationship is between two columns. The number varies from -1 to 1 such as : 1 means that there is a 1 to 1 relationship (a perfect correlation), and for this data set, each time a value went up in the first column, the other one went up as well. 0.9 is also a good relationship, and if you increase one value, the other will probably increase as well. -0.9 would be just as good relationship as 0.9, but if you increase one value, the other will probably go down 0.2 means NOT a good relationship, meaning that if one value goes up does not mean that the other will What is a good correlation? It depends on the use, but I think it is safe to say you have to have at least 0.6 (or -0.6) to call it a good correlation Perfect Correlation : We can see that \"Duration\" and \"Duration\" got the number 1.000000, which makes sense, each column always has a perfect relationship with itself. Good Correlation : \"Duration\" and \"Calories\" got a 0.922721 correlation, which is a very good correlation, and we can predict that the longer you work out, the more calories you burn, and the other way around: if you burned a lot of calories, you probably had a long work out Bad Correlation : \"Duration\" and \"Maxpulse\" got a 0.009403 correlation, which is a very bad correlation, meaning that we can not predict the max pulse by just looking at the duration of the work out, and vice versa","title":"Correlation in Pandas"},{"location":"plt/","text":"Matplotlib Matplotlib is a popular data visualization library in Python that provides a wide range of tools for creating static, animated, and interactive visualizations. It is widely used in scientific computing, data analysis, and machine learning. Matplotlib allows you to create a variety of plots, including line plots, scatter plots, bar plots, histogram plots, and more. It provides a high level of customization to create professional-looking plots with minimal coding. In this course, we will cover the basics of Matplotlib and walk through several examples to illustrate how to create different types of plots using Matplotlib. Installing and importing Matplotlib From the terminal type: pip install matplotlib For Jupyter in the command prompt type: ! pip install matplotlib Matplotlib is available preinstalled on Anaconda3 Jupyter Notebook. Once Matplotlib is installed, import it in your applications by adding the import module statement. You can also check which version of Matplotlib you have installed. Code example : import matplotlib #importing matplotlib into your code print ( matplotlib . __version__ ) #checking installed version Matplotlib Most of Matplotlib\u2019s utility is in the pyplot sub-module, and its usually imported under the plt alias. Code Example : import matplotlib.pyplot as plt Now let's create a simple plot using Matplotlib. We will plot a line chart of the sine function between 0 and 2\u03c0. import matplotlib.pyplot as plt import numpy as np # Generate data x = np . linspace ( 0 , 2 * np . pi , 100 ) y = np . sin ( x ) # Plot data plt . plot ( x , y ) # Show plot plt . show () In this example, we first generated the data by creating an array x using the linspace function of NumPy, which creates 100 evenly spaced numbers between 0 and 2\u03c0. We then computed the sine function of x using the NumPy sin function and stored it in an array y. To create the plot, we called the plot function of Matplotlib and passed x and y as arguments. This created a line chart of the sine function. Finally, we called the show function to display the plot. Basic Plotting with Matplotlib Line Plot The most basic type of plot in Matplotlib is a line plot, which displays data as a series of points connected by straight lines. To create a line plot in Matplotlib, we use the plot function, which takes two arrays of data as arguments: x and y import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . plot ( x , y ) # Show plot plt . show () Scatter Plot A scatter plot is a type of plot that displays data as a collection of points. To create a scatter plot in Matplotlib, we use the scatter function, which takes two arrays of data as arguments: x and y. import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . scatter ( x , y ) # Show plot plt . show () In this example, we used the scatter function of Matplotlib to create a scatter plot of the data. We passed x and y as arguments to the function, which created a scatter plot with five points. Bar Plot A bar plot is a type of plot that displays data as a series of bars. To create a bar plot in Matplotlib, we use the bar function, which takes two arrays of data as arguments: x and y . import matplotlib.pyplot as plt # Data x = [ 'A' , 'B' , 'C' , 'D' , 'E' ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . bar ( x , y ) # Show plot plt . show () In this example, we used the bar function of Matplotlib to create a bar plot of the data. We passed x and y as arguments to the function, which created a bar plot with five bars. If you want the bars to be displayed horizontally instead of vertically, use the barh() function. Histogram Plot A histogram plot is a type of plot that displays the distribution of a dataset. To create a histogram plot in Matplotlib, we use the hist function, which takes an array of data as argument: x. import matplotlib.pyplot as plt import numpy as np # Data x = np . random . randn ( 1000 ) # Plot data plt . hist ( x , bins = 20 ) # Show plot plt . show () In this example, we first generated random data using the NumPy randn function. We then used the hist function of Matplotlib to create a histogram plot of the data. We passed x as an argument to the function and set the number of bins to 20 using the bins parameter. Pie Charts Plot With Pyplot, you can use the pie() function to draw pie charts. Code Example : import matplotlib.pyplot as plt import numpy as np # Data y = np . array ([ 35 , 25 , 25 , 15 ]) plt . pie ( y ) plt . show () In this example, we created two lists x and y containing five numbers each. We then called the plot function and passed x and y as arguments. This created a line plot of the data. Customizing Plots with Matplotlib Matplotlib provides a wide range of customization options to create professional-looking plots. In this section, we will cover some of the most common customization options. Adding Titles and Labels To add a title to a plot in Matplotlib, we use the title function, which takes a string as argument: title. We can also add labels to the x and y axes using the xlabel and ylabel functions. import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . plot ( x , y ) # Add title and labels plt . title ( 'Line Plot' ) plt . xlabel ( 'X Axis' ) plt . ylabel ( 'Y Axis' ) # Show plot plt . show () Changing Colors and Styles Matplotlib allows you to customize the colors and styles of the plot elements, such as lines, markers, and bars. Colors : By default, Matplotlib uses a default color cycle to distinguish between different lines in a plot. We can change the color of a line using the color parameter of the plotting function. For example: import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . plot ( x , y ) # Add title and labels plt . title ( 'Line Plot' , color = 'red' ) plt . xlabel ( 'X Axis' ) plt . ylabel ( 'Y Axis' ) # Show plot plt . show () This will plot the data using a red line. We can also use a variety of named colors such as blue, green, orange, purple, brown, and gray. We can also use color maps to map numerical values to colors. Matplotlib provides several built-in color maps, such as viridis, plasma, inferno, and magma. Here's an example: import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Get the weight of each point z = np . random . rand ( 5 ) # Plot using color map plt . scatter ( x , y , c = z , cmap = 'plasma' ) plt . colorbar () This will plot a scatter plot where the color of each point is determined by the corresponding value of z. The cmap parameter specifies the name of the color map to use, and the colorbar() function adds a color bar to the plot. Line Styles : We can also change the style of lines in a plot using the linestyle parameter of the plotting function. Matplotlib provides several built-in line styles, such as solid lines ('-'), dashed lines ('--'), dotted lines (':'), and dash-dot lines ('--'). Here's an example: import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . plot ( x , y , linestyle = '--' ) # Add title and labels plt . title ( 'Line Plot' , color = 'red' ) plt . xlabel ( 'X Axis' ) plt . ylabel ( 'Y Axis' ) # Show plot plt . show () This will plot the data using a dashed line. We can also combine line styles with markers, as shown in the following example: import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . plot ( x , y , linestyle = '--' , marker = 'o' , markersize = 10 ) # Add title and labels plt . title ( 'Line Plot' , color = 'red' ) plt . xlabel ( 'X Axis' ) plt . ylabel ( 'Y Axis' ) # Show plot plt . show () This will plot the data using a dashed line with circular markers. The markersize parameter controls the size of the markers. Subplots Subplots are useful when you want to display multiple plots in one figure. Matplotlib provides several ways to create subplots, and the simplest is the plt.subplots() function. Here is an example of creating a figure with two subplots, side by side: import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y1 = [ 2 , 4 , 6 , 8 , 10 ] y2 = [ 3 , 5 , 7 , 9 , 11 ] # Plot data fig , axs = plt . subplots ( 1 , 2 , figsize = ( 10 , 5 )) # first figure axs [ 0 ] . plot ( x , y1 ) # Add title to first figure axs [ 0 ] . set_title ( 'Plot 1' ) # second figure axs [ 1 ] . plot ( x , y2 ) # Add title to second figure axs [ 1 ] . set_title ( 'Plot 2' ) # Show plot plt . show () The first argument of plt.subplots() specifies the number of rows, and the second argument specifies the number of columns of subplots. In this example, we create one row and two columns of subplots. The figsize parameter specifies the size of the figure in inches. The function returns two objects: the fig object that represents the whole figure and the axs object that represents the array of subplots. We can use indexing to access individual subplots. In this example, axs[0] represents the left subplot, and axs[1] represents the right subplot. We can plot data on each subplot by calling plotting functions on the corresponding axs object. We can also set individual titles for each subplot using the set_title() method of each axs object. Saving Figures in Matplotlib Matplotlib provides several ways to save figures to files, such as PNG, PDF, SVG, and EPS. The simplest way is to use the savefig() function: plt . savefig ( 'figure.png' ) This will save the current figure to a file named figure.png in the current directory. The file format is inferred from the file extension.","title":"Understanding & working with Matplotlib"},{"location":"plt/#matplotlib","text":"Matplotlib is a popular data visualization library in Python that provides a wide range of tools for creating static, animated, and interactive visualizations. It is widely used in scientific computing, data analysis, and machine learning. Matplotlib allows you to create a variety of plots, including line plots, scatter plots, bar plots, histogram plots, and more. It provides a high level of customization to create professional-looking plots with minimal coding. In this course, we will cover the basics of Matplotlib and walk through several examples to illustrate how to create different types of plots using Matplotlib.","title":"Matplotlib"},{"location":"plt/#installing-and-importing-matplotlib","text":"From the terminal type: pip install matplotlib For Jupyter in the command prompt type: ! pip install matplotlib Matplotlib is available preinstalled on Anaconda3 Jupyter Notebook. Once Matplotlib is installed, import it in your applications by adding the import module statement. You can also check which version of Matplotlib you have installed. Code example : import matplotlib #importing matplotlib into your code print ( matplotlib . __version__ ) #checking installed version Matplotlib Most of Matplotlib\u2019s utility is in the pyplot sub-module, and its usually imported under the plt alias. Code Example : import matplotlib.pyplot as plt Now let's create a simple plot using Matplotlib. We will plot a line chart of the sine function between 0 and 2\u03c0. import matplotlib.pyplot as plt import numpy as np # Generate data x = np . linspace ( 0 , 2 * np . pi , 100 ) y = np . sin ( x ) # Plot data plt . plot ( x , y ) # Show plot plt . show () In this example, we first generated the data by creating an array x using the linspace function of NumPy, which creates 100 evenly spaced numbers between 0 and 2\u03c0. We then computed the sine function of x using the NumPy sin function and stored it in an array y. To create the plot, we called the plot function of Matplotlib and passed x and y as arguments. This created a line chart of the sine function. Finally, we called the show function to display the plot.","title":"Installing and importing Matplotlib"},{"location":"plt/#basic-plotting-with-matplotlib","text":"","title":"Basic Plotting with Matplotlib"},{"location":"plt/#line-plot","text":"The most basic type of plot in Matplotlib is a line plot, which displays data as a series of points connected by straight lines. To create a line plot in Matplotlib, we use the plot function, which takes two arrays of data as arguments: x and y import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . plot ( x , y ) # Show plot plt . show ()","title":"Line Plot"},{"location":"plt/#scatter-plot","text":"A scatter plot is a type of plot that displays data as a collection of points. To create a scatter plot in Matplotlib, we use the scatter function, which takes two arrays of data as arguments: x and y. import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . scatter ( x , y ) # Show plot plt . show () In this example, we used the scatter function of Matplotlib to create a scatter plot of the data. We passed x and y as arguments to the function, which created a scatter plot with five points.","title":"Scatter Plot"},{"location":"plt/#bar-plot","text":"A bar plot is a type of plot that displays data as a series of bars. To create a bar plot in Matplotlib, we use the bar function, which takes two arrays of data as arguments: x and y . import matplotlib.pyplot as plt # Data x = [ 'A' , 'B' , 'C' , 'D' , 'E' ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . bar ( x , y ) # Show plot plt . show () In this example, we used the bar function of Matplotlib to create a bar plot of the data. We passed x and y as arguments to the function, which created a bar plot with five bars. If you want the bars to be displayed horizontally instead of vertically, use the barh() function.","title":"Bar Plot"},{"location":"plt/#histogram-plot","text":"A histogram plot is a type of plot that displays the distribution of a dataset. To create a histogram plot in Matplotlib, we use the hist function, which takes an array of data as argument: x. import matplotlib.pyplot as plt import numpy as np # Data x = np . random . randn ( 1000 ) # Plot data plt . hist ( x , bins = 20 ) # Show plot plt . show () In this example, we first generated random data using the NumPy randn function. We then used the hist function of Matplotlib to create a histogram plot of the data. We passed x as an argument to the function and set the number of bins to 20 using the bins parameter.","title":"Histogram Plot"},{"location":"plt/#pie-charts-plot","text":"With Pyplot, you can use the pie() function to draw pie charts. Code Example : import matplotlib.pyplot as plt import numpy as np # Data y = np . array ([ 35 , 25 , 25 , 15 ]) plt . pie ( y ) plt . show () In this example, we created two lists x and y containing five numbers each. We then called the plot function and passed x and y as arguments. This created a line plot of the data.","title":"Pie Charts Plot"},{"location":"plt/#customizing-plots-with-matplotlib","text":"Matplotlib provides a wide range of customization options to create professional-looking plots. In this section, we will cover some of the most common customization options.","title":"Customizing Plots with Matplotlib"},{"location":"plt/#adding-titles-and-labels","text":"To add a title to a plot in Matplotlib, we use the title function, which takes a string as argument: title. We can also add labels to the x and y axes using the xlabel and ylabel functions. import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . plot ( x , y ) # Add title and labels plt . title ( 'Line Plot' ) plt . xlabel ( 'X Axis' ) plt . ylabel ( 'Y Axis' ) # Show plot plt . show ()","title":"Adding Titles and Labels"},{"location":"plt/#changing-colors-and-styles","text":"Matplotlib allows you to customize the colors and styles of the plot elements, such as lines, markers, and bars. Colors : By default, Matplotlib uses a default color cycle to distinguish between different lines in a plot. We can change the color of a line using the color parameter of the plotting function. For example: import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . plot ( x , y ) # Add title and labels plt . title ( 'Line Plot' , color = 'red' ) plt . xlabel ( 'X Axis' ) plt . ylabel ( 'Y Axis' ) # Show plot plt . show () This will plot the data using a red line. We can also use a variety of named colors such as blue, green, orange, purple, brown, and gray. We can also use color maps to map numerical values to colors. Matplotlib provides several built-in color maps, such as viridis, plasma, inferno, and magma. Here's an example: import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Get the weight of each point z = np . random . rand ( 5 ) # Plot using color map plt . scatter ( x , y , c = z , cmap = 'plasma' ) plt . colorbar () This will plot a scatter plot where the color of each point is determined by the corresponding value of z. The cmap parameter specifies the name of the color map to use, and the colorbar() function adds a color bar to the plot. Line Styles : We can also change the style of lines in a plot using the linestyle parameter of the plotting function. Matplotlib provides several built-in line styles, such as solid lines ('-'), dashed lines ('--'), dotted lines (':'), and dash-dot lines ('--'). Here's an example: import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . plot ( x , y , linestyle = '--' ) # Add title and labels plt . title ( 'Line Plot' , color = 'red' ) plt . xlabel ( 'X Axis' ) plt . ylabel ( 'Y Axis' ) # Show plot plt . show () This will plot the data using a dashed line. We can also combine line styles with markers, as shown in the following example: import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 2 , 4 , 6 , 8 , 10 ] # Plot data plt . plot ( x , y , linestyle = '--' , marker = 'o' , markersize = 10 ) # Add title and labels plt . title ( 'Line Plot' , color = 'red' ) plt . xlabel ( 'X Axis' ) plt . ylabel ( 'Y Axis' ) # Show plot plt . show () This will plot the data using a dashed line with circular markers. The markersize parameter controls the size of the markers.","title":"Changing Colors and Styles"},{"location":"plt/#subplots","text":"Subplots are useful when you want to display multiple plots in one figure. Matplotlib provides several ways to create subplots, and the simplest is the plt.subplots() function. Here is an example of creating a figure with two subplots, side by side: import matplotlib.pyplot as plt # Data x = [ 1 , 2 , 3 , 4 , 5 ] y1 = [ 2 , 4 , 6 , 8 , 10 ] y2 = [ 3 , 5 , 7 , 9 , 11 ] # Plot data fig , axs = plt . subplots ( 1 , 2 , figsize = ( 10 , 5 )) # first figure axs [ 0 ] . plot ( x , y1 ) # Add title to first figure axs [ 0 ] . set_title ( 'Plot 1' ) # second figure axs [ 1 ] . plot ( x , y2 ) # Add title to second figure axs [ 1 ] . set_title ( 'Plot 2' ) # Show plot plt . show () The first argument of plt.subplots() specifies the number of rows, and the second argument specifies the number of columns of subplots. In this example, we create one row and two columns of subplots. The figsize parameter specifies the size of the figure in inches. The function returns two objects: the fig object that represents the whole figure and the axs object that represents the array of subplots. We can use indexing to access individual subplots. In this example, axs[0] represents the left subplot, and axs[1] represents the right subplot. We can plot data on each subplot by calling plotting functions on the corresponding axs object. We can also set individual titles for each subplot using the set_title() method of each axs object.","title":"Subplots"},{"location":"plt/#saving-figures-in-matplotlib","text":"Matplotlib provides several ways to save figures to files, such as PNG, PDF, SVG, and EPS. The simplest way is to use the savefig() function: plt . savefig ( 'figure.png' ) This will save the current figure to a file named figure.png in the current directory. The file format is inferred from the file extension.","title":"Saving Figures in Matplotlib"},{"location":"sns/","text":"Seaborn Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. Seaborn helps you explore and understand your data. Its plotting functions operate on dataframes and arrays containing whole datasets and internally perform the necessary semantic mapping and statistical aggregation to produce informative plots. Its dataset-oriented, declarative API lets you focus on what the different elements of your plots mean, rather than on the details of how to draw them. Installing and importing Seaborn In your terminal type pip install seaborn If using jupyter type : ! pip install seaborn To import Seaborn in your code : import seaborn as sns Loading Data from Seaborn First, we need to import Seaborn and load some data to work with. In this course, we will use the tips dataset, which is included in Seaborn. The tips dataset contains information about the bills and tips at a restaurant. import seaborn as sns import matplotlib.pyplot as plt tips = sns . load_dataset ( 'tips' ) The tips dataset has several columns: total_bill: the total bill amount (including tip) tip: the tip amount sex: the gender of the person who paid the bill (male or female) smoker: whether the person was a smoker or not (yes or no) day: the day of the week time: whether the meal was lunch or dinner size: the number of people in the party Creating Plots with Seaborn Scatter Plot One of the most basic types of plot is a scatter plot, which shows the relationship between two variables. We can create a scatter plot using Seaborn's scatterplot function. sns . scatterplot ( x = 'total_bill' , y = 'tip' , data = tips ) plt . show () This will create a scatter plot of the total bill versus the tip amount. Line Plot Another type of plot is a line plot, which shows the relationship between two variables over time. We can create a line plot using Seaborn's lineplot function. sns . lineplot ( x = 'size' , y = 'total_bill' , data = tips ) plt . show () This will create a line plot of the size versus the total bill amount over time. Bar Plot A bar plot is useful for showing comparisons between different categories. We can create a bar plot using Seaborn's barplot function. sns . barplot ( x = 'day' , y = 'total_bill' , data = tips ) plt . show () This will create a bar plot of the total bill for each day of the week. Histogram A histogram is useful for showing the distribution of a single variable. We can create a histogram using Seaborn's histplot function. sns . histplot ( x = 'total_bill' , data = tips ) plt . show () This will create a histogram of the total bill. Box Plot A box plot is useful for showing the distribution of a variable across different categories. We can create a box plot using Seaborn's boxplot function. sns . boxplot ( x = 'day' , y = 'total_bill' , data = tips ) plt . show () This will create a box plot of the total bill for each day of the week. Violin Plot A violin plot is similar to a box plot, but it also shows the distribution of the variable. We can create a violin plot using Seaborn's violinplot function. sns . violinplot ( x = 'day' , y = 'total_bill' , data = tips ) plt . show () This will create a violin plot of the total bill for each day of the week. Pair Plots Seaborn's pairplot function can be used to create scatter plots of pairs of variables in a dataset. By default, it plots the scatter plot between each pair of numerical variables, and a histogram of each variable on the diagonal. It is a useful tool to visualize the relationships between multiple variables at once. Example : import seaborn as sns import pandas as pd iris = sns . load_dataset ( 'iris' ) sns . pairplot ( iris , hue = 'species' ) Heatmaps Seaborn's heatmap function allows you to create a heatmap of a matrix of values, with each cell colored according to its value. Heatmaps are useful for visualizing large amounts of data and identifying patterns within the data. Example : import seaborn as sns import numpy as np # Create a matrix of random values data = np . random . rand ( 10 , 10 ) # Create a heatmap sns . heatmap ( data ) FacetGrid Seaborn's FacetGrid function allows you to create a grid of plots based on the levels of one or more categorical variables. This is useful when you want to visualize relationships between variables for different groups or categories. Example: import seaborn as sns import pandas as pd # Load the tips dataset tips = sns . load_dataset ( \"tips\" ) # Create a FacetGrid g = sns . FacetGrid ( tips , col = \"time\" , row = \"sex\" ) # Map the plot to the FacetGrid g . map ( sns . scatterplot , \"total_bill\" , \"tip\" ) Styling Plots Seaborn provides several functions for styling your plots, including setting the plot background, changing the color palette, and adjusting the font size and style. Example: import seaborn as sns import matplotlib.pyplot as plt # Set the plot background color sns . set_style ( \"darkgrid\" ) # Load the tips dataset tips = sns . load_dataset ( \"tips\" ) # Set the color palette sns . set_palette ( \"husl\" ) # Create a scatter plot sns . scatterplot ( data = tips , x = \"total_bill\" , y = \"tip\" , hue = \"sex\" , size = \"size\" ) # Set the title and axis labels plt . title ( \"Tips by Total Bill\" ) plt . xlabel ( \"Total Bill\" ) plt . ylabel ( \"Tip\" ) # Set the font size and style sns . set ( font_scale = 1.5 , font = \"Arial\" )","title":"Understanding & working with Seaborn"},{"location":"sns/#seaborn","text":"Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. Seaborn helps you explore and understand your data. Its plotting functions operate on dataframes and arrays containing whole datasets and internally perform the necessary semantic mapping and statistical aggregation to produce informative plots. Its dataset-oriented, declarative API lets you focus on what the different elements of your plots mean, rather than on the details of how to draw them.","title":"Seaborn"},{"location":"sns/#installing-and-importing-seaborn","text":"In your terminal type pip install seaborn If using jupyter type : ! pip install seaborn To import Seaborn in your code : import seaborn as sns","title":"Installing and importing Seaborn"},{"location":"sns/#loading-data-from-seaborn","text":"First, we need to import Seaborn and load some data to work with. In this course, we will use the tips dataset, which is included in Seaborn. The tips dataset contains information about the bills and tips at a restaurant. import seaborn as sns import matplotlib.pyplot as plt tips = sns . load_dataset ( 'tips' ) The tips dataset has several columns: total_bill: the total bill amount (including tip) tip: the tip amount sex: the gender of the person who paid the bill (male or female) smoker: whether the person was a smoker or not (yes or no) day: the day of the week time: whether the meal was lunch or dinner size: the number of people in the party","title":"Loading Data from Seaborn"},{"location":"sns/#creating-plots-with-seaborn","text":"","title":"Creating Plots with Seaborn"},{"location":"sns/#scatter-plot","text":"One of the most basic types of plot is a scatter plot, which shows the relationship between two variables. We can create a scatter plot using Seaborn's scatterplot function. sns . scatterplot ( x = 'total_bill' , y = 'tip' , data = tips ) plt . show () This will create a scatter plot of the total bill versus the tip amount.","title":"Scatter Plot"},{"location":"sns/#line-plot","text":"Another type of plot is a line plot, which shows the relationship between two variables over time. We can create a line plot using Seaborn's lineplot function. sns . lineplot ( x = 'size' , y = 'total_bill' , data = tips ) plt . show () This will create a line plot of the size versus the total bill amount over time.","title":"Line Plot"},{"location":"sns/#bar-plot","text":"A bar plot is useful for showing comparisons between different categories. We can create a bar plot using Seaborn's barplot function. sns . barplot ( x = 'day' , y = 'total_bill' , data = tips ) plt . show () This will create a bar plot of the total bill for each day of the week.","title":"Bar Plot"},{"location":"sns/#histogram","text":"A histogram is useful for showing the distribution of a single variable. We can create a histogram using Seaborn's histplot function. sns . histplot ( x = 'total_bill' , data = tips ) plt . show () This will create a histogram of the total bill.","title":"Histogram"},{"location":"sns/#box-plot","text":"A box plot is useful for showing the distribution of a variable across different categories. We can create a box plot using Seaborn's boxplot function. sns . boxplot ( x = 'day' , y = 'total_bill' , data = tips ) plt . show () This will create a box plot of the total bill for each day of the week.","title":"Box Plot"},{"location":"sns/#violin-plot","text":"A violin plot is similar to a box plot, but it also shows the distribution of the variable. We can create a violin plot using Seaborn's violinplot function. sns . violinplot ( x = 'day' , y = 'total_bill' , data = tips ) plt . show () This will create a violin plot of the total bill for each day of the week.","title":"Violin Plot"},{"location":"sns/#pair-plots","text":"Seaborn's pairplot function can be used to create scatter plots of pairs of variables in a dataset. By default, it plots the scatter plot between each pair of numerical variables, and a histogram of each variable on the diagonal. It is a useful tool to visualize the relationships between multiple variables at once. Example : import seaborn as sns import pandas as pd iris = sns . load_dataset ( 'iris' ) sns . pairplot ( iris , hue = 'species' )","title":"Pair Plots"},{"location":"sns/#heatmaps","text":"Seaborn's heatmap function allows you to create a heatmap of a matrix of values, with each cell colored according to its value. Heatmaps are useful for visualizing large amounts of data and identifying patterns within the data. Example : import seaborn as sns import numpy as np # Create a matrix of random values data = np . random . rand ( 10 , 10 ) # Create a heatmap sns . heatmap ( data )","title":"Heatmaps"},{"location":"sns/#facetgrid","text":"Seaborn's FacetGrid function allows you to create a grid of plots based on the levels of one or more categorical variables. This is useful when you want to visualize relationships between variables for different groups or categories. Example: import seaborn as sns import pandas as pd # Load the tips dataset tips = sns . load_dataset ( \"tips\" ) # Create a FacetGrid g = sns . FacetGrid ( tips , col = \"time\" , row = \"sex\" ) # Map the plot to the FacetGrid g . map ( sns . scatterplot , \"total_bill\" , \"tip\" )","title":"FacetGrid"},{"location":"sns/#styling-plots","text":"Seaborn provides several functions for styling your plots, including setting the plot background, changing the color palette, and adjusting the font size and style. Example: import seaborn as sns import matplotlib.pyplot as plt # Set the plot background color sns . set_style ( \"darkgrid\" ) # Load the tips dataset tips = sns . load_dataset ( \"tips\" ) # Set the color palette sns . set_palette ( \"husl\" ) # Create a scatter plot sns . scatterplot ( data = tips , x = \"total_bill\" , y = \"tip\" , hue = \"sex\" , size = \"size\" ) # Set the title and axis labels plt . title ( \"Tips by Total Bill\" ) plt . xlabel ( \"Total Bill\" ) plt . ylabel ( \"Tip\" ) # Set the font size and style sns . set ( font_scale = 1.5 , font = \"Arial\" )","title":"Styling Plots"},{"location":"sql/01_sql_intro/","text":"Introduction Welcome to the Database Management Systems course! In this course, you will learn how to use SQL to work with databases (extract, insert, delete and analyse data). Databases are an essential part of modern computing, and they are used in everything from social media applications to e-commerce websites to scientific research. Course goals This course will cover database basics, installation of MYSQL, various database types, database designs, SQL statements, and more. Here are some main goals as a developer for mastering databases: Understanding data modeling: The ability to design and implement effective data models is crucial for building scalable and efficient databases. This includes knowledge of different types of databases, data structures, and normalization techniques. Proficiency in SQL: SQL (Structured Query Language) is the standard language used for querying, manipulating, and managing data in databases. As a developer, it is important to have a strong understanding of SQL and its various functions. Database administration skills: Database administration involves tasks such as installing, configuring, and maintaining databases. A developer who is proficient in database administration can optimize performance, troubleshoot issues, and ensure the security of their databases. Knowledge of database architecture: Understanding the architecture of databases and how they interact with other systems is essential for building and integrating applications with databases. Table of content Introduction Overview of the main topics that will be covered in the course and goals Explanation of what a database is and why they are important Introduction to relational DBMS What is a RDBMS What is MySQL MySQL installation Database designs basics Explanation of tables and keys in databases Explanation of SQL language and its uses Overview of different SQL Statements Explanation of DDL language and its uses Overview of different DDL Statements Using MySQL Workbench Data servers MySQL/RDBMS Concepts Overview of different TCL statements Overview of different DML statements MySQL users Introduction Users selection User privileges Managing my database Creating database Creating tables Introduction to MySQL Data Types MySQL Clauses Retreive data from single tables Other statements Overview of the Groupby statement Joins in SQL Creating Views with Aggregate functions Constraints Indexes Select Statement Advanced topics Subqueries Introduction to Extraction Transformation and Loading ETL Process Introduction to NoSQL databases Let's get started \ud83e\udd73 Why database ? Imagine you work for a large online retailer, and your company needs to manage thousands of products, customers, and orders every day. You could store this data in an Excel spreadsheet, but as your company grows, this becomes increasingly difficult and time-consuming. You might have dozens or even hundreds of spreadsheets, each containing different pieces of data, making it difficult to find the information you need quickly. In addition, spreadsheets are not ideal for handling large amounts of data, and they can become slow and unwieldy as the size of the dataset grows. This is where databases come in. A database is an organized collection of data that is designed to be easy to access, manage, and update. With a database, you can store all your company's data in one place, making it easy to find the information you need quickly. Databases are also designed to handle large amounts of data efficiently, so you can work with massive datasets without running into performance issues. Types of Databases There are many different types of databases, each with its own strengths and weaknesses. Some of the most common types of databases include: Relational databases: These databases organize data into tables with columns and rows, similar to a spreadsheet. They are the most common type of database and are used in many different applications. NoSQL databases: These databases are designed to handle large amounts of unstructured or semi-structured data. They are commonly used in big data applications, such as social media analytics and scientific research. Object-oriented databases: These databases store data as objects, which can be manipulated using object-oriented programming techniques. They are commonly used in software development and data modeling. Some examples of day-to-day use cases for each type of database : Relational databases Customer database example : A business might use a relational database to keep track of customer information, such as their name, contact details, and purchase history. They could then use this information to target customers with personalized marketing campaigns based on their previous purchases. Inventory management example : A store might use a relational database to manage their inventory, with one table for products and another table for suppliers. They could then use SQL queries to quickly retrieve information on which products are in stock, which products are selling quickly, and which suppliers they need to contact to restock their inventory. Employee scheduling example : A company might use a relational database to manage employee schedules, with one table for employees and another table for shifts. They could then use SQL queries to quickly retrieve information on which employees are available to work on a particular day or time, and which shifts still need to be filled. NoSQL databases Social media analytics: Social media platforms like Facebook and Twitter use NoSQL databases to store and analyze massive amounts of user data, such as likes, comments, and shares. This allows them to quickly retrieve and analyze user data to provide better ad targeting and personalized content. Internet of Things (IoT) devices: IoT devices like smart thermostats and security cameras generate a huge amount of data, which can be stored and analyzed in NoSQL databases. This allows manufacturers to track device usage patterns, identify and fix bugs, and improve device performance over time. Gaming: Many video games use NoSQL databases to store player data, such as character stats and in-game achievements. This allows players to continue their game progress across different devices, and enables game developers to quickly retrieve and analyze player data to identify areas for improvement. Object-oriented databases Geolocation data: Companies that rely on geolocation data, such as mapping and navigation services, often use object-oriented databases to store and retrieve this data. This allows them to quickly retrieve and analyze large amounts of geolocation data in real-time. E-commerce: An e-commerce website might use an object-oriented database to store and manage product information, such as product images and descriptions. This allows them to easily update and manage product information across multiple platforms, such as their website, mobile app, and social media. Medical records: Hospitals and healthcare providers often use object-oriented databases to manage patient medical records, which can include a wide range of data types, such as images, test results, and diagnoses. This allows healthcare providers to easily access and update patient information, and can help improve patient care and outcomes. In this course, we will be focusing on relational databases, specifically MySQL, which is a popular open-source database management system. We will also introduce the concept of NoSQL databases. What are DBMS ? A Database Management System (DBMS) is defined as the software system that allows users to define, create, maintain and control access to the database. DBMS makes it possible for end users to create, read, update and delete data in database. A DBMS serves as an interface between an end-user and the database. DBMS Examples: MySQL, Microsoft Access, SQL Server, FileMaker, Oracle. Advantages of DBMS : Improved Data Availability Improved Data Security Improved data integration Improved decision making Increased end-user productivity Simplicity","title":"01 sql intro"},{"location":"sql/01_sql_intro/#introduction","text":"Welcome to the Database Management Systems course! In this course, you will learn how to use SQL to work with databases (extract, insert, delete and analyse data). Databases are an essential part of modern computing, and they are used in everything from social media applications to e-commerce websites to scientific research.","title":"Introduction"},{"location":"sql/01_sql_intro/#course-goals","text":"This course will cover database basics, installation of MYSQL, various database types, database designs, SQL statements, and more. Here are some main goals as a developer for mastering databases: Understanding data modeling: The ability to design and implement effective data models is crucial for building scalable and efficient databases. This includes knowledge of different types of databases, data structures, and normalization techniques. Proficiency in SQL: SQL (Structured Query Language) is the standard language used for querying, manipulating, and managing data in databases. As a developer, it is important to have a strong understanding of SQL and its various functions. Database administration skills: Database administration involves tasks such as installing, configuring, and maintaining databases. A developer who is proficient in database administration can optimize performance, troubleshoot issues, and ensure the security of their databases. Knowledge of database architecture: Understanding the architecture of databases and how they interact with other systems is essential for building and integrating applications with databases.","title":"Course goals"},{"location":"sql/01_sql_intro/#table-of-content","text":"Introduction Overview of the main topics that will be covered in the course and goals Explanation of what a database is and why they are important Introduction to relational DBMS What is a RDBMS What is MySQL MySQL installation Database designs basics Explanation of tables and keys in databases Explanation of SQL language and its uses Overview of different SQL Statements Explanation of DDL language and its uses Overview of different DDL Statements Using MySQL Workbench Data servers MySQL/RDBMS Concepts Overview of different TCL statements Overview of different DML statements MySQL users Introduction Users selection User privileges Managing my database Creating database Creating tables Introduction to MySQL Data Types MySQL Clauses Retreive data from single tables Other statements Overview of the Groupby statement Joins in SQL Creating Views with Aggregate functions Constraints Indexes Select Statement Advanced topics Subqueries Introduction to Extraction Transformation and Loading ETL Process Introduction to NoSQL databases Let's get started \ud83e\udd73","title":"Table of content"},{"location":"sql/01_sql_intro/#why-database","text":"Imagine you work for a large online retailer, and your company needs to manage thousands of products, customers, and orders every day. You could store this data in an Excel spreadsheet, but as your company grows, this becomes increasingly difficult and time-consuming. You might have dozens or even hundreds of spreadsheets, each containing different pieces of data, making it difficult to find the information you need quickly. In addition, spreadsheets are not ideal for handling large amounts of data, and they can become slow and unwieldy as the size of the dataset grows. This is where databases come in. A database is an organized collection of data that is designed to be easy to access, manage, and update. With a database, you can store all your company's data in one place, making it easy to find the information you need quickly. Databases are also designed to handle large amounts of data efficiently, so you can work with massive datasets without running into performance issues.","title":"Why database ?"},{"location":"sql/01_sql_intro/#types-of-databases","text":"There are many different types of databases, each with its own strengths and weaknesses. Some of the most common types of databases include: Relational databases: These databases organize data into tables with columns and rows, similar to a spreadsheet. They are the most common type of database and are used in many different applications. NoSQL databases: These databases are designed to handle large amounts of unstructured or semi-structured data. They are commonly used in big data applications, such as social media analytics and scientific research. Object-oriented databases: These databases store data as objects, which can be manipulated using object-oriented programming techniques. They are commonly used in software development and data modeling. Some examples of day-to-day use cases for each type of database :","title":"Types of Databases"},{"location":"sql/01_sql_intro/#relational-databases","text":"Customer database example : A business might use a relational database to keep track of customer information, such as their name, contact details, and purchase history. They could then use this information to target customers with personalized marketing campaigns based on their previous purchases. Inventory management example : A store might use a relational database to manage their inventory, with one table for products and another table for suppliers. They could then use SQL queries to quickly retrieve information on which products are in stock, which products are selling quickly, and which suppliers they need to contact to restock their inventory. Employee scheduling example : A company might use a relational database to manage employee schedules, with one table for employees and another table for shifts. They could then use SQL queries to quickly retrieve information on which employees are available to work on a particular day or time, and which shifts still need to be filled.","title":"Relational databases"},{"location":"sql/01_sql_intro/#nosql-databases","text":"Social media analytics: Social media platforms like Facebook and Twitter use NoSQL databases to store and analyze massive amounts of user data, such as likes, comments, and shares. This allows them to quickly retrieve and analyze user data to provide better ad targeting and personalized content. Internet of Things (IoT) devices: IoT devices like smart thermostats and security cameras generate a huge amount of data, which can be stored and analyzed in NoSQL databases. This allows manufacturers to track device usage patterns, identify and fix bugs, and improve device performance over time. Gaming: Many video games use NoSQL databases to store player data, such as character stats and in-game achievements. This allows players to continue their game progress across different devices, and enables game developers to quickly retrieve and analyze player data to identify areas for improvement.","title":"NoSQL databases"},{"location":"sql/01_sql_intro/#object-oriented-databases","text":"Geolocation data: Companies that rely on geolocation data, such as mapping and navigation services, often use object-oriented databases to store and retrieve this data. This allows them to quickly retrieve and analyze large amounts of geolocation data in real-time. E-commerce: An e-commerce website might use an object-oriented database to store and manage product information, such as product images and descriptions. This allows them to easily update and manage product information across multiple platforms, such as their website, mobile app, and social media. Medical records: Hospitals and healthcare providers often use object-oriented databases to manage patient medical records, which can include a wide range of data types, such as images, test results, and diagnoses. This allows healthcare providers to easily access and update patient information, and can help improve patient care and outcomes. In this course, we will be focusing on relational databases, specifically MySQL, which is a popular open-source database management system. We will also introduce the concept of NoSQL databases.","title":"Object-oriented databases"},{"location":"sql/01_sql_intro/#what-are-dbms","text":"A Database Management System (DBMS) is defined as the software system that allows users to define, create, maintain and control access to the database. DBMS makes it possible for end users to create, read, update and delete data in database. A DBMS serves as an interface between an end-user and the database. DBMS Examples: MySQL, Microsoft Access, SQL Server, FileMaker, Oracle. Advantages of DBMS : Improved Data Availability Improved Data Security Improved data integration Improved decision making Increased end-user productivity Simplicity","title":"What are DBMS ?"},{"location":"sql/02_db_kesako/","text":"What are RDBMS ? A relational database organizes data into tables which can be linked\u2014or related\u2014based on data common to each. This capability enables you to retrieve an entirely new table from data in one or more tables with a single query. Data is represented in the terms of rows/records and columns. In a relational database, each row in the table is a record with a unique ID called the key. What is MySQL ? MySQL is one of the most recognizable technologies in the modern big data ecosystem. Often called the most popular database and currently enjoying widespread, effective use regardless of industry, it\u2019s clear that anyone involved with enterprise data or general IT should at least aim for a basic familiarity of MySQL. MySQL is a relational database management system (RDBMS) developed by Oracle that is based on structured query language (SQL). MySQL is integral to many of the most popular software stacks for building and maintaining everything from customer-facing web applications to powerful, data-driven B2B services. Its open-source nature, stability, and rich feature set, paired with ongoing development and support from Oracle, have meant that internet-critical organizations such as Facebook, Flickr, Twitter, Wikipedia, and YouTube all employ MySQL backends. MySQL client and CLI Think of a database like a big organized warehouse full of information. In order to get information from the warehouse or add information to it, we need a way to talk to it. That's where the MySQL client comes in. It's like the messenger that we use to talk to the warehouse, and it allows us to read or update information stored in the database. We use a command line interface (CLI) to interact with the MySQL client, which allows us to send specific commands to the database. A command-line interface (CLI) is a text-based interface used to interact with a computer's operating system or software by typing commands in a terminal window. It allows you to perform various tasks such as managing files and directories, executing programs, and interacting with databases, by entering commands and receiving text-based output. In the context of MySQL, the CLI is a tool that enables you to interact with a MySQL database from a terminal window or a graphic interface by typing SQL commands. This means you can create, modify, and query your databases without using a graphical user interface. The CLI is a powerful tool that gives you fine-grained control over your database, but it requires some knowledge of SQL commands and syntax to use effectively. Vocabulary Here's an additional point on the differences between MySQL client, server, and SQL: MySQL client is a command-line tool that allows you to interact with the MySQL server, execute SQL queries, and manage databases. MySQL server is the software that stores and manages databases, and allows multiple clients to connect to it and perform operations on the databases. SQL (Structured Query Language) is the language used to interact with relational databases like MySQL, and it provides a standardized syntax for creating, modifying, and querying databases. Advantages of MySQL MySQL is secure as it consists of a solid data security layer to protect sensitive data from intruders and passwords in MySQL are encrypted MySQL is free and open source MySQL is compatible with most platforms including Windows, MacOS and Linux MySQL provides the ability to run the clients and the server on the same computer or on different computers, via internet or local network. MySQL has a unique storage engine architecture which makes it faster, cheaper and more reliable. MySQL gives developers higher productivity by using views, Triggers and Stored procedures MySQL is simple and easy to use. You can build and interact with MySQL with only the basic knowledge of MySQL and a few simple SQL statements. MySQL is scalable and capable of handling more than 50 million rows. This is enough to handle almost any amount of data. Although the default file size limit is 4GB but it can be increased to 8TB. Disadvantages of MYSQL MySQL is not very efficient in handling very large databases. MySQL doesn\u2019t have as good a developing and debugging tool as compared to paid databases. MySQL versions less than 5.0 do not support COMMIT, stored procedure and ROLE. MySQL is prone to data corruption as it inefficient in handling transactions. MySQL does not support SQL check constraints. Installing MySQL To install MySQL on your computer, please visit their website And download the free and open source community edition of MYSQL. For Windows select \u201cInstaller for Windows\u201d For Mac select \u201cMacOS\u201d For Linux select \u201cAPT\u201d or \u201cYUM\u201d Once downloaded, run the installer and follow the instructions to install MYSQL on your computer then launch the MYSQL Workbench","title":"02 db kesako"},{"location":"sql/02_db_kesako/#what-are-rdbms","text":"A relational database organizes data into tables which can be linked\u2014or related\u2014based on data common to each. This capability enables you to retrieve an entirely new table from data in one or more tables with a single query. Data is represented in the terms of rows/records and columns. In a relational database, each row in the table is a record with a unique ID called the key.","title":"What are RDBMS ?"},{"location":"sql/02_db_kesako/#what-is-mysql","text":"MySQL is one of the most recognizable technologies in the modern big data ecosystem. Often called the most popular database and currently enjoying widespread, effective use regardless of industry, it\u2019s clear that anyone involved with enterprise data or general IT should at least aim for a basic familiarity of MySQL. MySQL is a relational database management system (RDBMS) developed by Oracle that is based on structured query language (SQL). MySQL is integral to many of the most popular software stacks for building and maintaining everything from customer-facing web applications to powerful, data-driven B2B services. Its open-source nature, stability, and rich feature set, paired with ongoing development and support from Oracle, have meant that internet-critical organizations such as Facebook, Flickr, Twitter, Wikipedia, and YouTube all employ MySQL backends.","title":"What is MySQL ?"},{"location":"sql/02_db_kesako/#mysql-client-and-cli","text":"Think of a database like a big organized warehouse full of information. In order to get information from the warehouse or add information to it, we need a way to talk to it. That's where the MySQL client comes in. It's like the messenger that we use to talk to the warehouse, and it allows us to read or update information stored in the database. We use a command line interface (CLI) to interact with the MySQL client, which allows us to send specific commands to the database. A command-line interface (CLI) is a text-based interface used to interact with a computer's operating system or software by typing commands in a terminal window. It allows you to perform various tasks such as managing files and directories, executing programs, and interacting with databases, by entering commands and receiving text-based output. In the context of MySQL, the CLI is a tool that enables you to interact with a MySQL database from a terminal window or a graphic interface by typing SQL commands. This means you can create, modify, and query your databases without using a graphical user interface. The CLI is a powerful tool that gives you fine-grained control over your database, but it requires some knowledge of SQL commands and syntax to use effectively.","title":"MySQL client and CLI"},{"location":"sql/02_db_kesako/#vocabulary","text":"Here's an additional point on the differences between MySQL client, server, and SQL: MySQL client is a command-line tool that allows you to interact with the MySQL server, execute SQL queries, and manage databases. MySQL server is the software that stores and manages databases, and allows multiple clients to connect to it and perform operations on the databases. SQL (Structured Query Language) is the language used to interact with relational databases like MySQL, and it provides a standardized syntax for creating, modifying, and querying databases.","title":"Vocabulary"},{"location":"sql/02_db_kesako/#advantages-of-mysql","text":"MySQL is secure as it consists of a solid data security layer to protect sensitive data from intruders and passwords in MySQL are encrypted MySQL is free and open source MySQL is compatible with most platforms including Windows, MacOS and Linux MySQL provides the ability to run the clients and the server on the same computer or on different computers, via internet or local network. MySQL has a unique storage engine architecture which makes it faster, cheaper and more reliable. MySQL gives developers higher productivity by using views, Triggers and Stored procedures MySQL is simple and easy to use. You can build and interact with MySQL with only the basic knowledge of MySQL and a few simple SQL statements. MySQL is scalable and capable of handling more than 50 million rows. This is enough to handle almost any amount of data. Although the default file size limit is 4GB but it can be increased to 8TB.","title":"Advantages of MySQL"},{"location":"sql/02_db_kesako/#disadvantages-of-mysql","text":"MySQL is not very efficient in handling very large databases. MySQL doesn\u2019t have as good a developing and debugging tool as compared to paid databases. MySQL versions less than 5.0 do not support COMMIT, stored procedure and ROLE. MySQL is prone to data corruption as it inefficient in handling transactions. MySQL does not support SQL check constraints.","title":"Disadvantages of MYSQL"},{"location":"sql/02_db_kesako/#installing-mysql","text":"To install MySQL on your computer, please visit their website And download the free and open source community edition of MYSQL. For Windows select \u201cInstaller for Windows\u201d For Mac select \u201cMacOS\u201d For Linux select \u201cAPT\u201d or \u201cYUM\u201d Once downloaded, run the installer and follow the instructions to install MYSQL on your computer then launch the MYSQL Workbench","title":"Installing MySQL"},{"location":"sql/03_table/","text":"Tables & Keys Tables and keys are fundamental concepts in relational database management systems. A table is a collection of related data, organized into rows and columns. Each row in a table represents a unique instance of the data, while each column represents a specific attribute or characteristic of that data. Keys are used to uniquely identify each row in a table. A key is a column or set of columns in a table that contains values that are unique across all the rows in the table. Keys are used to enforce data integrity, to ensure that data is not duplicated or inconsistent, and to enable efficient searching and sorting of data. In this course, we'll explore the different types of keys that can be used in MySQL, and how they can be used to create tables with well-defined relationships between them. Creating Tables in MySQL Creating a table is the first step in building a database. To create a table in MySQL, we use the CREATE TABLE statement, followed by the table name and a list of columns and their data types. Here's an example of creating a simple table to store information about customers: CREATE TABLE customers ( customer_id INT PRIMARY KEY , first_name VARCHAR ( 50 ), last_name VARCHAR ( 50 ), email VARCHAR ( 100 ) ); This creates a table called customers with four columns: customer_id, first_name, last_name, and email. The customer_id column is defined as the primary key, which means it will contain unique values that identify each row in the table. Keys Keys are an important concept in database design. They are used to ensure data integrity and to establish relationships between tables. There are several types of keys in a database: Primary Key A primary key is a column or set of columns that uniquely identifies each row in a table. The primary key is used to enforce data integrity and to ensure that there are no duplicate rows in the table. We can define a primary key using the PRIMARY KEY constraint, as shown in the example above. Here's another example, this time with a table called orders that has a composite primary key made up of two columns: CREATE TABLE orders ( order_id INT PRIMARY KEY , customer_id INT , order_date DATE , ); This creates a table called orders with three columns: order_id, customer_id, and order_date. The PRIMARY KEY constraint is used to define a composite primary key made up of the order_id and customer_id columns. Foreign Key A foreign key is a column in one table that refers to the primary key of another table. Foreign keys are used to create relationships between tables, and to enforce referential integrity between them. In MySQL, we can define a foreign key using the FOREIGN KEY constraint. Here's an example of creating a table called orders that has a foreign key that references the customer_id column in the customers table: CREATE TABLE orders ( order_id INT PRIMARY KEY , customer_id INT , order_date DATE , FOREIGN KEY ( customer_id ) REFERENCES customers ( customer_id ) ); This creates a table called orders with three columns: order_id, customer_id, and order_date. The FOREIGN KEY constraint is used to define a foreign key that references the customer_id column in the customers table. Unique Keys A unique key is a column or set of columns in a table that contains unique values, but is not the primary key. Unique keys are used to enforce data integrity, and to enable efficient searching and sorting of data. In MySQL, we can define a unique key using the UNIQUE constraint. Here's an example of creating a table called products that has a unique key on the product_code column: CREATE TABLE products ( product_id INT PRIMARY KEY , product_code VARCHAR ( 20 ) UNIQUE , product_name VARCHAR ( 50 ), price DECIMAL ( 10 , 2 ) ); This creates a table called products with four columns: product_id, product_code, product_name, and price. The product_code column is defined as a unique key using the UNIQUE constraint, which means that it will contain unique values across all the rows in the table. Composite Key A composite key, also known as a composite primary key, is a primary key that consists of two or more columns in a table. In other words, it is a unique identifier made up of multiple columns. A composite key is used when a single column cannot uniquely identify each row in a table, but a combination of columns can. For example, consider a table called orders that tracks the orders made by customers. Each order is identified by a unique order number, but a customer can make multiple orders, so the order number alone cannot uniquely identify each row in the table. Instead, we can use a composite key made up of the order number and the customer ID to uniquely identify each row: CREATE TABLE orders ( order_number INT , customer_id INT , order_date DATE , PRIMARY KEY ( order_number , customer_id ) ); In this example, the primary key for the orders table is a composite key made up of the order_number and customer_id columns. This ensures that each row in the table is uniquely identified by a combination of these two columns. Using a composite key can improve the performance of queries that search or filter data based on a combination of columns. However, it can also make updates and deletions more complicated, since multiple columns must be taken into account. PS : A unique key is used to enforce uniqueness of data within a table, while a composite key is used to uniquely identify each row in a table. Conclusion Tables and keys are essential concepts in relational database management systems, and understanding them is crucial for designing efficient and well-organized databases. In MySQL, we can use the CREATE TABLE statement to create tables with different types of keys and indexes, and enforce data integrity and relationships between tables. By using these features effectively, we can create databases that are easy to query, maintain, and scale to meet the needs of any application.","title":"Tables & Keys"},{"location":"sql/03_table/#tables-keys","text":"Tables and keys are fundamental concepts in relational database management systems. A table is a collection of related data, organized into rows and columns. Each row in a table represents a unique instance of the data, while each column represents a specific attribute or characteristic of that data. Keys are used to uniquely identify each row in a table. A key is a column or set of columns in a table that contains values that are unique across all the rows in the table. Keys are used to enforce data integrity, to ensure that data is not duplicated or inconsistent, and to enable efficient searching and sorting of data. In this course, we'll explore the different types of keys that can be used in MySQL, and how they can be used to create tables with well-defined relationships between them.","title":"Tables &amp; Keys"},{"location":"sql/03_table/#creating-tables-in-mysql","text":"Creating a table is the first step in building a database. To create a table in MySQL, we use the CREATE TABLE statement, followed by the table name and a list of columns and their data types. Here's an example of creating a simple table to store information about customers: CREATE TABLE customers ( customer_id INT PRIMARY KEY , first_name VARCHAR ( 50 ), last_name VARCHAR ( 50 ), email VARCHAR ( 100 ) ); This creates a table called customers with four columns: customer_id, first_name, last_name, and email. The customer_id column is defined as the primary key, which means it will contain unique values that identify each row in the table.","title":"Creating Tables in MySQL"},{"location":"sql/03_table/#keys","text":"Keys are an important concept in database design. They are used to ensure data integrity and to establish relationships between tables. There are several types of keys in a database:","title":"Keys"},{"location":"sql/03_table/#primary-key","text":"A primary key is a column or set of columns that uniquely identifies each row in a table. The primary key is used to enforce data integrity and to ensure that there are no duplicate rows in the table. We can define a primary key using the PRIMARY KEY constraint, as shown in the example above. Here's another example, this time with a table called orders that has a composite primary key made up of two columns: CREATE TABLE orders ( order_id INT PRIMARY KEY , customer_id INT , order_date DATE , ); This creates a table called orders with three columns: order_id, customer_id, and order_date. The PRIMARY KEY constraint is used to define a composite primary key made up of the order_id and customer_id columns.","title":"Primary Key"},{"location":"sql/03_table/#foreign-key","text":"A foreign key is a column in one table that refers to the primary key of another table. Foreign keys are used to create relationships between tables, and to enforce referential integrity between them. In MySQL, we can define a foreign key using the FOREIGN KEY constraint. Here's an example of creating a table called orders that has a foreign key that references the customer_id column in the customers table: CREATE TABLE orders ( order_id INT PRIMARY KEY , customer_id INT , order_date DATE , FOREIGN KEY ( customer_id ) REFERENCES customers ( customer_id ) ); This creates a table called orders with three columns: order_id, customer_id, and order_date. The FOREIGN KEY constraint is used to define a foreign key that references the customer_id column in the customers table.","title":"Foreign Key"},{"location":"sql/03_table/#unique-keys","text":"A unique key is a column or set of columns in a table that contains unique values, but is not the primary key. Unique keys are used to enforce data integrity, and to enable efficient searching and sorting of data. In MySQL, we can define a unique key using the UNIQUE constraint. Here's an example of creating a table called products that has a unique key on the product_code column: CREATE TABLE products ( product_id INT PRIMARY KEY , product_code VARCHAR ( 20 ) UNIQUE , product_name VARCHAR ( 50 ), price DECIMAL ( 10 , 2 ) ); This creates a table called products with four columns: product_id, product_code, product_name, and price. The product_code column is defined as a unique key using the UNIQUE constraint, which means that it will contain unique values across all the rows in the table.","title":"Unique Keys"},{"location":"sql/03_table/#composite-key","text":"A composite key, also known as a composite primary key, is a primary key that consists of two or more columns in a table. In other words, it is a unique identifier made up of multiple columns. A composite key is used when a single column cannot uniquely identify each row in a table, but a combination of columns can. For example, consider a table called orders that tracks the orders made by customers. Each order is identified by a unique order number, but a customer can make multiple orders, so the order number alone cannot uniquely identify each row in the table. Instead, we can use a composite key made up of the order number and the customer ID to uniquely identify each row: CREATE TABLE orders ( order_number INT , customer_id INT , order_date DATE , PRIMARY KEY ( order_number , customer_id ) ); In this example, the primary key for the orders table is a composite key made up of the order_number and customer_id columns. This ensures that each row in the table is uniquely identified by a combination of these two columns. Using a composite key can improve the performance of queries that search or filter data based on a combination of columns. However, it can also make updates and deletions more complicated, since multiple columns must be taken into account. PS : A unique key is used to enforce uniqueness of data within a table, while a composite key is used to uniquely identify each row in a table.","title":"Composite Key"},{"location":"sql/03_table/#conclusion","text":"Tables and keys are essential concepts in relational database management systems, and understanding them is crucial for designing efficient and well-organized databases. In MySQL, we can use the CREATE TABLE statement to create tables with different types of keys and indexes, and enforce data integrity and relationships between tables. By using these features effectively, we can create databases that are easy to query, maintain, and scale to meet the needs of any application.","title":"Conclusion"},{"location":"sql/04_basics/","text":"What is SQL? SQL stands for Structured Query Language. It is a programming language used for managing and manipulating data stored in relational databases. SQL is used to create, modify, and query databases, and it is the most widely used language for managing databases. Why use SQL? SQL is used in many different industries and applications because it provides a powerful and flexible way to manage data. Here are some reasons why SQL is useful: SQL is a standardized language, meaning that it can be used with many different types of databases. SQL is flexible and scalable, meaning that it can be used to manage small or large amounts of data. SQL allows users to manipulate and analyze data in complex ways, making it a useful tool for data-driven decision making. SQL is widely used and well-documented, meaning that there is a large community of users who can offer support and guidance. How does SQL work? SQL works by interacting with relational databases, which are databases that store data in tables with rows and columns. Here's how it works: To create a database, users use SQL to define the structure of the tables and the relationships between them. To add data to a database, users use SQL to insert rows into the tables. To modify data in a database, users use SQL to update or delete rows in the tables. To query data from a database, users use SQL to retrieve specific data based on specified conditions. SQL is a powerful language that can be used to manipulate and analyze data in many different ways. With SQL, users can manage and analyze data in a flexible and scalable way, making it a useful tool for businesses, organizations, and individuals.","title":"04 basics"},{"location":"sql/04_basics/#what-is-sql","text":"SQL stands for Structured Query Language. It is a programming language used for managing and manipulating data stored in relational databases. SQL is used to create, modify, and query databases, and it is the most widely used language for managing databases.","title":"What is SQL?"},{"location":"sql/04_basics/#why-use-sql","text":"SQL is used in many different industries and applications because it provides a powerful and flexible way to manage data. Here are some reasons why SQL is useful: SQL is a standardized language, meaning that it can be used with many different types of databases. SQL is flexible and scalable, meaning that it can be used to manage small or large amounts of data. SQL allows users to manipulate and analyze data in complex ways, making it a useful tool for data-driven decision making. SQL is widely used and well-documented, meaning that there is a large community of users who can offer support and guidance.","title":"Why use SQL?"},{"location":"sql/04_basics/#how-does-sql-work","text":"SQL works by interacting with relational databases, which are databases that store data in tables with rows and columns. Here's how it works: To create a database, users use SQL to define the structure of the tables and the relationships between them. To add data to a database, users use SQL to insert rows into the tables. To modify data in a database, users use SQL to update or delete rows in the tables. To query data from a database, users use SQL to retrieve specific data based on specified conditions. SQL is a powerful language that can be used to manipulate and analyze data in many different ways. With SQL, users can manage and analyze data in a flexible and scalable way, making it a useful tool for businesses, organizations, and individuals.","title":"How does SQL work?"},{"location":"sql/07_creating_tables/","text":"Creating Tables We said before, in SQL a table is a collection of data stored in rows and columns. To create a table, you need to define the table schema which includes the table name, column names, data types, and any constraints on the data. The CREATE TABLE statement is used to create a new table in a database. In-depth look at how to create tables To create a new table in SQL, you use the CREATE TABLE command followed by the table name and a list of column definitions. Each column definition specifies the column name, data type, and any constraints on the data. Here is an example of creating a simple table with two columns: CREATE TABLE users ( id INT PRIMARY KEY , name VARCHAR ( 50 ) NOT NULL ); This creates a table named users with two columns: id and name . The id column is defined as an integer and is marked as the primary key for the table. The name column is defined as a variable-length string with a maximum length of 50 characters and is marked as required (NOT NULL) . Overview of different data types and how to use them SQL provides a wide range of data types that can be used to define columns in a table. These data types include integers, floating-point numbers, strings, dates, and more. Here are some common data types: INT: used for integer values VARCHAR(n): used for variable-length character strings with a maximum length of n DATE: used for date values FLOAT: used for floating-point numbers BOOLEAN: used for boolean values Here is an example of creating a table with columns of different data types: CREATE TABLE products ( id INT PRIMARY KEY , name VARCHAR ( 50 ) NOT NULL , price FLOAT , in_stock BOOLEAN , created_at DATE ); Add primary and foreign keys and link an other table In a relational database, a primary key is a unique identifier for each row in a table. It is used to ensure that each row can be uniquely identified and is commonly used to link to other tables in the database. A foreign key is a column in one table that refers to the primary key of another table. This is used to create relationships between tables and enforce referential integrity. Here is an example of creating a table with a primary key and a foreign key: CREATE TABLE orders ( id INT PRIMARY KEY , product_id INT , quantity INT , FOREIGN KEY ( product_id ) REFERENCES products ( id ) ); This creates a table named orders with three columns: id , product_id , and quantity . The id column is defined as the primary key for the table. The product_id column is defined as a foreign key that references the id column in the products table, which creates a relationship between the two tables. Here, the quantity column is defined as an integer.","title":"Creating Tables"},{"location":"sql/07_creating_tables/#creating-tables","text":"We said before, in SQL a table is a collection of data stored in rows and columns. To create a table, you need to define the table schema which includes the table name, column names, data types, and any constraints on the data. The CREATE TABLE statement is used to create a new table in a database.","title":"Creating Tables"},{"location":"sql/07_creating_tables/#in-depth-look-at-how-to-create-tables","text":"To create a new table in SQL, you use the CREATE TABLE command followed by the table name and a list of column definitions. Each column definition specifies the column name, data type, and any constraints on the data. Here is an example of creating a simple table with two columns: CREATE TABLE users ( id INT PRIMARY KEY , name VARCHAR ( 50 ) NOT NULL ); This creates a table named users with two columns: id and name . The id column is defined as an integer and is marked as the primary key for the table. The name column is defined as a variable-length string with a maximum length of 50 characters and is marked as required (NOT NULL) .","title":"In-depth look at how to create tables"},{"location":"sql/07_creating_tables/#overview-of-different-data-types-and-how-to-use-them","text":"SQL provides a wide range of data types that can be used to define columns in a table. These data types include integers, floating-point numbers, strings, dates, and more. Here are some common data types: INT: used for integer values VARCHAR(n): used for variable-length character strings with a maximum length of n DATE: used for date values FLOAT: used for floating-point numbers BOOLEAN: used for boolean values Here is an example of creating a table with columns of different data types: CREATE TABLE products ( id INT PRIMARY KEY , name VARCHAR ( 50 ) NOT NULL , price FLOAT , in_stock BOOLEAN , created_at DATE );","title":"Overview of different data types and how to use them"},{"location":"sql/07_creating_tables/#add-primary-and-foreign-keys-and-link-an-other-table","text":"In a relational database, a primary key is a unique identifier for each row in a table. It is used to ensure that each row can be uniquely identified and is commonly used to link to other tables in the database. A foreign key is a column in one table that refers to the primary key of another table. This is used to create relationships between tables and enforce referential integrity. Here is an example of creating a table with a primary key and a foreign key: CREATE TABLE orders ( id INT PRIMARY KEY , product_id INT , quantity INT , FOREIGN KEY ( product_id ) REFERENCES products ( id ) ); This creates a table named orders with three columns: id , product_id , and quantity . The id column is defined as the primary key for the table. The product_id column is defined as a foreign key that references the id column in the products table, which creates a relationship between the two tables. Here, the quantity column is defined as an integer.","title":"Add primary and foreign keys and link an other table"},{"location":"sql/08_insert/","text":"Inserting Data Once you have created a table, you can start inserting data into it. The process of inserting data involves specifying the table name, the columns to insert data into, and the values to be inserted. Overview of Different Insert Commands and Syntax There are a few different ways to insert data into a table in SQL, depending on how much information you have about the data you are inserting. Here are some common insert commands and their syntax: Inserting Values into Specific Columns You can use the INSERT INTO command to insert values into specific columns in a table. Here is the syntax for inserting a single row of data into a table: INSERT INTO table_name ( column1 , column2 , column3 , ...) VALUES ( value1 , value2 , value3 , ...); For example, to insert a new row into a users table with the values \"John Doe\" for the name column, \"johndoe@example.com\" for the email column, and 25 for the age column, you would use the following command: INSERT INTO users ( name , email , age ) VALUES ( 'John Doe' , 'johndoe@example.com' , 25 ); Inserting Values into All Columns If you have data to insert for every column in a table, you can omit the column names from the INSERT INTO command. Here is the syntax for inserting a single row of data into a table without specifying column names: INSERT INTO table_name VALUES ( value1 , value2 , value3 , ...); For example, to insert a new row into the users table with the values \"Jane Smith\" for the name column, \"janesmith@example.com\" for the email column, 30 for the age column, and \"female\" for the gender column, you would use the following command: INSERT INTO users VALUES ( 'Jane Smith' , 'janesmith@example.com' , 30 , 'female' ); Inserting Multiple Rows at Once You can also use the INSERT INTO command to insert multiple rows of data at once. Here is the syntax for inserting multiple rows of data into a table: INSERT INTO table_name ( column1 , column2 , column3 , ...) VALUES ( value1 , value2 , value3 , ...), ( value1 , value2 , value3 , ...), ( value1 , value2 , value3 , ...), ...; For example, to insert three new rows into the users table, you would use the following command: INSERT INTO users ( name , email , age ) VALUES ( 'Alice Johnson' , 'alicejohnson@example.com' , 35 ), ( 'Bob Williams' , 'bobwilliams@example.com' , 40 ), ( 'Charlie Brown' , 'charliebrown@example.com' , 45 ); By using these different insert commands and syntax, you can efficiently add data to your SQL database tables.","title":"Inserting Data"},{"location":"sql/08_insert/#inserting-data","text":"Once you have created a table, you can start inserting data into it. The process of inserting data involves specifying the table name, the columns to insert data into, and the values to be inserted.","title":"Inserting Data"},{"location":"sql/08_insert/#overview-of-different-insert-commands-and-syntax","text":"There are a few different ways to insert data into a table in SQL, depending on how much information you have about the data you are inserting. Here are some common insert commands and their syntax:","title":"Overview of Different Insert Commands and Syntax"},{"location":"sql/08_insert/#inserting-values-into-specific-columns","text":"You can use the INSERT INTO command to insert values into specific columns in a table. Here is the syntax for inserting a single row of data into a table: INSERT INTO table_name ( column1 , column2 , column3 , ...) VALUES ( value1 , value2 , value3 , ...); For example, to insert a new row into a users table with the values \"John Doe\" for the name column, \"johndoe@example.com\" for the email column, and 25 for the age column, you would use the following command: INSERT INTO users ( name , email , age ) VALUES ( 'John Doe' , 'johndoe@example.com' , 25 );","title":"Inserting Values into Specific Columns"},{"location":"sql/08_insert/#inserting-values-into-all-columns","text":"If you have data to insert for every column in a table, you can omit the column names from the INSERT INTO command. Here is the syntax for inserting a single row of data into a table without specifying column names: INSERT INTO table_name VALUES ( value1 , value2 , value3 , ...); For example, to insert a new row into the users table with the values \"Jane Smith\" for the name column, \"janesmith@example.com\" for the email column, 30 for the age column, and \"female\" for the gender column, you would use the following command: INSERT INTO users VALUES ( 'Jane Smith' , 'janesmith@example.com' , 30 , 'female' );","title":"Inserting Values into All Columns"},{"location":"sql/08_insert/#inserting-multiple-rows-at-once","text":"You can also use the INSERT INTO command to insert multiple rows of data at once. Here is the syntax for inserting multiple rows of data into a table: INSERT INTO table_name ( column1 , column2 , column3 , ...) VALUES ( value1 , value2 , value3 , ...), ( value1 , value2 , value3 , ...), ( value1 , value2 , value3 , ...), ...; For example, to insert three new rows into the users table, you would use the following command: INSERT INTO users ( name , email , age ) VALUES ( 'Alice Johnson' , 'alicejohnson@example.com' , 35 ), ( 'Bob Williams' , 'bobwilliams@example.com' , 40 ), ( 'Charlie Brown' , 'charliebrown@example.com' , 45 ); By using these different insert commands and syntax, you can efficiently add data to your SQL database tables.","title":"Inserting Multiple Rows at Once"},{"location":"sql/09_constraints/","text":"Constraints Constraints are rules that you can apply to a table in a database to enforce data integrity. They play a vital role in ensuring that the data within the database remains consistent and accurate. There are various types of constraints that can be applied to a table, each serving a specific purpose. Types of constraints One type of constraint is the primary key constraint, which enforces the uniqueness of a column or a group of columns within a table. Another type of constraint is the foreign key constraint, which establishes a relationship between two tables based on the values of their respective columns. Other types of constraints include the NOT NULL constraint, which ensures that a column cannot have a NULL value, and the UNIQUE constraint, which ensures that the values in a column are unique. Examples of customers table one without constraints and the other with constraints Without Constraints CREATE TABLE customers ( id INT , first_name VARCHAR ( 50 ), last_name VARCHAR ( 50 ), email VARCHAR ( 100 ) ); INSERT INTO customers ( id , first_name , last_name , email ) VALUES ( 1 , 'John' , 'Doe' , 'john.doe@example.com' ), ( 2 , 'Jane' , 'Doe' , 'jane.doe@example.com' ), ( 3 , 'Bob' , 'Smith' , 'bob.smith@example.com' ), ( 4 , 'Alice' , 'Johnson' , 'alice.johnson@example.com' ); In this example, we create a table named customers with four columns - id , first_name , last_name , and email . We then insert some sample data into the table. However, there are no constraints set on the table to enforce any rules about the data being inserted. For example, we can insert multiple rows with the same id value, which can lead to inconsistencies in the data. With Constraints CREATE TABLE customers ( id INT PRIMARY KEY , first_name VARCHAR ( 50 ) NOT NULL , last_name VARCHAR ( 50 ) NOT NULL , email VARCHAR ( 100 ) UNIQUE ); INSERT INTO customers ( id , first_name , last_name , email ) VALUES ( 1 , 'John' , 'Doe' , 'john.doe@example.com' ), ( 2 , 'Jane' , 'Doe' , 'jane.doe@example.com' ), ( 3 , 'Bob' , 'Smith' , 'bob.smith@example.com' ), ( 4 , 'Alice' , 'Johnson' , 'alice.johnson@example.com' ); INSERT INTO customers ( id , first_name , last_name , email ) VALUES ( 1 , 'Mark' , 'Smith' , 'mark.smith@example.com' ); -- This will fail due to duplicate primary key constraint INSERT INTO customers ( id , first_name , last_name , email ) VALUES ( 5 , 'Sam' , 'Jones' , 'bob.smith@example.com' ); -- This will fail due to unique constraint on email column In this example, we create the same customers table, but with additional constraints. We set the id column as the primary key, which means that it must be unique for each row. We also set the first_name and last_name columns as NOT NULL, which means that they cannot be empty. Finally, we set the email column as UNIQUE, which means that each email must be unique in the table. When we try to insert data into the table, the constraints are enforced. The first INSERT statement will work fine because it does not violate any constraints. However, the second INSERT statement will fail because it tries to insert a row with a duplicate id value, which violates the primary key constraint. Similarly, the third INSERT statement will fail because it tries to insert a row with a duplicate email value, which violates the unique constraint on the email column.","title":"Constraints"},{"location":"sql/09_constraints/#constraints","text":"Constraints are rules that you can apply to a table in a database to enforce data integrity. They play a vital role in ensuring that the data within the database remains consistent and accurate. There are various types of constraints that can be applied to a table, each serving a specific purpose.","title":"Constraints"},{"location":"sql/09_constraints/#types-of-constraints","text":"One type of constraint is the primary key constraint, which enforces the uniqueness of a column or a group of columns within a table. Another type of constraint is the foreign key constraint, which establishes a relationship between two tables based on the values of their respective columns. Other types of constraints include the NOT NULL constraint, which ensures that a column cannot have a NULL value, and the UNIQUE constraint, which ensures that the values in a column are unique.","title":"Types of constraints"},{"location":"sql/09_constraints/#examples-of-customers-table-one-without-constraints-and-the-other-with-constraints","text":"","title":"Examples of customers table one without constraints and the other with constraints"},{"location":"sql/09_constraints/#without-constraints","text":"CREATE TABLE customers ( id INT , first_name VARCHAR ( 50 ), last_name VARCHAR ( 50 ), email VARCHAR ( 100 ) ); INSERT INTO customers ( id , first_name , last_name , email ) VALUES ( 1 , 'John' , 'Doe' , 'john.doe@example.com' ), ( 2 , 'Jane' , 'Doe' , 'jane.doe@example.com' ), ( 3 , 'Bob' , 'Smith' , 'bob.smith@example.com' ), ( 4 , 'Alice' , 'Johnson' , 'alice.johnson@example.com' ); In this example, we create a table named customers with four columns - id , first_name , last_name , and email . We then insert some sample data into the table. However, there are no constraints set on the table to enforce any rules about the data being inserted. For example, we can insert multiple rows with the same id value, which can lead to inconsistencies in the data.","title":"Without Constraints"},{"location":"sql/09_constraints/#with-constraints","text":"CREATE TABLE customers ( id INT PRIMARY KEY , first_name VARCHAR ( 50 ) NOT NULL , last_name VARCHAR ( 50 ) NOT NULL , email VARCHAR ( 100 ) UNIQUE ); INSERT INTO customers ( id , first_name , last_name , email ) VALUES ( 1 , 'John' , 'Doe' , 'john.doe@example.com' ), ( 2 , 'Jane' , 'Doe' , 'jane.doe@example.com' ), ( 3 , 'Bob' , 'Smith' , 'bob.smith@example.com' ), ( 4 , 'Alice' , 'Johnson' , 'alice.johnson@example.com' ); INSERT INTO customers ( id , first_name , last_name , email ) VALUES ( 1 , 'Mark' , 'Smith' , 'mark.smith@example.com' ); -- This will fail due to duplicate primary key constraint INSERT INTO customers ( id , first_name , last_name , email ) VALUES ( 5 , 'Sam' , 'Jones' , 'bob.smith@example.com' ); -- This will fail due to unique constraint on email column In this example, we create the same customers table, but with additional constraints. We set the id column as the primary key, which means that it must be unique for each row. We also set the first_name and last_name columns as NOT NULL, which means that they cannot be empty. Finally, we set the email column as UNIQUE, which means that each email must be unique in the table. When we try to insert data into the table, the constraints are enforced. The first INSERT statement will work fine because it does not violate any constraints. However, the second INSERT statement will fail because it tries to insert a row with a duplicate id value, which violates the primary key constraint. Similarly, the third INSERT statement will fail because it tries to insert a row with a duplicate email value, which violates the unique constraint on the email column.","title":"With Constraints"},{"location":"sql/10_update_delete/","text":"Update & Delete In addition to inserting data into tables, you may also need to modify or delete existing data. The SQL language provides several commands for updating and deleting data within tables. Updating Data To update data within a table, you can use the UPDATE command followed by the name of the table and the SET keyword. The SET keyword is followed by the column name you want to update, an equals sign, and the new value you want to set. Here's the basic syntax for updating data in a table: UPDATE table_name SET column_name = new_value WHERE condition ; In this syntax, the WHERE clause specifies which rows to update. Without a WHERE clause, all rows in the table would be updated. Here's an example that updates the price of a product in a table called products : UPDATE products SET price = 19 . 99 WHERE product_id = 1234 ; This statement updates the price column for the row where the product_id is equal to 1234. Deleting Data To delete data from a table, you can use the DELETE command followed by the name of the table. If you want to delete only certain rows, you can use a WHERE clause to specify which rows to delete. Here's the basic syntax for deleting data from a table: DELETE FROM table_name WHERE condition ; Here's an example that deletes a row from a table called orders : DELETE FROM orders WHERE order_id = 5678 ; This statement deletes only the row where the order_id is equal to 5678. Summarize : creating, inserting, updating and deleting Let's summarize the previous notions with an SQL example code to create a table, insert values into it, and update a field : -- Creating a table for products CREATE TABLE products ( id INT PRIMARY KEY , name VARCHAR ( 50 ), category VARCHAR ( 50 ), price DECIMAL ( 8 , 2 ) ); -- Inserting data into the table INSERT INTO products ( id , name , category , price ) VALUES ( 1 , 'Product A' , 'Category 1' , 10 . 99 ), ( 2 , 'Product B' , 'Category 2' , 19 . 99 ), ( 3 , 'Product C' , 'Category 1' , 5 . 99 ); -- Updating the price of Product A UPDATE products SET price = 12 . 99 WHERE id = 1 ; -- Deleting a record from the 'products' table DELETE FROM products WHERE product_id = 2 ; In this example, we first create a table named products with four columns: id , name , category , and price . We define the id column as the primary key, meaning it uniquely identifies each row in the table. Next, we insert three rows of data into the table using the INSERT INTO command. Each row represents a different product, with values for the id , name , category , and price columns. Finally, we update the price of Product A using the UPDATE command. We specify the table we want to update ( products ), the field we want to update ( price ), and the new value we want to set (12.99) . We use the WHERE clause to specify which row(s) we want to update; in this case, we only want to update the row with an id of 1 , which corresponds to Product A . Then, the DELETE command is used to remove the record from the products table where the value of the product_id field is equal to 2 . This will delete the second product from the table, which in this case is Product B . Deleting a single field in a row Here's an example of deleting a single field in a row of the products table: -- Delete the description of the product with id 3 UPDATE products SET description = NULL WHERE id = 3 ; In this example, we use the UPDATE command to modify the description field of the row with id equal to 3 . The SET keyword is used to specify the new value of the description field, which we set to NULL to delete the existing value. The WHERE clause is used to specify which row(s) to update. In this case, we're only updating the row with id equal to 3 . By setting the description field to NULL , we effectively delete the value of that field for that particular row.","title":"Update & Delete"},{"location":"sql/10_update_delete/#update-delete","text":"In addition to inserting data into tables, you may also need to modify or delete existing data. The SQL language provides several commands for updating and deleting data within tables.","title":"Update &amp; Delete"},{"location":"sql/10_update_delete/#updating-data","text":"To update data within a table, you can use the UPDATE command followed by the name of the table and the SET keyword. The SET keyword is followed by the column name you want to update, an equals sign, and the new value you want to set. Here's the basic syntax for updating data in a table: UPDATE table_name SET column_name = new_value WHERE condition ; In this syntax, the WHERE clause specifies which rows to update. Without a WHERE clause, all rows in the table would be updated. Here's an example that updates the price of a product in a table called products : UPDATE products SET price = 19 . 99 WHERE product_id = 1234 ; This statement updates the price column for the row where the product_id is equal to 1234.","title":"Updating Data"},{"location":"sql/10_update_delete/#deleting-data","text":"To delete data from a table, you can use the DELETE command followed by the name of the table. If you want to delete only certain rows, you can use a WHERE clause to specify which rows to delete. Here's the basic syntax for deleting data from a table: DELETE FROM table_name WHERE condition ; Here's an example that deletes a row from a table called orders : DELETE FROM orders WHERE order_id = 5678 ; This statement deletes only the row where the order_id is equal to 5678.","title":"Deleting Data"},{"location":"sql/10_update_delete/#summarize-creating-inserting-updating-and-deleting","text":"Let's summarize the previous notions with an SQL example code to create a table, insert values into it, and update a field : -- Creating a table for products CREATE TABLE products ( id INT PRIMARY KEY , name VARCHAR ( 50 ), category VARCHAR ( 50 ), price DECIMAL ( 8 , 2 ) ); -- Inserting data into the table INSERT INTO products ( id , name , category , price ) VALUES ( 1 , 'Product A' , 'Category 1' , 10 . 99 ), ( 2 , 'Product B' , 'Category 2' , 19 . 99 ), ( 3 , 'Product C' , 'Category 1' , 5 . 99 ); -- Updating the price of Product A UPDATE products SET price = 12 . 99 WHERE id = 1 ; -- Deleting a record from the 'products' table DELETE FROM products WHERE product_id = 2 ; In this example, we first create a table named products with four columns: id , name , category , and price . We define the id column as the primary key, meaning it uniquely identifies each row in the table. Next, we insert three rows of data into the table using the INSERT INTO command. Each row represents a different product, with values for the id , name , category , and price columns. Finally, we update the price of Product A using the UPDATE command. We specify the table we want to update ( products ), the field we want to update ( price ), and the new value we want to set (12.99) . We use the WHERE clause to specify which row(s) we want to update; in this case, we only want to update the row with an id of 1 , which corresponds to Product A . Then, the DELETE command is used to remove the record from the products table where the value of the product_id field is equal to 2 . This will delete the second product from the table, which in this case is Product B .","title":"Summarize : creating, inserting, updating and deleting"},{"location":"sql/10_update_delete/#deleting-a-single-field-in-a-row","text":"Here's an example of deleting a single field in a row of the products table: -- Delete the description of the product with id 3 UPDATE products SET description = NULL WHERE id = 3 ; In this example, we use the UPDATE command to modify the description field of the row with id equal to 3 . The SET keyword is used to specify the new value of the description field, which we set to NULL to delete the existing value. The WHERE clause is used to specify which row(s) to update. In this case, we're only updating the row with id equal to 3 . By setting the description field to NULL , we effectively delete the value of that field for that particular row.","title":"Deleting a single field in a row"},{"location":"sql/11_queries/","text":"Basic Queries In the world of database management, tables and queries go hand in hand. Queries are a fundamental component of any database, as they allow you to retrieve and manipulate data in meaningful ways. In this chapter, we will explore the basics of SQL queries and how they are used to extract data from tables. To demonstrate this, we will use two example tables, the orders and customers tables. These tables will be linked together using a foreign key to show how queries can retrieve data from multiple tables at once. Understanding queries and the relationship between tables is essential for effective database management, as it enables developers to extract valuable insights and make informed decisions based on data. This is the example table called customers : CREATE TABLE customers ( id INT PRIMARY KEY , first_name VARCHAR ( 50 ), last_name VARCHAR ( 50 ), email VARCHAR ( 100 ), address VARCHAR ( 100 ), city VARCHAR ( 50 ), state VARCHAR ( 50 ), zip_code VARCHAR ( 20 ) ); This table has columns for a customer's ID, first name, last name, email address, street address, city, state, and zip code. The id column is the primary key for the table, which means that each row in the table is uniquely identified by its value in the id column. This is the example of an orders table: CREATE TABLE orders ( order_id INT PRIMARY KEY , customer_id INT , order_date DATE , total_price DECIMAL ( 10 , 2 ) ); This table has four columns: order_id , customer_id , order_date , and total_price . The order_id column is the primary key of the table, which means that each row has a unique value in that column. The customer_id column is a foreign key that references the customer_id column in the customers table. This establishes a relationship between the two tables. The orders table contains information about each order placed by a customer. The customer_id column is used to link each order to a specific customer in the customers table. The order_date column contains the date that the order was placed, and the total_price column contains the total price of the order. By joining the orders table with the customers table on the customer_id column, we can retrieve information about both the customer and their order in a single query. Overview of Different SELECT Commands and Syntax The SELECT statement has a variety of options for retrieving and manipulating data. Here are some examples: The WHERE clause is used to filter data based on a specified condition: SELECT * FROM customers WHERE city = 'London' ; This statement retrieves all columns and rows from the customers table where the city is London . The ORDER BY clause is used to sort data by one or more columns: SELECT * FROM customers ORDER BY last_name ; This statement retrieves all columns and rows from the customers table, sorted by the last_name column. The GROUP BY clause is used to group data by one or more columns: SELECT city , COUNT ( * ) FROM customers GROUP BY city ; This statement retrieves the city column and a count of how many times each city appears in the customers table. The JOIN command is used to combine data from two or more tables: SELECT * FROM customers JOIN orders ON customers . customer_id = orders . customer_id ; This statement retrieves all columns and rows from both the customers and orders tables where the customer_id column matches in both tables.","title":"Basic Queries"},{"location":"sql/11_queries/#basic-queries","text":"In the world of database management, tables and queries go hand in hand. Queries are a fundamental component of any database, as they allow you to retrieve and manipulate data in meaningful ways. In this chapter, we will explore the basics of SQL queries and how they are used to extract data from tables. To demonstrate this, we will use two example tables, the orders and customers tables. These tables will be linked together using a foreign key to show how queries can retrieve data from multiple tables at once. Understanding queries and the relationship between tables is essential for effective database management, as it enables developers to extract valuable insights and make informed decisions based on data. This is the example table called customers : CREATE TABLE customers ( id INT PRIMARY KEY , first_name VARCHAR ( 50 ), last_name VARCHAR ( 50 ), email VARCHAR ( 100 ), address VARCHAR ( 100 ), city VARCHAR ( 50 ), state VARCHAR ( 50 ), zip_code VARCHAR ( 20 ) ); This table has columns for a customer's ID, first name, last name, email address, street address, city, state, and zip code. The id column is the primary key for the table, which means that each row in the table is uniquely identified by its value in the id column. This is the example of an orders table: CREATE TABLE orders ( order_id INT PRIMARY KEY , customer_id INT , order_date DATE , total_price DECIMAL ( 10 , 2 ) ); This table has four columns: order_id , customer_id , order_date , and total_price . The order_id column is the primary key of the table, which means that each row has a unique value in that column. The customer_id column is a foreign key that references the customer_id column in the customers table. This establishes a relationship between the two tables. The orders table contains information about each order placed by a customer. The customer_id column is used to link each order to a specific customer in the customers table. The order_date column contains the date that the order was placed, and the total_price column contains the total price of the order. By joining the orders table with the customers table on the customer_id column, we can retrieve information about both the customer and their order in a single query.","title":"Basic Queries"},{"location":"sql/11_queries/#overview-of-different-select-commands-and-syntax","text":"The SELECT statement has a variety of options for retrieving and manipulating data. Here are some examples: The WHERE clause is used to filter data based on a specified condition: SELECT * FROM customers WHERE city = 'London' ; This statement retrieves all columns and rows from the customers table where the city is London . The ORDER BY clause is used to sort data by one or more columns: SELECT * FROM customers ORDER BY last_name ; This statement retrieves all columns and rows from the customers table, sorted by the last_name column. The GROUP BY clause is used to group data by one or more columns: SELECT city , COUNT ( * ) FROM customers GROUP BY city ; This statement retrieves the city column and a count of how many times each city appears in the customers table. The JOIN command is used to combine data from two or more tables: SELECT * FROM customers JOIN orders ON customers . customer_id = orders . customer_id ; This statement retrieves all columns and rows from both the customers and orders tables where the customer_id column matches in both tables.","title":"Overview of Different SELECT Commands and Syntax"},{"location":"sql/12_company_db_1/","text":"Company Database Introduction In the modern era of technology, most businesses depend on software to manage and track various aspects of their operations. One of the most important types of software that businesses rely on is the database management system (DBMS). A DBMS allows companies to store, manage, and retrieve information in a structured and organized way. A company database is a type of DBMS that is specifically designed to help organizations store and manage information about their employees, customers, products, and services. A company database can be used for a wide range of purposes, such as tracking inventory, processing transactions, generating reports, and analyzing data. By keeping all the relevant information in a centralized location, a company database provides a more efficient and accurate way to manage and analyze data. This, in turn, enables businesses to make informed decisions based on reliable and up-to-date information. Having a well-designed and properly maintained company database is vital to the success of any business. A good company database can help to improve operational efficiency, streamline processes, and enhance customer satisfaction. It can also help organizations to identify trends, analyze performance, and make strategic decisions based on real data. In this chapter, we will explore the various components of a company database, including tables, fields, and relationships. We will also learn how to design and build a company database from scratch, as well as how to use SQL to retrieve, analyze, and manipulate data. By the end of this tutorial, you should have a good understanding how to build a database from scratch for your own business or project. Summary of the project This project will focus on building a company database that includes seven tables: employees departments projects department_projects employee_projects jobs location These tables will be linked together using foreign keys and relationships, allowing organizations to easily access and manage information. The project will also include the creation of primary keys, indexes, and constraints to ensure the integrity and consistency of the data. This database will provide a robust platform for companies to store, organize, and access data in a way that enhances their ability to make data-driven decisions. Set up the project Start by opening your MySQL client and connecting to your server. In our case just start MySQL Workbench like in the installation section. Database creation Create a new database call company with the graphic interface like in the installation section or with the SQL command line : CREATE DATABASE company ; if you used the command line option run also this command : USE company; like you've guess it just tell to MySQL to use our database for the futur queries. Tables creation This is the SQL script that creates the necessary tables : CREATE DATABASE company ; USE company ; -- Create the jobs table CREATE TABLE jobs ( job_id INT PRIMARY KEY , job_title VARCHAR ( 50 ), min_salary DECIMAL ( 10 , 2 ), max_salary DECIMAL ( 10 , 2 ) ); -- Create the locations table CREATE TABLE locations ( location_id INT PRIMARY KEY , city VARCHAR ( 50 ), state VARCHAR ( 50 ), country VARCHAR ( 50 ), ); -- Create the departments table CREATE TABLE departments ( department_id INT PRIMARY KEY , department_name VARCHAR ( 50 ), location_id INT , FOREIGN KEY ( location_id ) REFERENCES locations ( location_id ) ); -- Create the employees table CREATE TABLE employees ( employee_id INT PRIMARY KEY , first_name VARCHAR ( 50 ), last_name VARCHAR ( 50 ), email VARCHAR ( 50 ), phone_number VARCHAR ( 20 ), hire_date DATE , job_id INT , salary DECIMAL ( 10 , 2 ), department_id INT , FOREIGN KEY ( job_id ) REFERENCES jobs ( job_id ), FOREIGN KEY ( department_id ) REFERENCES departments ( department_id ) ); -- Create the projects table CREATE TABLE projects ( project_id INT PRIMARY KEY , project_name VARCHAR ( 50 ), start_date DATE , end_date DATE , estimated_cost DECIMAL ( 10 , 2 ) ); -- Create the department_projects table CREATE TABLE department_projects ( department_id INT , project_id INT , PRIMARY KEY ( department_id , project_id ), FOREIGN KEY ( department_id ) REFERENCES departments ( department_id ), FOREIGN KEY ( project_id ) REFERENCES projects ( project_id ) ); -- Create the employee_projects table CREATE TABLE employee_projects ( employee_id INT , project_id INT , PRIMARY KEY ( employee_id , project_id ), FOREIGN KEY ( employee_id ) REFERENCES employees ( employee_id ), FOREIGN KEY ( project_id ) REFERENCES projects ( project_id ) ); Note that the foreign keys are created using the CONSTRAINT keyword and the REFERENCES keyword to specify the table and column to which the key refers. The AUTO_INCREMENT keyword is used to specify that the primary key column should automatically increment for each new row. Insert data Then populate the tables with this script : -- insert 10 rows into jobs table INSERT INTO jobs ( job_id , job_title , min_salary , max_salary ) VALUES ( 1 , 'Manager' , 70000 , 120000 ), ( 2 , 'Salesperson' , 20000 , 40000 ), ( 3 , 'Developer' , 50000 , 100000 ), ( 4 , 'Accountant' , 35000 , 60000 ), ( 5 , 'HR Manager' , 45000 , 80000 ), ( 6 , 'Marketing Specialist' , 40000 , 75000 ), ( 7 , 'Administrative Assistant' , 25000 , 35000 ), ( 8 , 'Designer' , 45000 , 80000 ), ( 9 , 'Writer' , 30000 , 50000 ), ( 10 , 'Engineer' , 55000 , 90000 ); -- insert 10 rows into location table INSERT INTO locations ( location_id , city , state , country ) VALUES ( 1 , 'New York' , 'NY' , 'USA' ), ( 2 , 'Los Angeles' , 'CA' , 'USA' ), ( 3 , 'San Francisco' , 'CA' , 'USA' ), ( 4 , 'Chicago' , 'IL' , 'USA' ), ( 5 , 'Houston' , 'TX' , 'USA' ), ( 6 , 'London' , NULL , 'England' ), ( 7 , 'Paris' , NULL , 'France' ), ( 8 , 'Berlin' , NULL , 'Germany' ), ( 9 , 'Sydney' , NULL , 'Australia' ), ( 10 , 'Tokyo' , NULL , 'Japan' ); -- insert 5 rows into departments table INSERT INTO departments ( department_id , department_name , location_id ) VALUES ( 1 , 'Engineering' , 1 ), ( 2 , 'Sales' , 2 ), ( 3 , 'Administration' , 2 ), ( 4 , 'Marketing' , 3 ), ( 5 , 'Data pole' , 1 ); -- Insert 10 employees INSERT INTO employees ( employee_id , first_name , last_name , email , phone_number , hire_date , job_id , salary , department_id ) VALUES ( 1 , 'John' , 'Doe' , 'johndoe@example.com' , '555-555-1234' , '2022-01-01' , 1 , 50000 , 1 ), ( 2 , 'Jane' , 'Doe' , 'janedoe@example.com' , '555-555-5678' , '2022-01-01' , 2 , 60000 , 1 ), ( 3 , 'Bob' , 'Smith' , 'bobsmith@example.com' , '555-555-9012' , '2022-02-01' , 3 , 75000 , 2 ), ( 4 , 'Alice' , 'Johnson' , 'alicejohnson@example.com' , '555-555-3456' , '2022-02-01' , 4 , 85000 , 2 ), ( 5 , 'Mark' , 'Lee' , 'marklee@example.com' , '555-555-7890' , '2022-03-01' , 5 , 95000 , 3 ), ( 6 , 'Emily' , 'Chen' , 'emilychen@example.com' , '555-555-2345' , '2022-03-01' , 5 , 80000 , 3 ), ( 7 , 'Sara' , 'Kim' , 'sarakim@example.com' , '555-555-6789' , '2022-04-01' , 6 , 70000 , 4 ), ( 8 , 'Michael' , 'Wu' , 'michaelwu@example.com' , '555-555-0123' , '2022-04-01' , 7 , 65000 , 4 ), ( 9 , 'David' , 'Nguyen' , 'davidnguyen@example.com' , '555-555-4567' , '2022-05-01' , 8 , 55000 , 5 ), ( 10 , 'Jennifer' , 'Garcia' , 'jennifergarcia@example.com' , '555-555-8901' , '2022-05-01' , 9 , 60000 , 5 ); -- Insert 4 projects INSERT INTO projects ( project_id , project_name , start_date , end_date , estimated_cost ) VALUES ( 1 , 'Website Redesign' , '2022-01-01' , '2022-06-30' , 50000 ), ( 2 , 'Sales Campaign' , '2022-02-01' , '2022-04-30' , 120000 ), ( 3 , 'Database Migration' , '2022-03-01' , '2022-08-31' , 140000 ), ( 4 , 'NLP' , '2022-04-01' , '2022-07-01' , 8000 ); -- insert 10 rows into department_projects table INSERT INTO department_projects ( department_id , project_id ) VALUES ( 1 , 1 ), ( 1 , 2 ), ( 2 , 1 ), ( 2 , 3 ), ( 3 , 2 ), ( 3 , 3 ), ( 4 , 1 ), ( 4 , 2 ), ( 5 , 1 ), ( 5 , 3 ); -- Insert 10 rows into the employee_projects table INSERT INTO employee_projects ( employee_id , project_id ) VALUES ( 1 , 1 ), ( 1 , 2 ), ( 2 , 1 ), ( 2 , 3 ), ( 3 , 2 ), ( 3 , 3 ), ( 4 , 2 ), ( 4 , 1 ), ( 5 , 3 ), ( 5 , 1 ); Tests some queries for verification --> TO TEST Let's take a look to ten example queries to verify the data in the seven tables: Retrieve all employees who work in the \"Sales\" department: SELECT e.first_name, e.last_name, d.department_name FROM employees e JOIN departments d ON e.department_id = d.department_id WHERE d.department_name = 'Sales'; Retrieve all projects that are assigned to the \"Marketing\" department: SELECT p.project_name, d.department_name FROM projects p JOIN department_projects dp ON p.project_id = dp.project_id JOIN departments d ON dp.department_id = d.department_id WHERE d.department_name = 'Marketing'; Retrieve all projects that have an estimated cost greater than $100,000: SELECT project_name, estimated_cost FROM projects WHERE estimated_cost > 100000; Retrieve all employees who are working on the \"Database Migration\": SELECT e.first_name, e.last_name, p.project_name FROM employees e JOIN employee_projects ep ON e.employee_id = ep.employee_id JOIN projects p ON ep.project_id = p.project_id WHERE p.project_name = 'Database Migration'; Retrieve all job titles and the number of employees who hold each job title: SELECT j.job_title, COUNT(*) AS num_employees FROM employees e JOIN jobs j ON e.job_id = j.job_id GROUP BY j.job_title; List all employees and their department: SELECT e.employee_id, e.first_name, e.last_name, d.department_name FROM employees e INNER JOIN departments d ON e.department_id = d.department_id; List all departments and their location: SELECT d.department_name, l.city, l.state FROM departments d INNER JOIN locations l ON d.location_id = l.location_id; List all projects and their department: SELECT p.project_id, p.project_name, d.department_name FROM projects p INNER JOIN department_projects dp ON p.project_id = dp.project_id INNER JOIN departments d ON dp.department_id = d.department_id; List all employees and the projects they are working on: SELECT e.first_name, e.last_name, p.project_name FROM employees e INNER JOIN employee_projects ep ON e.employee_id = ep.employee_id INNER JOIN projects p ON ep.project_id = p.project_id; List all employees, their job title, and salary: SELECT e.first_name, e.last_name, j.job_title, e.salary FROM employees e INNER JOIN jobs j ON e.job_id = j.job_id; The importance of schema and organization Creating a schema and diagrams for a database is critical, especially when dealing with large databases with many tables and relationships. Without proper organization and documentation, it can be challenging to understand the structure and relationships between different tables. This is particularly true when many people are working on the database or when there is a lot of data being added and updated regularly. Having a clear schema and diagrams can help developers and users understand the structure and relationships of the data, leading to more efficient and effective use of the database. Additionally, it can help to identify and prevent errors in the data or in the database design itself. Overall, investing time in creating a clear schema and diagrams can save time and resources in the long run and make the database easier to manage and use. Wrap-up In this project, we learned how to create a company database using MySQL. We created 7 tables: employees, departments, projects, department_projects, employee_projects, jobs, and location. We added primary keys to all tables with auto-increment options for unique identification and added foreign keys to establish relationships between tables. We inserted data into each table and test some queries. We also learned about the importance of schema and diagrams for databases, especially as the number of tables and relationships grows, and the significance of foreign keys in ensuring data integrity and consistency.","title":"Company Database Introduction"},{"location":"sql/12_company_db_1/#company-database-introduction","text":"In the modern era of technology, most businesses depend on software to manage and track various aspects of their operations. One of the most important types of software that businesses rely on is the database management system (DBMS). A DBMS allows companies to store, manage, and retrieve information in a structured and organized way. A company database is a type of DBMS that is specifically designed to help organizations store and manage information about their employees, customers, products, and services. A company database can be used for a wide range of purposes, such as tracking inventory, processing transactions, generating reports, and analyzing data. By keeping all the relevant information in a centralized location, a company database provides a more efficient and accurate way to manage and analyze data. This, in turn, enables businesses to make informed decisions based on reliable and up-to-date information. Having a well-designed and properly maintained company database is vital to the success of any business. A good company database can help to improve operational efficiency, streamline processes, and enhance customer satisfaction. It can also help organizations to identify trends, analyze performance, and make strategic decisions based on real data. In this chapter, we will explore the various components of a company database, including tables, fields, and relationships. We will also learn how to design and build a company database from scratch, as well as how to use SQL to retrieve, analyze, and manipulate data. By the end of this tutorial, you should have a good understanding how to build a database from scratch for your own business or project.","title":"Company Database Introduction"},{"location":"sql/12_company_db_1/#summary-of-the-project","text":"This project will focus on building a company database that includes seven tables: employees departments projects department_projects employee_projects jobs location These tables will be linked together using foreign keys and relationships, allowing organizations to easily access and manage information. The project will also include the creation of primary keys, indexes, and constraints to ensure the integrity and consistency of the data. This database will provide a robust platform for companies to store, organize, and access data in a way that enhances their ability to make data-driven decisions.","title":"Summary of the project"},{"location":"sql/12_company_db_1/#set-up-the-project","text":"Start by opening your MySQL client and connecting to your server. In our case just start MySQL Workbench like in the installation section.","title":"Set up the project"},{"location":"sql/12_company_db_1/#database-creation","text":"Create a new database call company with the graphic interface like in the installation section or with the SQL command line : CREATE DATABASE company ; if you used the command line option run also this command : USE company; like you've guess it just tell to MySQL to use our database for the futur queries.","title":"Database creation"},{"location":"sql/12_company_db_1/#tables-creation","text":"This is the SQL script that creates the necessary tables : CREATE DATABASE company ; USE company ; -- Create the jobs table CREATE TABLE jobs ( job_id INT PRIMARY KEY , job_title VARCHAR ( 50 ), min_salary DECIMAL ( 10 , 2 ), max_salary DECIMAL ( 10 , 2 ) ); -- Create the locations table CREATE TABLE locations ( location_id INT PRIMARY KEY , city VARCHAR ( 50 ), state VARCHAR ( 50 ), country VARCHAR ( 50 ), ); -- Create the departments table CREATE TABLE departments ( department_id INT PRIMARY KEY , department_name VARCHAR ( 50 ), location_id INT , FOREIGN KEY ( location_id ) REFERENCES locations ( location_id ) ); -- Create the employees table CREATE TABLE employees ( employee_id INT PRIMARY KEY , first_name VARCHAR ( 50 ), last_name VARCHAR ( 50 ), email VARCHAR ( 50 ), phone_number VARCHAR ( 20 ), hire_date DATE , job_id INT , salary DECIMAL ( 10 , 2 ), department_id INT , FOREIGN KEY ( job_id ) REFERENCES jobs ( job_id ), FOREIGN KEY ( department_id ) REFERENCES departments ( department_id ) ); -- Create the projects table CREATE TABLE projects ( project_id INT PRIMARY KEY , project_name VARCHAR ( 50 ), start_date DATE , end_date DATE , estimated_cost DECIMAL ( 10 , 2 ) ); -- Create the department_projects table CREATE TABLE department_projects ( department_id INT , project_id INT , PRIMARY KEY ( department_id , project_id ), FOREIGN KEY ( department_id ) REFERENCES departments ( department_id ), FOREIGN KEY ( project_id ) REFERENCES projects ( project_id ) ); -- Create the employee_projects table CREATE TABLE employee_projects ( employee_id INT , project_id INT , PRIMARY KEY ( employee_id , project_id ), FOREIGN KEY ( employee_id ) REFERENCES employees ( employee_id ), FOREIGN KEY ( project_id ) REFERENCES projects ( project_id ) ); Note that the foreign keys are created using the CONSTRAINT keyword and the REFERENCES keyword to specify the table and column to which the key refers. The AUTO_INCREMENT keyword is used to specify that the primary key column should automatically increment for each new row.","title":"Tables creation"},{"location":"sql/12_company_db_1/#insert-data","text":"Then populate the tables with this script : -- insert 10 rows into jobs table INSERT INTO jobs ( job_id , job_title , min_salary , max_salary ) VALUES ( 1 , 'Manager' , 70000 , 120000 ), ( 2 , 'Salesperson' , 20000 , 40000 ), ( 3 , 'Developer' , 50000 , 100000 ), ( 4 , 'Accountant' , 35000 , 60000 ), ( 5 , 'HR Manager' , 45000 , 80000 ), ( 6 , 'Marketing Specialist' , 40000 , 75000 ), ( 7 , 'Administrative Assistant' , 25000 , 35000 ), ( 8 , 'Designer' , 45000 , 80000 ), ( 9 , 'Writer' , 30000 , 50000 ), ( 10 , 'Engineer' , 55000 , 90000 ); -- insert 10 rows into location table INSERT INTO locations ( location_id , city , state , country ) VALUES ( 1 , 'New York' , 'NY' , 'USA' ), ( 2 , 'Los Angeles' , 'CA' , 'USA' ), ( 3 , 'San Francisco' , 'CA' , 'USA' ), ( 4 , 'Chicago' , 'IL' , 'USA' ), ( 5 , 'Houston' , 'TX' , 'USA' ), ( 6 , 'London' , NULL , 'England' ), ( 7 , 'Paris' , NULL , 'France' ), ( 8 , 'Berlin' , NULL , 'Germany' ), ( 9 , 'Sydney' , NULL , 'Australia' ), ( 10 , 'Tokyo' , NULL , 'Japan' ); -- insert 5 rows into departments table INSERT INTO departments ( department_id , department_name , location_id ) VALUES ( 1 , 'Engineering' , 1 ), ( 2 , 'Sales' , 2 ), ( 3 , 'Administration' , 2 ), ( 4 , 'Marketing' , 3 ), ( 5 , 'Data pole' , 1 ); -- Insert 10 employees INSERT INTO employees ( employee_id , first_name , last_name , email , phone_number , hire_date , job_id , salary , department_id ) VALUES ( 1 , 'John' , 'Doe' , 'johndoe@example.com' , '555-555-1234' , '2022-01-01' , 1 , 50000 , 1 ), ( 2 , 'Jane' , 'Doe' , 'janedoe@example.com' , '555-555-5678' , '2022-01-01' , 2 , 60000 , 1 ), ( 3 , 'Bob' , 'Smith' , 'bobsmith@example.com' , '555-555-9012' , '2022-02-01' , 3 , 75000 , 2 ), ( 4 , 'Alice' , 'Johnson' , 'alicejohnson@example.com' , '555-555-3456' , '2022-02-01' , 4 , 85000 , 2 ), ( 5 , 'Mark' , 'Lee' , 'marklee@example.com' , '555-555-7890' , '2022-03-01' , 5 , 95000 , 3 ), ( 6 , 'Emily' , 'Chen' , 'emilychen@example.com' , '555-555-2345' , '2022-03-01' , 5 , 80000 , 3 ), ( 7 , 'Sara' , 'Kim' , 'sarakim@example.com' , '555-555-6789' , '2022-04-01' , 6 , 70000 , 4 ), ( 8 , 'Michael' , 'Wu' , 'michaelwu@example.com' , '555-555-0123' , '2022-04-01' , 7 , 65000 , 4 ), ( 9 , 'David' , 'Nguyen' , 'davidnguyen@example.com' , '555-555-4567' , '2022-05-01' , 8 , 55000 , 5 ), ( 10 , 'Jennifer' , 'Garcia' , 'jennifergarcia@example.com' , '555-555-8901' , '2022-05-01' , 9 , 60000 , 5 ); -- Insert 4 projects INSERT INTO projects ( project_id , project_name , start_date , end_date , estimated_cost ) VALUES ( 1 , 'Website Redesign' , '2022-01-01' , '2022-06-30' , 50000 ), ( 2 , 'Sales Campaign' , '2022-02-01' , '2022-04-30' , 120000 ), ( 3 , 'Database Migration' , '2022-03-01' , '2022-08-31' , 140000 ), ( 4 , 'NLP' , '2022-04-01' , '2022-07-01' , 8000 ); -- insert 10 rows into department_projects table INSERT INTO department_projects ( department_id , project_id ) VALUES ( 1 , 1 ), ( 1 , 2 ), ( 2 , 1 ), ( 2 , 3 ), ( 3 , 2 ), ( 3 , 3 ), ( 4 , 1 ), ( 4 , 2 ), ( 5 , 1 ), ( 5 , 3 ); -- Insert 10 rows into the employee_projects table INSERT INTO employee_projects ( employee_id , project_id ) VALUES ( 1 , 1 ), ( 1 , 2 ), ( 2 , 1 ), ( 2 , 3 ), ( 3 , 2 ), ( 3 , 3 ), ( 4 , 2 ), ( 4 , 1 ), ( 5 , 3 ), ( 5 , 1 );","title":"Insert data"},{"location":"sql/12_company_db_1/#tests-some-queries-for-verification-to-test","text":"Let's take a look to ten example queries to verify the data in the seven tables: Retrieve all employees who work in the \"Sales\" department: SELECT e.first_name, e.last_name, d.department_name FROM employees e JOIN departments d ON e.department_id = d.department_id WHERE d.department_name = 'Sales'; Retrieve all projects that are assigned to the \"Marketing\" department: SELECT p.project_name, d.department_name FROM projects p JOIN department_projects dp ON p.project_id = dp.project_id JOIN departments d ON dp.department_id = d.department_id WHERE d.department_name = 'Marketing'; Retrieve all projects that have an estimated cost greater than $100,000: SELECT project_name, estimated_cost FROM projects WHERE estimated_cost > 100000; Retrieve all employees who are working on the \"Database Migration\": SELECT e.first_name, e.last_name, p.project_name FROM employees e JOIN employee_projects ep ON e.employee_id = ep.employee_id JOIN projects p ON ep.project_id = p.project_id WHERE p.project_name = 'Database Migration'; Retrieve all job titles and the number of employees who hold each job title: SELECT j.job_title, COUNT(*) AS num_employees FROM employees e JOIN jobs j ON e.job_id = j.job_id GROUP BY j.job_title; List all employees and their department: SELECT e.employee_id, e.first_name, e.last_name, d.department_name FROM employees e INNER JOIN departments d ON e.department_id = d.department_id; List all departments and their location: SELECT d.department_name, l.city, l.state FROM departments d INNER JOIN locations l ON d.location_id = l.location_id; List all projects and their department: SELECT p.project_id, p.project_name, d.department_name FROM projects p INNER JOIN department_projects dp ON p.project_id = dp.project_id INNER JOIN departments d ON dp.department_id = d.department_id; List all employees and the projects they are working on: SELECT e.first_name, e.last_name, p.project_name FROM employees e INNER JOIN employee_projects ep ON e.employee_id = ep.employee_id INNER JOIN projects p ON ep.project_id = p.project_id; List all employees, their job title, and salary: SELECT e.first_name, e.last_name, j.job_title, e.salary FROM employees e INNER JOIN jobs j ON e.job_id = j.job_id;","title":"Tests some queries for verification --&gt; TO TEST"},{"location":"sql/12_company_db_1/#the-importance-of-schema-and-organization","text":"Creating a schema and diagrams for a database is critical, especially when dealing with large databases with many tables and relationships. Without proper organization and documentation, it can be challenging to understand the structure and relationships between different tables. This is particularly true when many people are working on the database or when there is a lot of data being added and updated regularly. Having a clear schema and diagrams can help developers and users understand the structure and relationships of the data, leading to more efficient and effective use of the database. Additionally, it can help to identify and prevent errors in the data or in the database design itself. Overall, investing time in creating a clear schema and diagrams can save time and resources in the long run and make the database easier to manage and use.","title":"The importance of schema and organization"},{"location":"sql/12_company_db_1/#wrap-up","text":"In this project, we learned how to create a company database using MySQL. We created 7 tables: employees, departments, projects, department_projects, employee_projects, jobs, and location. We added primary keys to all tables with auto-increment options for unique identification and added foreign keys to establish relationships between tables. We inserted data into each table and test some queries. We also learned about the importance of schema and diagrams for databases, especially as the number of tables and relationships grows, and the significance of foreign keys in ensuring data integrity and consistency.","title":"Wrap-up"},{"location":"sql/13_queries_db/","text":"More queries In this chapter we will be working on the MySQL Sample Database. The MySQL Sample Database provides a sample database called \"employees\" that you can use to practice SQL queries. You can download the database and load it into your MySQL server. Link to the database Download the database and load it into MySQLWorkbench \ud83d\udea7 You need to run MySQL server (with MAMP for example) before lunching MySQLWorkbench \ud83d\udea7 Dowload the MySQL Sample Database You can follow the documentation above or just go to : link and download the repo as zip. Load MySQL Sample Database into MySQLWorkbench When you have downloaded the git repo as zip go to your Download files and unzip the folder and open MySQLWorkbench then go to > File > Run SQL Scripts and load the file employees.sql Run a test query We will running a test query for testing our database, we must open a new file for writing our query for that you can click on the file icon button like in the screen below or go to File > New Query Tab use employees ; SELECT d . dept_name , AVG ( s . salary ) AS avg_salary FROM departments d INNER JOIN dept_emp de ON d . dept_no = de . dept_no INNER JOIN salaries s ON de . emp_no = s . emp_no GROUP BY d . dept_name ; Notice that, the first line use employees; is here to tell to our software to use the employees database then you can see the result of our test query in the window bellow : We will study in detail this query later don't worry. In-depth look at more basic queries in SQL We encourage you to pratice the queries into MySQLWorkbench, let's review some basics ! SELECT statement: The SELECT statement is used to retrieve data from a table in a database. It can take multiple arguments, which are separated by commas. The * character can be used as a shorthand to select all columns in a table . We often use the AS keyword is used to assign a name to a column in the output. SELECT first_name , last_name , salary AS \"Annual Salary\" FROM employees ; In this example, the AS keyword is used to assign a new name to the \"salary\" column in the output. The new name is \"Annual Salary\". This query selects the first name, last name, and salary of all the employees in the \"employees\" table, but it renames the \"salary\" column as \"Annual Salary\" in the output. Note that the AS keyword is optional, and you can also use a space or equals sign to assign a name to a column. For example, the following query is equivalent to the one above: SELECT first_name , last_name , salary \"Annual Salary\" FROM employees ; In both cases, the output column is named \"Annual Salary\". WHERE clause: The WHERE clause is used to filter the results returned by a SELECT statement. It contains a logical expression that evaluates to true or false for each row in the table. SELECT * FROM orders WHERE order_date >= '2022-01-01' ; This query selects all the columns from the \"orders\" table where the order date is on or after January 1, 2022. This is an other example : SELECT first_name , last_name , salary * 12 AS \"Annual Salary\" FROM employees WHERE hire_date >= '2005-01-01' ; In this example, the WHERE clause is used to filter the results to include only employees hired on or after January 1, 2005. The AS keyword is used to assign a new name to the \"salary * 12\" expression in the output. The new name is \"Annual Salary\". This query selects the first name, last name, and annual salary of all the employees in the \"employees\" table who were hired on or after January 1, 2005. The annual salary is calculated by multiplying the monthly salary by 12. Note that the order of the SQL clauses matters. The WHERE clause is used to filter the results before the AS keyword is used to assign a new name to the output column. JOIN clause The JOIN clause is used to combine rows from two or more tables based on a related column between them. Here's an example: SELECT customers . first_name , customers . last_name , orders . order_date FROM customers INNER JOIN orders ON customers . customer_id = orders . customer_id ; This query selects the first name, last name, and order date of all customers who have placed an order. The results are obtained by joining the \"customers\" and \"orders\" tables on the customer_id column. We will discuss nore about JOIN later don't worry. ORDER BY clause The ORDER BY clause is used to sort the results returned by a SELECT statement based on one or more columns. Here's an example: SELECT product_name , unit_price FROM products ORDER BY unit_price DESC ; This query selects the product name and unit price of all the products in the \"products\" table and sorts the results in descending order based on the unit price. GROUP BY clause The GROUP BY clause is used to group the rows returned by a SELECT statement based on one or more columns. The columns listed in the SELECT statement must be either in the GROUP BY clause or have an aggregate function applied to them. Aggregate functions like COUNT, SUM, AVG, MAX, and MIN can be used to perform calculations on the grouped data. SELECT category_id , COUNT ( * ) AS num_products FROM products GROUP BY category_id ; This query groups the products in the \"products\" table by their category and counts the number of products in each category. The COUNT(*) function is used to count the number of rows in each group, and the AS keyword is used to assign the name \"num_products\" to the output column. Here an other example : SELECT department , AVG ( salary ) AS \"Average Salary\" FROM employees GROUP BY department ORDER BY \"Average Salary\" DESC ; In this example, the GROUP BY clause is used to group the employees by department, and the AVG() function is used to calculate the average salary for each department. The AS keyword is used to assign a new name to the \"AVG(salary)\" expression in the output. The new name is \"Average Salary\". The ORDER BY keyword is used to sort the results in descending order based on the \"Average Salary\" column. Note that we need to enclose the output column name in double quotes because it contains a space. This query selects the department and average salary of all the employees in the \"employees\" table, grouped by department, and sorted in descending order by average salary. Note that when using the GROUP BY clause, the SELECT statement can only include the columns that are specified in the GROUP BY clause or have an aggregate function applied to them. Any other columns will result in an error, unless they are included in an aggregate function. In this example, we only select the department and average salary columns because the department column is included in the GROUP BY clause. Wrap up These are just a few examples of basic SQL queries, but they provide a good foundation for building more complex queries. By combining these statements with other SQL clauses, you can perform powerful data analysis and extract valuable insights from your data. Let's summarize what we've learn in this section : The SELECT statement is used to retrieve data from a table in a database. It can take multiple arguments, which are separated by commas. The * character can be used as a shorthand to select all columns in a table. The AS keyword is used to assign a name to a column in the output. The WHERE clause is used to filter the results returned by a SELECT statement. It contains a logical expression that evaluates to true or false for each row in the table. The JOIN clause is used to combine rows from two or more tables based on a related column between them. It can be used to join tables on a primary key/foreign key relationship or on a common column. The GROUP BY clause is used to group the rows returned by a SELECT statement based on one or more columns. The columns listed in the SELECT statement must be either in the GROUP BY clause or have an aggregate function applied to them. Aggregate functions like COUNT, SUM, AVG, MAX, and MIN can be used to perform calculations on the grouped data. The ORDER BY clause is used to sort the results returned by a SELECT statement based on one or more columns. It can be used to sort in ascending (ASC) or descending (DESC) order. The AS keyword is used to assign a new name to a column or an expression in the output. SQL keywords are not case-sensitive, but it is a best practice to use them in uppercase to make the code more readable. The order of the SQL clauses matters, and it can affect the output of the query.","title":"More queries"},{"location":"sql/13_queries_db/#more-queries","text":"In this chapter we will be working on the MySQL Sample Database. The MySQL Sample Database provides a sample database called \"employees\" that you can use to practice SQL queries. You can download the database and load it into your MySQL server. Link to the database","title":"More queries"},{"location":"sql/13_queries_db/#download-the-database-and-load-it-into-mysqlworkbench","text":"\ud83d\udea7 You need to run MySQL server (with MAMP for example) before lunching MySQLWorkbench \ud83d\udea7","title":"Download the database and load it into MySQLWorkbench"},{"location":"sql/13_queries_db/#dowload-the-mysql-sample-database","text":"You can follow the documentation above or just go to : link and download the repo as zip.","title":"Dowload the MySQL Sample Database"},{"location":"sql/13_queries_db/#load-mysql-sample-database-into-mysqlworkbench","text":"When you have downloaded the git repo as zip go to your Download files and unzip the folder and open MySQLWorkbench then go to > File > Run SQL Scripts and load the file employees.sql","title":"Load MySQL Sample Database into MySQLWorkbench"},{"location":"sql/13_queries_db/#run-a-test-query","text":"We will running a test query for testing our database, we must open a new file for writing our query for that you can click on the file icon button like in the screen below or go to File > New Query Tab use employees ; SELECT d . dept_name , AVG ( s . salary ) AS avg_salary FROM departments d INNER JOIN dept_emp de ON d . dept_no = de . dept_no INNER JOIN salaries s ON de . emp_no = s . emp_no GROUP BY d . dept_name ; Notice that, the first line use employees; is here to tell to our software to use the employees database then you can see the result of our test query in the window bellow : We will study in detail this query later don't worry.","title":"Run a test query"},{"location":"sql/13_queries_db/#in-depth-look-at-more-basic-queries-in-sql","text":"We encourage you to pratice the queries into MySQLWorkbench, let's review some basics !","title":"In-depth look at more basic queries in SQL"},{"location":"sql/13_queries_db/#select-statement","text":"The SELECT statement is used to retrieve data from a table in a database. It can take multiple arguments, which are separated by commas. The * character can be used as a shorthand to select all columns in a table . We often use the AS keyword is used to assign a name to a column in the output. SELECT first_name , last_name , salary AS \"Annual Salary\" FROM employees ; In this example, the AS keyword is used to assign a new name to the \"salary\" column in the output. The new name is \"Annual Salary\". This query selects the first name, last name, and salary of all the employees in the \"employees\" table, but it renames the \"salary\" column as \"Annual Salary\" in the output. Note that the AS keyword is optional, and you can also use a space or equals sign to assign a name to a column. For example, the following query is equivalent to the one above: SELECT first_name , last_name , salary \"Annual Salary\" FROM employees ; In both cases, the output column is named \"Annual Salary\".","title":"SELECT statement:"},{"location":"sql/13_queries_db/#where-clause","text":"The WHERE clause is used to filter the results returned by a SELECT statement. It contains a logical expression that evaluates to true or false for each row in the table. SELECT * FROM orders WHERE order_date >= '2022-01-01' ; This query selects all the columns from the \"orders\" table where the order date is on or after January 1, 2022. This is an other example : SELECT first_name , last_name , salary * 12 AS \"Annual Salary\" FROM employees WHERE hire_date >= '2005-01-01' ; In this example, the WHERE clause is used to filter the results to include only employees hired on or after January 1, 2005. The AS keyword is used to assign a new name to the \"salary * 12\" expression in the output. The new name is \"Annual Salary\". This query selects the first name, last name, and annual salary of all the employees in the \"employees\" table who were hired on or after January 1, 2005. The annual salary is calculated by multiplying the monthly salary by 12. Note that the order of the SQL clauses matters. The WHERE clause is used to filter the results before the AS keyword is used to assign a new name to the output column.","title":"WHERE clause:"},{"location":"sql/13_queries_db/#join-clause","text":"The JOIN clause is used to combine rows from two or more tables based on a related column between them. Here's an example: SELECT customers . first_name , customers . last_name , orders . order_date FROM customers INNER JOIN orders ON customers . customer_id = orders . customer_id ; This query selects the first name, last name, and order date of all customers who have placed an order. The results are obtained by joining the \"customers\" and \"orders\" tables on the customer_id column. We will discuss nore about JOIN later don't worry.","title":"JOIN clause"},{"location":"sql/13_queries_db/#order-by-clause","text":"The ORDER BY clause is used to sort the results returned by a SELECT statement based on one or more columns. Here's an example: SELECT product_name , unit_price FROM products ORDER BY unit_price DESC ; This query selects the product name and unit price of all the products in the \"products\" table and sorts the results in descending order based on the unit price.","title":"ORDER BY clause"},{"location":"sql/13_queries_db/#group-by-clause","text":"The GROUP BY clause is used to group the rows returned by a SELECT statement based on one or more columns. The columns listed in the SELECT statement must be either in the GROUP BY clause or have an aggregate function applied to them. Aggregate functions like COUNT, SUM, AVG, MAX, and MIN can be used to perform calculations on the grouped data. SELECT category_id , COUNT ( * ) AS num_products FROM products GROUP BY category_id ; This query groups the products in the \"products\" table by their category and counts the number of products in each category. The COUNT(*) function is used to count the number of rows in each group, and the AS keyword is used to assign the name \"num_products\" to the output column. Here an other example : SELECT department , AVG ( salary ) AS \"Average Salary\" FROM employees GROUP BY department ORDER BY \"Average Salary\" DESC ; In this example, the GROUP BY clause is used to group the employees by department, and the AVG() function is used to calculate the average salary for each department. The AS keyword is used to assign a new name to the \"AVG(salary)\" expression in the output. The new name is \"Average Salary\". The ORDER BY keyword is used to sort the results in descending order based on the \"Average Salary\" column. Note that we need to enclose the output column name in double quotes because it contains a space. This query selects the department and average salary of all the employees in the \"employees\" table, grouped by department, and sorted in descending order by average salary. Note that when using the GROUP BY clause, the SELECT statement can only include the columns that are specified in the GROUP BY clause or have an aggregate function applied to them. Any other columns will result in an error, unless they are included in an aggregate function. In this example, we only select the department and average salary columns because the department column is included in the GROUP BY clause.","title":"GROUP BY clause"},{"location":"sql/13_queries_db/#wrap-up","text":"These are just a few examples of basic SQL queries, but they provide a good foundation for building more complex queries. By combining these statements with other SQL clauses, you can perform powerful data analysis and extract valuable insights from your data. Let's summarize what we've learn in this section : The SELECT statement is used to retrieve data from a table in a database. It can take multiple arguments, which are separated by commas. The * character can be used as a shorthand to select all columns in a table. The AS keyword is used to assign a name to a column in the output. The WHERE clause is used to filter the results returned by a SELECT statement. It contains a logical expression that evaluates to true or false for each row in the table. The JOIN clause is used to combine rows from two or more tables based on a related column between them. It can be used to join tables on a primary key/foreign key relationship or on a common column. The GROUP BY clause is used to group the rows returned by a SELECT statement based on one or more columns. The columns listed in the SELECT statement must be either in the GROUP BY clause or have an aggregate function applied to them. Aggregate functions like COUNT, SUM, AVG, MAX, and MIN can be used to perform calculations on the grouped data. The ORDER BY clause is used to sort the results returned by a SELECT statement based on one or more columns. It can be used to sort in ascending (ASC) or descending (DESC) order. The AS keyword is used to assign a new name to a column or an expression in the output. SQL keywords are not case-sensitive, but it is a best practice to use them in uppercase to make the code more readable. The order of the SQL clauses matters, and it can affect the output of the query.","title":"Wrap up"}]}